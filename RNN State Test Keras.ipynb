{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN State Test using Keras \n",
    "\n",
    "In this notebook I will be demostrating the difference between return_seqences and return_states in the Keras API for recrrent layers. I will be using both LSTM and GRU cells for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10 # seqence length or time-steps\n",
    "D = 2 # Input dimension or features \n",
    "M = 4 # Hidden layer size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(1,T,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "\n",
    "# This is the input shape that a RNN cell expects \n",
    "\n",
    "# The input must be a 3-D tensor of shape (batch,time-steps,features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_1():\n",
    "    '''\n",
    "    This functions defines a LSTM cell and returns its output,hidden state and cell state.\n",
    "    The return_state is set to True and return_seqences is set to False.\n",
    "    '''\n",
    "    \n",
    "    input_ = Input(shape=(T,D))\n",
    "    rnn = LSTM(units=M,return_state=True,return_sequences=False)\n",
    "    x = rnn(input_)\n",
    "    \n",
    "    model = Model(inputs=input_ , outputs= x)\n",
    "    o,h,c = model.predict(X)\n",
    "    \n",
    "    print('Output:',o)\n",
    "    print('\\n')\n",
    "    print('Output Shape:',o.shape)\n",
    "    print('\\n')\n",
    "    print('Hidden State:',h)\n",
    "    print('\\n')\n",
    "    print('Hidden State Shape:',h.shape)\n",
    "    print('\\n')\n",
    "    print('Cell State:',c)\n",
    "    print('\\n')\n",
    "    print('Cell State shape:',c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_2():\n",
    "    '''\n",
    "    This functions defines a LSTM cell and returns its output,hidden state and cell state.\n",
    "    The return_state is set to True and return_seqences is set to True.\n",
    "    '''\n",
    "    \n",
    "    input_ = Input(shape=(T,D))\n",
    "    rnn = LSTM(units=M,return_sequences=True,return_state=True)\n",
    "    x = rnn(input_)\n",
    "    \n",
    "    model = Model(input_,x)\n",
    "    o,h,c = model.predict(X)\n",
    "    \n",
    "    print('Output:',o)\n",
    "    print('\\n')\n",
    "    print('Output Shape:',o.shape)\n",
    "    print('\\n')\n",
    "    print('Hidden State:',h)\n",
    "    print('\\n')\n",
    "    print('Hidden State Shape:',h.shape)\n",
    "    print('\\n')\n",
    "    print('Cell State:',c)\n",
    "    print('\\n')\n",
    "    print('Cell State shape:',c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_1():\n",
    "    '''\n",
    "    This functions defines a GRU cell and returns its output and hidden state.\n",
    "    The return_state is set to True and return_seqences is set to False.\n",
    "    '''\n",
    "    \n",
    "    input_ = Input(shape=(T,D))\n",
    "    rnn = GRU(units=M,return_state=True,return_sequences=False)\n",
    "    x = rnn(input_)\n",
    "    \n",
    "    model = Model(input_,x)\n",
    "    o,h = model.predict(X)\n",
    "    \n",
    "    print('Output:',o)\n",
    "    print('\\n')\n",
    "    print('Output Shape:',o.shape)\n",
    "    print('\\n')\n",
    "    print('Hidden State:',h)\n",
    "    print('\\n')\n",
    "    print('Hidden State Shape:',h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_2():\n",
    "    '''\n",
    "    This functions defines a GRU cell and returns its output and hidden state.\n",
    "    The return_state is set to True and return_seqences is set to True.\n",
    "    '''\n",
    "    \n",
    "    input_ = Input(shape=(T,D))\n",
    "    rnn = GRU(units=M,return_state=True,return_sequences=True)\n",
    "    x = rnn(input_)\n",
    "    \n",
    "    model = Model(input_,x)\n",
    "    o,h = model.predict(X)\n",
    "    \n",
    "    print('Output:',o)\n",
    "    print('\\n')\n",
    "    print('Output Shape:',o.shape)\n",
    "    print('\\n')\n",
    "    print('Hidden State:',h)\n",
    "    print('\\n')\n",
    "    print('Hidden State Shape:',h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_1\n",
      "\n",
      "\n",
      "Output: [[-0.13705452  0.12022021 -0.3441377   0.07776075]]\n",
      "\n",
      "\n",
      "Output Shape: (1, 4)\n",
      "\n",
      "\n",
      "Hidden State: [[-0.13705452  0.12022021 -0.3441377   0.07776075]]\n",
      "\n",
      "\n",
      "Hidden State Shape: (1, 4)\n",
      "\n",
      "\n",
      "Cell State: [[-0.22892734  0.18493187 -0.70387197  0.12077542]]\n",
      "\n",
      "\n",
      "Cell State shape: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('lstm_1')\n",
    "print('\\n')\n",
    "lstm_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the output and hidden state are same but the cell state is different. Notice the shape of every object here, they are all of the shape (1,4) which corresponds to the sample and hidden dimension respectively. Here we have set the return_seqences to be False, hence the output returns only the hidden and cell state of the final seqence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_2\n",
      "\n",
      "\n",
      "Output: [[[-0.01556229  0.07676451  0.04730725  0.00345482]\n",
      "  [-0.05091928  0.13667482 -0.0356027  -0.00430598]\n",
      "  [-0.10059121  0.2106916  -0.10895777 -0.02924241]\n",
      "  [ 0.04250218 -0.0860673   0.16977929  0.0072417 ]\n",
      "  [ 0.09593287 -0.22544116  0.13827918  0.00587416]\n",
      "  [ 0.04078832 -0.06416251  0.2189483   0.00339779]\n",
      "  [ 0.0487584  -0.14450897  0.20324133  0.00274296]\n",
      "  [ 0.06455808 -0.18928595  0.2756748   0.00673052]\n",
      "  [-0.05552567 -0.00833835  0.02959559 -0.02320448]\n",
      "  [-0.08483997  0.04004847 -0.06473035 -0.03224741]]]\n",
      "\n",
      "\n",
      "Output Shape: (1, 10, 4)\n",
      "\n",
      "\n",
      "Hidden State: [[-0.08483997  0.04004847 -0.06473035 -0.03224741]]\n",
      "\n",
      "\n",
      "Hidden State Shape: (1, 4)\n",
      "\n",
      "\n",
      "Cell State: [[-0.19424611  0.07681724 -0.16359454 -0.06385694]]\n",
      "\n",
      "\n",
      "Cell State shape: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('lstm_2')\n",
    "print('\\n')\n",
    "lstm_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see the difference when we set return_seqences to be True. The only difference here is the output contains the entire seqence. Notice the shape of the output (1,10,4) which corrensponds to batch,time-step and hidden dimension respectively. When we are stacking multiple layers of LSTM it is necessary to specify return_seqences to be True so that input to the second LSTM layer will be a 3-D tensor with time dimension on the 2nd axis. Here, we can also see that the last row of the output is same as that of the hidden state, this proves that when we set return_seqences False only the last hidden state value is returned as output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_1\n",
      "Output: [[ 0.43486446  0.4459237   0.11545931 -0.26306632]]\n",
      "\n",
      "\n",
      "Output Shape: (1, 4)\n",
      "\n",
      "\n",
      "Hidden State: [[ 0.43486446  0.4459237   0.11545931 -0.26306632]]\n",
      "\n",
      "\n",
      "Hidden State Shape: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('gru_1')\n",
    "gru_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_2\n",
      "Output: [[[-0.03148022  0.12049837  0.18103163  0.18454805]\n",
      "  [-0.19749367  0.04313508  0.2563645  -0.09047672]\n",
      "  [-0.41434777 -0.14893222  0.31628466 -0.6242127 ]\n",
      "  [ 0.28279668 -0.00580456 -0.25375867 -0.3491187 ]\n",
      "  [ 0.39277342 -0.20834535 -0.45176262 -0.33512896]\n",
      "  [ 0.30699134  0.05046801 -0.0405878   0.07690015]\n",
      "  [ 0.31485742 -0.08253266 -0.23865432 -0.02356813]\n",
      "  [ 0.3808537  -0.06204725 -0.36540538  0.06372052]\n",
      "  [-0.06494007 -0.04870018  0.03072032 -0.36238673]\n",
      "  [-0.19713812 -0.12900753  0.09717467 -0.49170685]]]\n",
      "\n",
      "\n",
      "Output Shape: (1, 10, 4)\n",
      "\n",
      "\n",
      "Hidden State: [[-0.19713812 -0.12900753  0.09717467 -0.49170685]]\n",
      "\n",
      "\n",
      "Hidden State Shape: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('gru_2')\n",
    "gru_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theory of LSTM can be extended to GRU as well. The only difference here is the absence of a cell state. This is understandable since GRU uses only one update gate to produce the next hidden state where as LSTM uses both forget gate and input gate to generate the next cell state which inturn is used to produce the next hidden state. Basically GRU incorporates the cell and hidden state into one hidden state where as in LSTM they two seperate states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
