{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poetry Generation using LSTM \n",
    "\n",
    "In this notebook, I will try to generate a poem by American poet Robert Frost. The poem I am using is 'The Road Not Taken' and can be downloaded from the link given below. \n",
    "\n",
    "Poetry generation belongs to a class of NLP called language modelling. The idea itself is not so different from a seq2seq model, the difference here is that we won't be having an encoder network but just a decoder network. For language modelling tasks such as poetry generation, the network architecture is similar to the decoder network in a seq2seq model.\n",
    "\n",
    "\n",
    "https://www.poetryfoundation.org/poems/44272/the-road-not-taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ambar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Random Seed and Reproducible results in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "rn.seed(12345)\n",
    "\n",
    "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)(Makes training very slow)\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_VOCAB_SIZE = 3000\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 1000\n",
    "HIDDEN_DIM = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Pre-Trained Glove Vectors \n",
    "\n",
    "We will be using 50 dim Glove vecors here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "word2vec = {}\n",
    "with open(os.path.join('glove.6B/glove.6B.50d.txt'),encoding='utf8') as f:\n",
    "  \n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found {} word vectors'.format(len(word2vec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the original Poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood,\n",
      "\n",
      "And sorry I could not travel both\n",
      "\n",
      "And be one traveler, long I stood\n",
      "\n",
      "And looked down one as far as I could\n",
      "\n",
      "To where it bent in the undergrowth; \n",
      "\n",
      "\n",
      "\n",
      "Then took the other, as just as fair,\n",
      "\n",
      "And having perhaps the better claim\n",
      "\n",
      "Because it was grassy and wanted wear,\n",
      "\n",
      "Though as for that the passing there\n",
      "\n",
      "Had worn them really about the same,\n",
      "\n",
      "\n",
      "\n",
      "And both that morning equally lay\n",
      "\n",
      "In leaves no step had trodden black.\n",
      "\n",
      "Oh, I kept the first for another day! \n",
      "\n",
      "Yet knowing how way leads on to way\n",
      "\n",
      "I doubted if I should ever come back.\n",
      "\n",
      "\n",
      "\n",
      "I shall be telling this with a sigh\n",
      "\n",
      "Somewhere ages and ages hence:\n",
      "\n",
      "Two roads diverged in a wood, and I,\n",
      "\n",
      "I took the one less traveled by,\n",
      "\n",
      "And that has made all the difference.\n",
      "\n",
      "\n",
      "\n",
      "Whose woods these are I think I know.\n",
      "\n",
      "His house is in the village, though; \n",
      "\n",
      "He will not see me stopping here\n",
      "\n",
      "To watch his woods fill up with snow.\n",
      "\n",
      "\n",
      "\n",
      "My little horse must think it queer\n",
      "\n",
      "To stop without a farmhouse near\n",
      "\n",
      "Between the woods and frozen lake\n",
      "\n",
      "The darkest evening of the year.\n",
      "\n",
      "\n",
      "\n",
      "He gives his harness bells a shake\n",
      "\n",
      "To ask if there is some mistake.\n",
      "\n",
      "The only other sound's the sweep\n",
      "\n",
      "Of easy wind and downy flake.\n",
      "\n",
      "\n",
      "\n",
      "The woods are lovely, dark and deep,\n",
      "\n",
      "But I have promises to keep,\n",
      "\n",
      "And miles to go before I sleep,\n",
      "\n",
      "And miles to go before I sleep. \n",
      "\n",
      "\n",
      "\n",
      "Some say the world will end in fire,\n",
      "\n",
      "Some say in ice.\n",
      "\n",
      "From what I've tasted of desire\n",
      "\n",
      "I hold with those who favor fire.\n",
      "\n",
      "But if it had to perish twice,\n",
      "\n",
      "I think I know enough of hate\n",
      "\n",
      "To say that for destruction ice\n",
      "\n",
      "Is also great\n",
      "\n",
      "And would suffice.\n",
      "\n",
      "\n",
      "\n",
      "Nature's first green is gold,\n",
      "\n",
      "Her hardest hue to hold.\n",
      "\n",
      "Her early leaf's a flower; \n",
      "\n",
      "But only so an hour.\n",
      "\n",
      "Then leaf subsides to leaf,\n",
      "\n",
      "So Eden sank to grief,\n",
      "\n",
      "So dawn goes down to day\n",
      "\n",
      "Nothing gold can stay.\n",
      "\n",
      "\n",
      "\n",
      "I have been one acquainted with the night.\n",
      "\n",
      "I have walked out in rain - and back in rain.\n",
      "\n",
      "I have outwalked the furthest city light.\n",
      "\n",
      "\n",
      "\n",
      "I have looked down the saddest city lane.\n",
      "\n",
      "I have passed by the watchman on his beat\n",
      "\n",
      "And dropped my eyes, unwilling to explain.\n",
      "\n",
      "\n",
      "\n",
      "I have stood still and stopped the sound of feet\n",
      "\n",
      "When far away an interrupted cry\n",
      "\n",
      "Came over houses from another street,\n",
      "\n",
      "\n",
      "\n",
      "But not to call me back or say good-bye; \n",
      "\n",
      "And further still at an unearthly height,\n",
      "\n",
      "One luminary clock against the sky\n",
      "\n",
      "\n",
      "\n",
      "Proclaimed the time was neither wrong nor right.\n",
      "\n",
      "I have been one acquainted with the night.\n",
      "\n",
      "\n",
      "\n",
      "When I go up through the mowing field,\n",
      "\n",
      "The headless aftermath,\n",
      "\n",
      "Smooth-laid like thatch with the heavy dew,\n",
      "\n",
      "Half closes the garden path.\n",
      "\n",
      "\n",
      "\n",
      "And when I come to the garden ground,\n",
      "\n",
      "The whir of sober birds\n",
      "\n",
      "Up from the tangle of withered weeds\n",
      "\n",
      "Is sadder than any words\n",
      "\n",
      "\n",
      "\n",
      "A tree beside the wall stands bare,\n",
      "\n",
      "But a leaf that lingered brown,\n",
      "\n",
      "Disturbed, I doubt not, by my thought,\n",
      "\n",
      "Comes softly rattling down.\n",
      "\n",
      "\n",
      "\n",
      "I end not far from my going forth\n",
      "\n",
      "By picking the faded blue\n",
      "\n",
      "Of the last remaining aster flower\n",
      "\n",
      "To carry again to you.\n",
      "\n",
      "\n",
      "\n",
      "A voice said, Look me in the stars\n",
      "\n",
      "And tell me truly, men of earth,\n",
      "\n",
      "If all the soul-and-body scars\n",
      "\n",
      "Were not too much to pay for birth.\n",
      "\n",
      "\n",
      "\n",
      "To think to know the country and now know\n",
      "\n",
      "The hillside on the day the sun lets go\n",
      "\n",
      "Ten million silver lizards out of snow!\n",
      "\n",
      "As often as I've seen it done before\n",
      "\n",
      "I can't pretend to tell the way it's done.\n",
      "\n",
      "It looks as if some magic of the sun\n",
      "\n",
      "Lifted the rug that bred them on the floor\n",
      "\n",
      "And the light breaking on them made them run.\n",
      "\n",
      "But if I though to stop the wet stampede,\n",
      "\n",
      "And caught one silver lizard by the tail,\n",
      "\n",
      "And put my foot on one without avail,\n",
      "\n",
      "And threw myself wet-elbowed and wet-kneed\n",
      "\n",
      "In front of twenty others' wriggling speed,- \n",
      "\n",
      "In the confusion of them all aglitter,\n",
      "\n",
      "And birds that joined in the excited fun\n",
      "\n",
      "By doubling and redoubling song and twitter,\n",
      "\n",
      "I have no doubt I'd end by holding none.\n",
      "\n",
      "\n",
      "\n",
      "It takes the moon for this. The sun's a wizard\n",
      "\n",
      "By all I tell; but so's the moon a witch.\n",
      "\n",
      "From the high west she makes a gentle cast\n",
      "\n",
      "And suddenly, without a jerk or twitch,\n",
      "\n",
      "She has her speel on every single lizard.\n",
      "\n",
      "I fancied when I looked at six o'clock\n",
      "\n",
      "The swarm still ran and scuttled just as fast.\n",
      "\n",
      "The moon was waiting for her chill effect.\n",
      "\n",
      "I looked at nine: the swarm was turned to rock\n",
      "\n",
      "In every lifelike posture of the swarm,\n",
      "\n",
      "Transfixed on mountain slopes almost erect.\n",
      "\n",
      "Across each other and side by side they lay.\n",
      "\n",
      "The spell that so could hold them as they were\n",
      "\n",
      "Was wrought through trees without a breath of storm\n",
      "\n",
      "To make a leaf, if there had been one, stir.\n",
      "\n",
      "One lizard at the end of every ray.\n",
      "\n",
      "The thought of my attempting such a stray! \n",
      "\n",
      "\n",
      "\n",
      "ONCE on the kind of day called \"weather breeder,\"\n",
      "\n",
      "When the heat slowly hazes and the sun\n",
      "\n",
      "By its own power seems to be undone,\n",
      "\n",
      "I was half boring through, half climbing through\n",
      "\n",
      "A swamp of cedar. Choked with oil of cedar\n",
      "\n",
      "And scurf of plants, and weary and over-heated,\n",
      "\n",
      "And sorry I ever left the road I knew,\n",
      "\n",
      "I paused and rested on a sort of hook\n",
      "\n",
      "That had me by the coat as good as seated,\n",
      "\n",
      "And since there was no other way to look,\n",
      "\n",
      "Looked up toward heaven, and there against the blue,\n",
      "\n",
      "Stood over me a resurrected tree,\n",
      "\n",
      "A tree that had been down and raised again—\n",
      "\n",
      "A barkless spectre. He had halted too,\n",
      "\n",
      "As if for fear of treading upon me.\n",
      "\n",
      "I saw the strange position of his hands—\n",
      "\n",
      "Up at his shoulders, dragging yellow strands\n",
      "\n",
      "Of wire with something in it from men to men.\n",
      "\n",
      "\"You here?\" I said. \"Where aren't you nowadays\n",
      "\n",
      "And what's the news you carry—if you know?\n",
      "\n",
      "And tell me where you're off for—Montreal?\n",
      "\n",
      "Me? I'm not off for anywhere at all.\n",
      "\n",
      "Sometimes I wander out of beaten ways\n",
      "\n",
      "Half looking for the orchid Calypso.\"\n",
      "\n",
      "\n",
      "\n",
      "Brown lived at such a lofty farm\n",
      "\n",
      "That everyone for miles could see\n",
      "\n",
      "His lantern when he did his chores\n",
      "\n",
      "In winter after half-past three.\n",
      "\n",
      "\n",
      "\n",
      "And many must have seen him make\n",
      "\n",
      "His wild descent from there one night,\n",
      "\n",
      "'Cross lots, 'cross walls, 'cross everything,\n",
      "\n",
      "Describing rings of lantern light.\n",
      "\n",
      "\n",
      "\n",
      "Between the house and barn the gale\n",
      "\n",
      "Got him by something he had on\n",
      "\n",
      "And blew him out on the icy crust\n",
      "\n",
      "That cased the world, and he was gone!\n",
      "\n",
      "\n",
      "\n",
      "Walls were all buried, trees were few:\n",
      "\n",
      "He saw no stay unless he stove\n",
      "\n",
      "A hole in somewhere with his heel.\n",
      "\n",
      "But though repeatedly he strove\n",
      "\n",
      "\n",
      "\n",
      "And stamped and said things to himself,\n",
      "\n",
      "And sometimes something seemed to yield,\n",
      "\n",
      "He gained no foothold, but pursued\n",
      "\n",
      "His journey down from field to field.\n",
      "\n",
      "\n",
      "\n",
      "Sometimes he came with arms outspread\n",
      "\n",
      "Like wings, revolving in the scene\n",
      "\n",
      "Upon his longer axis, and\n",
      "\n",
      "With no small dignity of mien.\n",
      "\n",
      "\n",
      "\n",
      "Faster or slower as he chanced,\n",
      "\n",
      "Sitting or standing as he chose,\n",
      "\n",
      "According as he feared to risk\n",
      "\n",
      "His neck, or thought to spare his clothes,\n",
      "\n",
      "\n",
      "\n",
      "He never let the lantern drop.\n",
      "\n",
      "And some exclaimed who saw afar\n",
      "\n",
      "The figures he described with it,\n",
      "\n",
      "\"I wonder what those signals are\n",
      "\n",
      "\n",
      "\n",
      "Brown makes at such an hour of night!\n",
      "\n",
      "He's celebrating something strange.\n",
      "\n",
      "I wonder if he's sold his farm,\n",
      "\n",
      "Or been made Master of the Grange.\"\n",
      "\n",
      "\n",
      "\n",
      "He reeled, he lurched, he bobbed, he checked;\n",
      "\n",
      "He fell and made the lantern rattle\n",
      "\n",
      "(But saved the light from going out.)\n",
      "\n",
      "So half-way down he fought the battle\n",
      "\n",
      "\n",
      "\n",
      "Incredulous of his own bad luck.\n",
      "\n",
      "And then becoming reconciled\n",
      "\n",
      "To everything, he gave it up\n",
      "\n",
      "And came down like a coasting child.\n",
      "\n",
      "\n",
      "\n",
      "\"Well—I—be—\" that was all he said,\n",
      "\n",
      "As standing in the river road,\n",
      "\n",
      "He looked back up the slippery slope\n",
      "\n",
      "(Two miles it was) to his abode.\n",
      "\n",
      "\n",
      "\n",
      "Sometimes as an authority\n",
      "\n",
      "On motor-cars, I'm asked if I\n",
      "\n",
      "Should say our stock was petered out,\n",
      "\n",
      "And this is my sincere reply:\n",
      "\n",
      "\n",
      "\n",
      "Yankees are what they always were.\n",
      "\n",
      "Don't think Brown ever gave up hope\n",
      "\n",
      "Of getting home again because\n",
      "\n",
      "He couldn't climb that slippery slope;\n",
      "\n",
      "\n",
      "\n",
      "Or even thought of standing there\n",
      "\n",
      "Until the January thaw\n",
      "\n",
      "Should take the polish off the crust.\n",
      "\n",
      "He bowed with grace to natural law,\n",
      "\n",
      "\n",
      "\n",
      "And then went round it on his feet,\n",
      "\n",
      "After the manner of our stock;\n",
      "\n",
      "Not much concerned for those to whom,\n",
      "\n",
      "At that particular time o'clock,\n",
      "\n",
      "\n",
      "\n",
      "It must have looked as if the course\n",
      "\n",
      "He steered was really straight away\n",
      "\n",
      "From that which he was headed for—\n",
      "\n",
      "Not much concerned for them, I say:\n",
      "\n",
      "\n",
      "\n",
      "No more so than became a man—\n",
      "\n",
      "And politician at odd seasons.\n",
      "\n",
      "I've kept Brown standing in the cold\n",
      "\n",
      "While I invested him with reasons;\n",
      "\n",
      "\n",
      "\n",
      "But now he snapped his eyes three times;\n",
      "\n",
      "Then shook his lantern, saying, \"Ile's\n",
      "\n",
      "'Bout out!\" and took the long way home\n",
      "\n",
      "By road, a matter of several miles.\n",
      "\n",
      "\n",
      "\n",
      "NOW that they've got it settled whose I be,\n",
      "\n",
      "I'm going to tell them something they won't like:\n",
      "\n",
      "They've got it settled wrong, and I can prove it.\n",
      "\n",
      "Flattered I must be to have two towns fighting\n",
      "\n",
      "To make a present of me to each other.\n",
      "\n",
      "They don't dispose me, either one of them,\n",
      "\n",
      "To spare them any trouble. Double trouble's\n",
      "\n",
      "Always the witch's motto anyway.\n",
      "\n",
      "I'll double theirs for both of them- you watch me.\n",
      "\n",
      "They'll find they've got the whole thing to do over,\n",
      "\n",
      "That is, if facts is what they want to go by.\n",
      "\n",
      "They set a lot (now don't they?) by a record\n",
      "\n",
      "Of Arthur Amy's having once been up\n",
      "\n",
      "For Hog Reeve in March Meeting here in Warren.\n",
      "\n",
      "I could have told them any time this twelvemonth\n",
      "\n",
      "The Arthur Amy I was married to\n",
      "\n",
      "Couldn't have been the one they say was up\n",
      "\n",
      "In Warren at March Meeting for the reason\n",
      "\n",
      "He wa'n't but fifteen at the time they say.\n",
      "\n",
      "The Arthur Amy I was married to\n",
      "\n",
      "voted the only times he ever voted,\n",
      "\n",
      "Which wasn't many, in the town of Wentworth.\n",
      "\n",
      "One of the times was when 'twas in the warrant\n",
      "\n",
      "To see if the town wanted to take over\n",
      "\n",
      "The tote road to our clearing where we lived.\n",
      "\n",
      "I'll tell you who'd remember- Heman Lapish.\n",
      "\n",
      "Their Arthur Amy was the father of mine.\n",
      "\n",
      "So now they've dragged it through the law courts once\n",
      "\n",
      "I guess they'd better drag it through again.\n",
      "\n",
      "Wentworth and Warren's both good towns to live in,\n",
      "\n",
      "Only I happen to prefer to live\n",
      "\n",
      "In Wentworth from now on; and when all's said,\n",
      "\n",
      "Right's right, and the temptation to do right\n",
      "\n",
      "When I can hurt someone by doing it\n",
      "\n",
      "Has always been too much for me, it has.\n",
      "\n",
      "I know of some folks that'd be set up\n",
      "\n",
      "At having in their town a noted witch:\n",
      "\n",
      "But most would have to think of the expense\n",
      "\n",
      "That even I would be. They ought to know\n",
      "\n",
      "That as a witch I'd often milk a bat\n",
      "\n",
      "And that'd be enough to last for days.\n",
      "\n",
      "It'd make my position stronger, I think,\n",
      "\n",
      "If I was to consent to give some sign\n",
      "\n",
      "To make it surer that I was a witch?\n",
      "\n",
      "It wa'n't no sign, I s'pose, when Mallice Huse\n",
      "\n",
      "Said that I took him out in his old age\n",
      "\n",
      "And rode all over everything on him\n",
      "\n",
      "Until I'd had him worn to skin and bones,\n",
      "\n",
      "And if I'd left him hitched unblanketed\n",
      "\n",
      "In front of one Town Hall, I'd left him hitched\n",
      "\n",
      "In front of every one in Grafton County.\n",
      "\n",
      "Some cried shame on me not to blanket him,\n",
      "\n",
      "The poor old man. It would have been all right\n",
      "\n",
      "If some one hadn't said to gnaw the posts\n",
      "\n",
      "He stood beside and leave his trade mark on them,\n",
      "\n",
      "So they could recognize them. Not a post\n",
      "\n",
      "That they could hear tell of was scarified.\n",
      "\n",
      "They made him keep on gnawing till he whined.\n",
      "\n",
      "Then that same smarty someone said to look- \n",
      "\n",
      "He'd bet Huse was a cribber and had gnawed\n",
      "\n",
      "The crib he slept in- and as sure's you're born\n",
      "\n",
      "They found he'd gnawed the four posts of his bed,\n",
      "\n",
      "All four of them to splinters. What did that prove?\n",
      "\n",
      "Not that he hadn't gnawed the hitching posts\n",
      "\n",
      "He said he had besides. Because a horse\n",
      "\n",
      "Gnaws in the stable ain't no proof to me\n",
      "\n",
      "He don't gnaw trees and posts and fences too.\n",
      "\n",
      "But everybody took it for proof.\n",
      "\n",
      "I was a strapping girl of twenty then.\n",
      "\n",
      "The smarty someone who spoiled everything\n",
      "\n",
      "Was Arthur Amy. You know who he was.\n",
      "\n",
      "That was the way he started courting me.\n",
      "\n",
      "He never said much after we were married,\n",
      "\n",
      "But I mistrusted he was none too proud\n",
      "\n",
      "Of having interfered in the Huse business.\n",
      "\n",
      "I guess he found he got more out of me\n",
      "\n",
      "By having me a witch. Or something happened\n",
      "\n",
      "To turn him round. He got to saying things\n",
      "\n",
      "To undo what he'd done and make it right,\n",
      "\n",
      "Like, 'No, she ain't come back from kiting yet.\n",
      "\n",
      "Last night was one of her nights out. She's kiting.\n",
      "\n",
      "She thinks when the wind makes a night of it\n",
      "\n",
      "She might as well herself.' But he liked best\n",
      "\n",
      "To let on he was plagued to death with me:\n",
      "\n",
      "If anyone had seen me coming home\n",
      "\n",
      "Over the ridgepole, 'stride of a broomstick,\n",
      "\n",
      "As often as he had in the tail of the night,\n",
      "\n",
      "He guessed they'd know what he had to put up with.\n",
      "\n",
      "Well, I showed Arthur Amy signs enough\n",
      "\n",
      "Off from the house as far as we could keep\n",
      "\n",
      "And from barn smells you can't wash out of ploughed ground\n",
      "\n",
      "With all the rain and snow of seven years;\n",
      "\n",
      "And I don't mean just skulls of Roger's Rangers\n",
      "\n",
      "On Moosilauke, but woman signs to man,\n",
      "\n",
      "Only bewitched so I would last him longer.\n",
      "\n",
      "Up where the trees grow short, the mosses tall,\n",
      "\n",
      "I made him gather me wet snow berries\n",
      "\n",
      "On slippery rocks beside a waterfall.\n",
      "\n",
      "I made him do it for me in the dark.\n",
      "\n",
      "And he liked everything I made him do.\n",
      "\n",
      "I hope if he is where he sees me now\n",
      "\n",
      "He's so far off he can't see what I've come to.\n",
      "\n",
      "You _can_ come down from everything to nothing.\n",
      "\n",
      "All is, if I'd a-known when I was young\n",
      "\n",
      "And full of it, that this would be the end,\n",
      "\n",
      "It doesn't seem as if I'd had the courage\n",
      "\n",
      "To make so free and kick up in folks' faces.\n",
      "\n",
      "I might have, but it doesn't seem as if.\n",
      "\n",
      "\n",
      "\n",
      "Old Davis owned a solid mica mountain\n",
      "\n",
      "In Dalton that would someday make his fortune.\n",
      "\n",
      "There'd been some Boston people out to see it:\n",
      "\n",
      "And experts said that deep down in the mountain\n",
      "\n",
      "The mica sheets were big as plate-glass windows.\n",
      "\n",
      "He'd like to take me there and show it to me.\n",
      "\n",
      "\n",
      "\n",
      "'I'll tell you what you show me. You remember\n",
      "\n",
      "You said you knew the place where once, on Kinsman,\n",
      "\n",
      "The early Mormons made a settlement\n",
      "\n",
      "And built a stone baptismal font outdoors-\n",
      "\n",
      "But Smith, or someone, called them off the mountain\n",
      "\n",
      "To go West to a worse fight with the desert.\n",
      "\n",
      "You said you'd seen the stone baptismal font.\n",
      "\n",
      "Well, take me there.'\n",
      "\n",
      "\n",
      "\n",
      "Someday I will.'\n",
      "\n",
      "\n",
      "\n",
      "'Today.'\n",
      "\n",
      "\n",
      "\n",
      "'Huh, that old bathtub, what is that to see?\n",
      "\n",
      "Let's talk about it.'\n",
      "\n",
      "\n",
      "\n",
      "'Let's go see the place.'\n",
      "\n",
      "\n",
      "\n",
      "'To shut you up I'll tell you what I'll do:\n",
      "\n",
      "I'll find that fountain if it takes all summer,\n",
      "\n",
      "And both of our united strengths, to do it.'\n",
      "\n",
      "\n",
      "\n",
      "'You've lost it, then?'\n",
      "\n",
      "\n",
      "\n",
      "'Not so but I can find it.\n",
      "\n",
      "No doubt it's grown up some to woods around it.\n",
      "\n",
      "The mountain may have shifted since I saw it\n",
      "\n",
      "In eighty-five.'\n",
      "\n",
      "\n",
      "\n",
      "'As long ago as that?'\n",
      "\n",
      "\n",
      "\n",
      "'If I remember rightly, it had sprung\n",
      "\n",
      "A leak and emptied then. And forty years\n",
      "\n",
      "Can do a good deal to bad masonry.\n",
      "\n",
      "You won't see any Mormon swimming in it.\n",
      "\n",
      "But you have said it, and we're off to find it.\n",
      "\n",
      "Old as I am, I'm going to let myself\n",
      "\n",
      "Be dragged by you all over everywhere- '\n",
      "\n",
      "'I thought you were a guide.'\n",
      "\n",
      "\n",
      "\n",
      "'I am a guide,\n",
      "\n",
      "And that's why I can't decently refuse you.'\n",
      "\n",
      "\n",
      "\n",
      "We made a day of it out of the world,\n",
      "\n",
      "Ascending to descend to reascend.\n",
      "\n",
      "The old man seriously took his bearings,\n",
      "\n",
      "And spoke his doubts in every open place.\n",
      "\n",
      "\n",
      "\n",
      "We came out on a look-off where we faced\n",
      "\n",
      "A cliff, and on the cliff a bottle painted,\n",
      "\n",
      "Or stained by vegetation from above,\n",
      "\n",
      "A likeness to surprise the thrilly tourist.\n",
      "\n",
      "\n",
      "\n",
      "'Well, if I haven't brought you to the fountain,\n",
      "\n",
      "At least I've brought you to the famous Bottle.'\n",
      "\n",
      "\n",
      "\n",
      "'I won't accept the substitute. It's empty.'\n",
      "\n",
      "\n",
      "\n",
      "'So's everything.'\n",
      "\n",
      "\n",
      "\n",
      "'I want my fountain.'\n",
      "\n",
      "\n",
      "\n",
      "'I guess you'd find the fountain just as empty.\n",
      "\n",
      "And anyway this tells me where I am.'\n",
      "\n",
      "\n",
      "\n",
      "'Hadn't you long suspected where you were?'\n",
      "\n",
      "\n",
      "\n",
      "'You mean miles from that Mormon settlement?\n",
      "\n",
      "Look here, you treat your guide with due respect\n",
      "\n",
      "If you don't want to spend the night outdoors.\n",
      "\n",
      "I vow we must be near the place from where\n",
      "\n",
      "The two converging slides, the avalanches,\n",
      "\n",
      "On Marshall, look like donkey's ears.\n",
      "\n",
      "We may as well see that and save the day.'\n",
      "\n",
      "\n",
      "\n",
      "'Don't donkey's ears suggest we shake our own?'\n",
      "\n",
      "\n",
      "\n",
      "'For God's sake, aren't you fond of viewing nature?\n",
      "\n",
      "You don't like nature. All you like is books.\n",
      "\n",
      "What signify a donkey's cars and bottle,\n",
      "\n",
      "However natural? Give you your books!\n",
      "\n",
      "Well then, right here is where I show you books.\n",
      "\n",
      "Come straight down off this mountain just as fast\n",
      "\n",
      "As we can fall and keep a-bouncing on our feet.\n",
      "\n",
      "It's hell for knees unless done hell-for-leather.'\n",
      "\n",
      "\n",
      "\n",
      "Be ready, I thought, for almost anything.\n",
      "\n",
      "\n",
      "\n",
      "We struck a road I didn't recognize,\n",
      "\n",
      "But welcomed for the chance to lave my shoes\n",
      "\n",
      "In dust once more. We followed this a mile,\n",
      "\n",
      "Perhaps, to where it ended at a house\n",
      "\n",
      "I didn't know was there. It was the kind\n",
      "\n",
      "To bring me to for broad-board paneling.\n",
      "\n",
      "I never saw so good a house deserted.\n",
      "\n",
      "\n",
      "\n",
      "'Excuse me if I ask you in a window\n",
      "\n",
      "That happens to be broken, Davis said.\n",
      "\n",
      "'The outside doors as yet have held against us.\n",
      "\n",
      "I want to introduce you to the people\n",
      "\n",
      "Who used to live here. They were Robinsons.\n",
      "\n",
      "You must have heard of Clara Robinson,\n",
      "\n",
      "The poetess who wrote the book of verses\n",
      "\n",
      "And had it published. It was all about\n",
      "\n",
      "The posies on her inner windowsill,\n",
      "\n",
      "And the birds on her outer windowsill,\n",
      "\n",
      "And how she tended both, or had them tended:\n",
      "\n",
      "She never tended anything herself.\n",
      "\n",
      "She was 'shut in' for life. She lived her whole\n",
      "\n",
      "Life long in bed, and wrote her things in bed.\n",
      "\n",
      "I'll show You how she had her sills extended\n",
      "\n",
      "To entertain the birds and hold the flowers.\n",
      "\n",
      "Our business first's up attic with her books.'\n",
      "\n",
      "\n",
      "\n",
      "We trod uncomfortably on crunching glass\n",
      "\n",
      "Through a house stripped of everything\n",
      "\n",
      "Except, it seemed, the poetess's poems.\n",
      "\n",
      "Books, I should say!- if books are what is needed.\n",
      "\n",
      "A whole edition in a packing case\n",
      "\n",
      "That, overflowing like a horn of plenty,\n",
      "\n",
      "Or like the poetess's heart of love,\n",
      "\n",
      "Had spilled them near the window, toward the light\n",
      "\n",
      "Where driven rain had wet and swollen them.\n",
      "\n",
      "Enough to stock a village library-\n",
      "\n",
      "Unfortunately all of one kind, though.\n",
      "\n",
      "They bad been brought home from some publisher\n",
      "\n",
      "And taken thus into the family.\n",
      "\n",
      "Boys and bad hunters had known what to do\n",
      "\n",
      "With stone and lead to unprotected glass:\n",
      "\n",
      "Shatter it inward on the unswept floors.\n",
      "\n",
      "How had the tender verse escaped their outrage?\n",
      "\n",
      "By being invisible for what it was,\n",
      "\n",
      "Or else by some remoteness that defied them\n",
      "\n",
      "To find out what to do to hurt a poem.\n",
      "\n",
      "Yet oh! the tempting flatness of a book,\n",
      "\n",
      "To send it sailing out the attic window\n",
      "\n",
      "Till it caught wind and, opening out its covers,\n",
      "\n",
      "Tried to improve on sailing like a tile\n",
      "\n",
      "By flying like a bird (silent in flight,\n",
      "\n",
      "But all the burden of its body song),\n",
      "\n",
      "Only to tumble like a stricken bird,\n",
      "\n",
      "And lie in stones and bushes unretrieved.\n",
      "\n",
      "Books were not thrown irreverently about.\n",
      "\n",
      "They simply lay where someone now and then,\n",
      "\n",
      "Having tried one, had dropped it at his feet\n",
      "\n",
      "And left it lying where it fell rejected.\n",
      "\n",
      "Here were all those the poetess's life\n",
      "\n",
      "Had been too short to sell or give away.\n",
      "\n",
      "\n",
      "\n",
      "'Take one,' Old Davis bade me graciously.\n",
      "\n",
      "\n",
      "\n",
      "'Why not take two or three?'\n",
      "\n",
      "\n",
      "\n",
      "'Take all you want.'\n",
      "\n",
      "Good-looking books like that.' He picked one fresh\n",
      "\n",
      "In virgin wrapper from deep in the box,\n",
      "\n",
      "And stroked it with a horny-handed kindness.\n",
      "\n",
      "He read in one and I read in another,\n",
      "\n",
      "Both either looking for or finding something.\n",
      "\n",
      "\n",
      "\n",
      "The attic wasps went missing by like bullets.\n",
      "\n",
      "\n",
      "\n",
      "I was soon satisfied for the time being.\n",
      "\n",
      "\n",
      "\n",
      "All the way home I kept remembering\n",
      "\n",
      "The small book in my pocket. It was there.\n",
      "\n",
      "The poetess had sighed, I knew, in heaven\n",
      "\n",
      "At having eased her heart of one more copy-\n",
      "\n",
      "Legitimately. My demand upon her,\n",
      "\n",
      "Though slight, was a demand. She felt the tug.\n",
      "\n",
      "In time she would be rid of all her books.\n",
      "\n",
      "\n",
      "\n",
      "I stay;\n",
      "\n",
      "But it isn't as if\n",
      "\n",
      "There wasn't always Hudson's Bay\n",
      "\n",
      "And the fur trade,\n",
      "\n",
      "A small skiff\n",
      "\n",
      "And a paddle blade.\n",
      "\n",
      "\n",
      "\n",
      "I can just see my tent pegged,\n",
      "\n",
      "And me on the floor,\n",
      "\n",
      "Cross-legged,\n",
      "\n",
      "And a trapper looking in at the door\n",
      "\n",
      "With furs to sell.\n",
      "\n",
      "\n",
      "\n",
      "His name's Joe,\n",
      "\n",
      "Alias John,\n",
      "\n",
      "And between what he doesn't know\n",
      "\n",
      "And won't tell\n",
      "\n",
      "About where Henry Hudson's gone,\n",
      "\n",
      "I can't say he's much help;\n",
      "\n",
      "But we get on.\n",
      "\n",
      "\n",
      "\n",
      "The seal yelp\n",
      "\n",
      "On an ice cake.\n",
      "\n",
      "It's not men by some mistake?\n",
      "\n",
      "No,\n",
      "\n",
      "There's not a soul\n",
      "\n",
      "For a windbreak\n",
      "\n",
      "Between me and the North Pole—\n",
      "\n",
      "\n",
      "\n",
      "Except always John-Joe,\n",
      "\n",
      "My French Indian Esquimaux,\n",
      "\n",
      "And he's off setting traps\n",
      "\n",
      "In one himself perhaps.\n",
      "\n",
      "\n",
      "\n",
      "Give a headshake\n",
      "\n",
      "Over so much bay\n",
      "\n",
      "Thrown away\n",
      "\n",
      "In snow and mist\n",
      "\n",
      "That doesn't exist,\n",
      "\n",
      "\n",
      "\n",
      "I was going to say,\n",
      "\n",
      "For God, man, or beast's sake,\n",
      "\n",
      "Yet does perhaps for all three.\n",
      "\n",
      "\n",
      "\n",
      "Don't ask Joe\n",
      "\n",
      "What it is to him.\n",
      "\n",
      "It's sometimes dim\n",
      "\n",
      "What it is to me,\n",
      "\n",
      "Unless it be\n",
      "\n",
      "It's the old captain's dark fate\n",
      "\n",
      "Who failed to find or force a strait\n",
      "\n",
      "In its two-thousand-mile coast;\n",
      "\n",
      "And his crew left him where be failed,\n",
      "\n",
      "And nothing came of all be sailed.\n",
      "\n",
      "\n",
      "\n",
      "It's to say, 'You and I—'\n",
      "\n",
      "To such a ghost—\n",
      "\n",
      "You and I\n",
      "\n",
      "Off here\n",
      "\n",
      "With the dead race of the Great Auk!'\n",
      "\n",
      "And, 'Better defeat almost,\n",
      "\n",
      "If seen clear,\n",
      "\n",
      "Than life's victories of doubt\n",
      "\n",
      "That need endless talk-talk\n",
      "\n",
      "To make them out.' \n",
      "\n",
      "\n",
      "\n",
      "I staid the night for shelter at a farm\n",
      "\n",
      "Behind the mountains, with a mother and son,\n",
      "\n",
      "Two old-believers. They did all the talking.\n",
      "\n",
      "\n",
      "\n",
      "MOTHER Folks think a witch who has familiar spirits\n",
      "\n",
      "She could call up to pass a winter evening,\n",
      "\n",
      "But won't, should be burned at the stake or something.\n",
      "\n",
      "Summoning spirits isn't 'Button, button,\n",
      "\n",
      "Who's got the button,' I would have them know.\n",
      "\n",
      "\n",
      "\n",
      "SON: Mother can make a common table rear\n",
      "\n",
      "And kick with two legs like an army mule.\n",
      "\n",
      "\n",
      "\n",
      "MOTHER: And when I've done it, what good have I\n",
      "\n",
      "done?\n",
      "\n",
      "Rather than tip a table for you, let me\n",
      "\n",
      "Tell you what Ralle the Sioux Control once told me.\n",
      "\n",
      "He said the dead had souls, but when I asked him\n",
      "\n",
      "How could that be - I thought the dead were souls,\n",
      "\n",
      "He broke my trance. Don't that make you suspicious\n",
      "\n",
      "That there's something the dead are keeping back?\n",
      "\n",
      "Yes, there's something the dead are keeping back.\n",
      "\n",
      "\n",
      "\n",
      "SON: You wouldn't want to tell him what we have\n",
      "\n",
      "Up attic, mother?\n",
      "\n",
      "\n",
      "\n",
      "MOTHER: Bones - a skeleton.\n",
      "\n",
      "\n",
      "\n",
      "SON: But the headboard of mother's bed is pushed\n",
      "\n",
      "Against the' attic door: the door is nailed.\n",
      "\n",
      "It's harmless. Mother hears it in the night\n",
      "\n",
      "Halting perplexed behind the barrier\n",
      "\n",
      "Of door and headboard. Where it wants to get\n",
      "\n",
      "Is back into the cellar where it came from.\n",
      "\n",
      "\n",
      "\n",
      "MOTHER: We'll never let them, will we, son! We'll\n",
      "\n",
      "never !\n",
      "\n",
      "\n",
      "\n",
      "SON: It left the cellar forty years ago\n",
      "\n",
      "And carried itself like a pile of dishes\n",
      "\n",
      "Up one flight from the cellar to the kitchen,\n",
      "\n",
      "Another from the kitchen to the bedroom,\n",
      "\n",
      "Another from the bedroom to the attic,\n",
      "\n",
      "Right past both father and mother, and neither stopped\n",
      "\n",
      "it.\n",
      "\n",
      "Father had gone upstairs; mother was downstairs.\n",
      "\n",
      "I was a baby: I don't know where I was.\n",
      "\n",
      "\n",
      "\n",
      "MOTHER: The only fault my husband found with me - \n",
      "\n",
      "I went to sleep before I went to bed,\n",
      "\n",
      "Especially in winter when the bed\n",
      "\n",
      "Might just as well be ice and the clothes snow.\n",
      "\n",
      "The night the bones came up the cellar-stairs\n",
      "\n",
      "Toffile had gone to bed alone and left me,\n",
      "\n",
      "But left an open door to cool the room off\n",
      "\n",
      "So as to sort of turn me out of it.\n",
      "\n",
      "I was just coming to myself enough\n",
      "\n",
      "To wonder where the cold was coming from,\n",
      "\n",
      "When I heard Toffile upstairs in the bedroom\n",
      "\n",
      "And thought I heard him downstairs in the cellar.\n",
      "\n",
      "The board we had laid down to walk dry-shod on\n",
      "\n",
      "When there was water in the cellar in spring\n",
      "\n",
      "Struck the hard cellar bottom. And then someone\n",
      "\n",
      "Began the stairs, two footsteps for each step,\n",
      "\n",
      "The way a man with one leg and a crutch,\n",
      "\n",
      "Or a little child, comes up. It wasn't Toffile:\n",
      "\n",
      "It wasn't anyone who could be there.\n",
      "\n",
      "The bulkhead double-doors were double-locked\n",
      "\n",
      "And swollen tight and buried under snow.\n",
      "\n",
      "The cellar windows were banked up with sawdust\n",
      "\n",
      "And swollen tight and buried under snow.\n",
      "\n",
      "It was the bones. I knew them - and good reason.\n",
      "\n",
      "My first impulse was to get to the knob\n",
      "\n",
      "And hold the door. But the bones didn't try\n",
      "\n",
      "The door; they halted helpless on the landing,\n",
      "\n",
      "Waiting for things to happen in their favour.'\n",
      "\n",
      "The faintest restless rustling ran all through them.\n",
      "\n",
      "I never could have done the thing I did\n",
      "\n",
      "If the wish hadn't been too strong in me\n",
      "\n",
      "To see how they were mounted for this walk.\n",
      "\n",
      "I had a vision of them put together\n",
      "\n",
      "Not like a man, but like a chandelier.\n",
      "\n",
      "So suddenly I flung the door wide on him.\n",
      "\n",
      "A moment he stood balancing with emotion,\n",
      "\n",
      "And all but lost himself. (A tongue of fire\n",
      "\n",
      "Flashed out and licked along his upper teeth.\n",
      "\n",
      "Smoke rolled inside the sockets of his eyes.)\n",
      "\n",
      "Then he came at me with one hand outstretched,\n",
      "\n",
      "The way he did in life once; but this time\n",
      "\n",
      "I struck the hand off brittle on the floor,\n",
      "\n",
      "And fell back from him on the floor myself.\n",
      "\n",
      "The finger-pieces slid in all directions.\n",
      "\n",
      "(Where did I see one of those pieces lately?\n",
      "\n",
      "Hand me my button-box- it must be there.)\n",
      "\n",
      "I sat up on the floor and shouted, 'Toffile,\n",
      "\n",
      "It's coming up to you.' It had its choice\n",
      "\n",
      "Of the door to the cellar or the hall.\n",
      "\n",
      "It took the hall door for the novelty,\n",
      "\n",
      "And set off briskly for so slow a thing,\n",
      "\n",
      "Stillgoing every which way in the joints, though,\n",
      "\n",
      "So that it looked like lightning or a scribble,\n",
      "\n",
      ">From the slap I had just now given its hand.\n",
      "\n",
      "I listened till it almost climbed the stairs\n",
      "\n",
      ">From the hall to the only finished bedroom,\n",
      "\n",
      "Before I got up to do anything;\n",
      "\n",
      "Then ran and shouted, 'Shut the bedroom door,\n",
      "\n",
      "Toffile, for my sake!' 'Company?' he said,\n",
      "\n",
      "'Don't make me get up; I'm too warm in bed.'\n",
      "\n",
      "So lying forward weakly on the handrail\n",
      "\n",
      "I pushed myself upstairs, and in the light\n",
      "\n",
      "(The kitchen had been dark) I had to own\n",
      "\n",
      "I could see nothing. 'Toffile, I don't see it.\n",
      "\n",
      "It's with us in the room though. It's the bones.'\n",
      "\n",
      "'What bones?' 'The cellar bones- out of the grave.'\n",
      "\n",
      "That made him throw his bare legs out of bed\n",
      "\n",
      "And sit up by me and take hold of me.\n",
      "\n",
      "I wanted to put out the light and see\n",
      "\n",
      "If I could see it, or else mow the room,\n",
      "\n",
      "With our arms at the level of our knees,\n",
      "\n",
      "And bring the chalk-pile down. 'I'll tell you what-\n",
      "\n",
      "It's looking for another door to try.\n",
      "\n",
      "The uncommonly deep snow has made him think\n",
      "\n",
      "Of his old song, The Wild Colonial Boy,\n",
      "\n",
      "He always used to sing along the tote-road.\n",
      "\n",
      "He's after an open door to get out-doors.\n",
      "\n",
      "Let's trap him with an open door up attic.'\n",
      "\n",
      "Toffile agreed to that, and sure enough,\n",
      "\n",
      "Almost the moment he was given an opening,\n",
      "\n",
      "The steps began to climb the attic stairs.\n",
      "\n",
      "I heard them. Toffile didn't seem to hear them.\n",
      "\n",
      "'Quick !' I slammed to the door and held the knob.\n",
      "\n",
      "'Toffile, get nails.' I made him nail the door shut,\n",
      "\n",
      "And push the headboard of the bed against it.\n",
      "\n",
      "Then we asked was there anything\n",
      "\n",
      "Up attic that we'd ever want again.\n",
      "\n",
      "The attic was less to us than the cellar.\n",
      "\n",
      "If the bones liked the attic, let them have it.\n",
      "\n",
      "Let them stay in the attic. When they sometimes\n",
      "\n",
      "Come down the stairs at night and stand perplexed\n",
      "\n",
      "Behind the door and headboard of the bed,\n",
      "\n",
      "Brushing their chalky skull with chalky fingers,\n",
      "\n",
      "With sounds like the dry rattling of a shutter,\n",
      "\n",
      "That's what I sit up in the dark to say-\n",
      "\n",
      "To no one any more since Toffile died.\n",
      "\n",
      "2o3 Let them stay in the attic since they went there.\n",
      "\n",
      "I promised Toffile to be cruel to them\n",
      "\n",
      "For helping them be cruel once to him.\n",
      "\n",
      "\n",
      "\n",
      "SON: We think they had a grave down in the cellar.\n",
      "\n",
      "\n",
      "\n",
      "MOTHER: We know they had a grave down in the cellar.\n",
      "\n",
      "\n",
      "\n",
      "SON: We never could find out whose bones they were.\n",
      "\n",
      "\n",
      "\n",
      "MOTHER: Yes, we could too, son. Tell the truth for once.\n",
      "\n",
      "They were a man's his father killed for me.\n",
      "\n",
      "I mean a man he killed instead of me.\n",
      "\n",
      "The least I could do was to help dig their grave.\n",
      "\n",
      "We were about it one night in the cellar.\n",
      "\n",
      "Son knows the story: but 'twas not for him\n",
      "\n",
      "To tell the truth, suppose the time had come.\n",
      "\n",
      "Son looks surprised to see me end a lie\n",
      "\n",
      "We'd kept all these years between ourselves\n",
      "\n",
      "So as to have it ready for outsiders.\n",
      "\n",
      "But to-night I don't care enough to lie-\n",
      "\n",
      "I don't remember why I ever cared.\n",
      "\n",
      "Toffile, if he were here, I don't believe\n",
      "\n",
      "Could tell you why he ever cared himself-\n",
      "\n",
      "\n",
      "\n",
      "She hadn't found the finger-bone she wanted\n",
      "\n",
      "Among the buttons poured out in her lap.\n",
      "\n",
      "I verified the name next morning: Toffile.\n",
      "\n",
      "The rural letter-box said Toffile Lajway.\n",
      "\n",
      "\n",
      "\n",
      "The west was getting out of gold,\n",
      "\n",
      "The breath of air had died of cold,\n",
      "\n",
      "When shoeing home across the white,\n",
      "\n",
      "I thought I saw a bird alight.\n",
      "\n",
      "\n",
      "\n",
      "In summer when I passed the place\n",
      "\n",
      "I had to stop and lift my face;\n",
      "\n",
      "A bird with an angelic gift\n",
      "\n",
      "Was singing in it sweet and swift.\n",
      "\n",
      "\n",
      "\n",
      "No bird was singing in it now.\n",
      "\n",
      "A single leaf was on a bough,\n",
      "\n",
      "And that was all there was to see\n",
      "\n",
      "In going twice around the tree.\n",
      "\n",
      "\n",
      "\n",
      "From my advantage on a hill\n",
      "\n",
      "I judged that such a crystal chill\n",
      "\n",
      "Was only adding frost to snow\n",
      "\n",
      "As gilt to gold that wouldn't show.\n",
      "\n",
      "\n",
      "\n",
      "A brush had left a crooked stroke\n",
      "\n",
      "Of what was either cloud or smoke\n",
      "\n",
      "From north to south across the blue;\n",
      "\n",
      "A piercing little star was through.\n",
      "\n",
      "\n",
      "\n",
      "A governor it was proclaimed this time, \n",
      "\n",
      "When all who would come seeking in New Hampshire \n",
      "\n",
      "Ancestral memories might come together. \n",
      "\n",
      "And those of the name Stark gathered in Bow, \n",
      "\n",
      "A rock-strewn town where farming has fallen off, \n",
      "\n",
      "And sprout-lands flourish where the axe has gone. \n",
      "\n",
      "Someone had literally run to earth \n",
      "\n",
      "In an old cellar hole in a by-road \n",
      "\n",
      "The origin of all the family there. \n",
      "\n",
      "Thence they were sprung, so numerous a tribe \n",
      "\n",
      "That now not all the houses left in town \n",
      "\n",
      "Made shift to shelter them without the help \n",
      "\n",
      "Of here and there a tent in grove and orchard. \n",
      "\n",
      "They were at Bow, but that was not enough: \n",
      "\n",
      "Nothing would do but they must fix a day \n",
      "\n",
      "To stand together on the crater's verge \n",
      "\n",
      "That turned them on the world, and try to fathom \n",
      "\n",
      "The past and get some strangeness out of it. \n",
      "\n",
      "But rain spoiled all. The day began uncertain, \n",
      "\n",
      "With clouds low trailing and moments of rain that misted. \n",
      "\n",
      "The young folk held some hope out to each other \n",
      "\n",
      "Till well toward noon when the storm settled down \n",
      "\n",
      "With a swish in the grass. 'What if the others \n",
      "\n",
      "Are there,' they said. 'It isn't going to rain.' \n",
      "\n",
      "Only one from a farm not far away \n",
      "\n",
      "Strolled thither, not expecting he would find \n",
      "\n",
      "Anyone else, but out of idleness. \n",
      "\n",
      "One, and one other, yes, for there were two. \n",
      "\n",
      "The second round the curving hillside road \n",
      "\n",
      "Was a girl; and she halted some way off \n",
      "\n",
      "To reconnoitre, and then made up her mind \n",
      "\n",
      "At least to pass by and see who he was, \n",
      "\n",
      "And perhaps hear some word about the weather. \n",
      "\n",
      "This was some Stark she didn't know. He nodded. \n",
      "\n",
      "'No fête to-day,' he said. \n",
      "\n",
      "'It looks that way.' \n",
      "\n",
      "She swept the heavens, turning on her heel. \n",
      "\n",
      "'I only idled down.' \n",
      "\n",
      "'I idled down.' \n",
      "\n",
      "Provision there had been for just such meeting \n",
      "\n",
      "Of stranger cousins, in a family tree \n",
      "\n",
      "Drawn on a sort of passport with the branch \n",
      "\n",
      "Of the one bearing it done in detail- \n",
      "\n",
      "Some zealous one's laborious device. \n",
      "\n",
      "She made a sudden movement toward her bodice, \n",
      "\n",
      "As one who clasps her heart. They laughed together. \n",
      "\n",
      "'Stark?' he inquired. 'No matter for the proof.' \n",
      "\n",
      "'Yes, Stark. And you?' \n",
      "\n",
      "'I'm Stark.' He drew his passport. \n",
      "\n",
      "'You know we might not be and still be cousins: \n",
      "\n",
      "The town is full of Chases, Lowes, and Baileys, \n",
      "\n",
      "All claiming some priority in Starkness. \n",
      "\n",
      "My mother was a Lane, yet might have married \n",
      "\n",
      "Anyone upon earth and still her children \n",
      "\n",
      "Would have been Starks, and doubtless here to-day.' \n",
      "\n",
      "'You riddle with your genealogy \n",
      "\n",
      "Like a Viola. I don't follow you.' \n",
      "\n",
      "'I only mean my mother was a Stark \n",
      "\n",
      "Several times over, and by marrying father \n",
      "\n",
      "No more than brought us back into the name.' \n",
      "\n",
      "'One ought not to be thrown into confusion \n",
      "\n",
      "By a plain statement of relationship, \n",
      "\n",
      "But I own what you say makes my head spin. \n",
      "\n",
      "You take my card- you seem so good at such things- \n",
      "\n",
      "And see if you can reckon our cousinship. \n",
      "\n",
      "Why not take seats here on the cellar wall \n",
      "\n",
      "And dangle feet among the raspberry vines?' \n",
      "\n",
      "'Under the shelter of the family tree.' \n",
      "\n",
      "'Just so- that ought to be enough protection.' \n",
      "\n",
      "'Not from the rain. I think it's going to rain.' \n",
      "\n",
      "'It's raining.' \n",
      "\n",
      "'No, it's misting; let's be fair. \n",
      "\n",
      "Does the rain seem to you to cool the eyes?' \n",
      "\n",
      "The situation was like this: the road \n",
      "\n",
      "Bowed outward on the mountain half-way up, \n",
      "\n",
      "And disappeared and ended not far off. \n",
      "\n",
      "No one went home that way. The only house \n",
      "\n",
      "Beyond where they were was a shattered seedpod. \n",
      "\n",
      "And below roared a brook hidden in trees, \n",
      "\n",
      "The sound of which was silence for the place. \n",
      "\n",
      "This he sat listening to till she gave judgment. \n",
      "\n",
      "'On father's side, it seems, we're- let me see- - ' \n",
      "\n",
      "'Don't be too technical.- You have three cards.' \n",
      "\n",
      "'Four cards, one yours, three mine, one for each branch \n",
      "\n",
      "Of the Stark family I'm a member of.' \n",
      "\n",
      "'D'you know a person so related to herself \n",
      "\n",
      "Is supposed to be mad.' \n",
      "\n",
      "'I may be mad.' \n",
      "\n",
      "'You look so, sitting out here in the rain \n",
      "\n",
      "Studying genealogy with me \n",
      "\n",
      "You never saw before. What will we come to \n",
      "\n",
      "With all this pride of ancestry, we Yankees? \n",
      "\n",
      "I think we're all mad. Tell me why we're here \n",
      "\n",
      "Drawn into town about this cellar hole \n",
      "\n",
      "Like wild geese on a lake before a storm? \n",
      "\n",
      "What do we see in such a hole, I wonder.' \n",
      "\n",
      "'The Indians had a myth of Chicamoztoc, \n",
      "\n",
      "Which means The Seven Caves that We Came out of. \n",
      "\n",
      "This is the pit from which we Starks were digged.' \n",
      "\n",
      "'You must be learned. That's what you see in it?' \n",
      "\n",
      "'And what do you see?' \n",
      "\n",
      "'Yes, what do I see? \n",
      "\n",
      "First let me look. I see raspberry vines- - ' \n",
      "\n",
      "'Oh, if you're going to use your eyes, just hear \n",
      "\n",
      "What I see. It's a little, little boy, \n",
      "\n",
      "As pale and dim as a match flame in the sun; \n",
      "\n",
      "He's groping in the cellar after jam, \n",
      "\n",
      "He thinks it's dark and it's flooded with daylight.' \n",
      "\n",
      "'He's nothing. Listen. When I lean like this \n",
      "\n",
      "I can make out old Grandsir Stark distinctly,- \n",
      "\n",
      "With his pipe in his mouth and his brown jug- \n",
      "\n",
      "Bless you, it isn't Grandsir Stark, it's Granny, \n",
      "\n",
      "But the pipe's there and smoking and the jug. \n",
      "\n",
      "She's after cider, the old girl, she's thirsty; \n",
      "\n",
      "Here's hoping she gets her drink and gets out safely.' \n",
      "\n",
      "'Tell me about her. Does she look like me?' \n",
      "\n",
      "'She should, shouldn't she, you're so many times \n",
      "\n",
      "Over descended from her. I believe \n",
      "\n",
      "She does look like you. Stay the way you are. \n",
      "\n",
      "The nose is just the same, and so's the chin- \n",
      "\n",
      "Making allowance, making due allowance.' \n",
      "\n",
      "'You poor, dear, great, great, great, great Granny!' \n",
      "\n",
      "'See that you get her greatness right. Don't stint her.' \n",
      "\n",
      "'Yes, it's important, though you think it isn't. \n",
      "\n",
      "I won't be teased. But see how wet I am.' \n",
      "\n",
      "'Yes, you must go; we can't stay here for ever. \n",
      "\n",
      "But wait until I give you a hand up. \n",
      "\n",
      "A bead of silver water more or less \n",
      "\n",
      "Strung on your hair won't hurt your summer looks. \n",
      "\n",
      "I wanted to try something with the noise \n",
      "\n",
      "That the brook raises in the empty valley. \n",
      "\n",
      "We have seen visions- now consult the voices. \n",
      "\n",
      "Something I must have learned riding in trains \n",
      "\n",
      "When I was young. I used the roar \n",
      "\n",
      "To set the voices speaking out of it, \n",
      "\n",
      "Speaking or singing, and the band-music playing. \n",
      "\n",
      "Perhaps you have the art of what I mean. \n",
      "\n",
      "I've never listened in among the sounds \n",
      "\n",
      "That a brook makes in such a wild descent. \n",
      "\n",
      "It ought to give a purer oracle.' \n",
      "\n",
      "'It's as you throw a picture on a screen: \n",
      "\n",
      "The meaning of it all is out of you; \n",
      "\n",
      "The voices give you what you wish to hear.' \n",
      "\n",
      "'Strangely, it's anything they wish to give.' \n",
      "\n",
      "'Then I don't know. It must be strange enough. \n",
      "\n",
      "I wonder if it's not your make-believe. \n",
      "\n",
      "What do you think you're like to hear to-day?' \n",
      "\n",
      "'From the sense of our having been together- \n",
      "\n",
      "But why take time for what I'm like to hear? \n",
      "\n",
      "I'll tell you what the voices really say. \n",
      "\n",
      "You will do very well right where you are \n",
      "\n",
      "A little longer. I mustn't feel too hurried, \n",
      "\n",
      "Or I can't give myself to hear the voices.' \n",
      "\n",
      "'Is this some trance you are withdrawing into?' \n",
      "\n",
      "'You must be very still; you mustn't talk.' \n",
      "\n",
      "'I'll hardly breathe.' \n",
      "\n",
      "'The voices seem to say- - ' \n",
      "\n",
      "'I'm waiting.' \n",
      "\n",
      "'Don't! The voices seem to say: \n",
      "\n",
      "Call her Nausicaa, the unafraid \n",
      "\n",
      "Of an acquaintance made adventurously.' \n",
      "\n",
      "'I let you say that- on consideration.' \n",
      "\n",
      "'I don't see very well how you can help it. \n",
      "\n",
      "You want the truth. I speak but by the voices. \n",
      "\n",
      "You see they know I haven't had your name, \n",
      "\n",
      "Though what a name should matter between us- - ' \n",
      "\n",
      "'I shall suspect- - ' \n",
      "\n",
      "'Be good. The voices say: \n",
      "\n",
      "Call her Nausicaa, and take a timber \n",
      "\n",
      "That you shall find lies in the cellar charred \n",
      "\n",
      "Among the raspberries, and hew and shape it \n",
      "\n",
      "For a door-sill or other corner piece \n",
      "\n",
      "In a new cottage on the ancient spot. \n",
      "\n",
      "The life is not yet all gone out of it. \n",
      "\n",
      "And come and make your summer dwelling here, \n",
      "\n",
      "And perhaps she will come, still unafraid, \n",
      "\n",
      "And sit before you in the open door \n",
      "\n",
      "With flowers in her lap until they fade, \n",
      "\n",
      "But not come in across the sacred sill- - ' \n",
      "\n",
      "'I wonder where your oracle is tending. \n",
      "\n",
      "You can see that there's something wrong with it, \n",
      "\n",
      "Or it would speak in dialect. Whose voice \n",
      "\n",
      "Does it purport to speak in? Not old Grandsir's \n",
      "\n",
      "Nor Granny's, surely. Call up one of them. \n",
      "\n",
      "They have best right to be heard in this place.' \n",
      "\n",
      "'You seem so partial to our great-grandmother \n",
      "\n",
      "(Nine times removed. Correct me if I err.) \n",
      "\n",
      "You will be likely to regard as sacred \n",
      "\n",
      "Anything she may say. But let me warn you, \n",
      "\n",
      "Folks in her day were given to plain speaking. \n",
      "\n",
      "You think you'd best tempt her at such a time?' \n",
      "\n",
      "'It rests with us always to cut her off.' \n",
      "\n",
      "'Well then, it's Granny speaking: 'I dunnow! \n",
      "\n",
      "Mebbe I'm wrong to take it as I do. \n",
      "\n",
      "There ain't no names quite like the old ones though, \n",
      "\n",
      "Nor never will be to my way of thinking. \n",
      "\n",
      "One mustn't bear too hard on the new comers, \n",
      "\n",
      "But there's a dite too many of them for comfort. \n",
      "\n",
      "I should feel easier if I could see \n",
      "\n",
      "More of the salt wherewith they're to be salted. \n",
      "\n",
      "Son, you do as you're told! You take the timber- \n",
      "\n",
      "It's as sound as the day when it was cut- \n",
      "\n",
      "And begin over- - ' There, she'd better stop. \n",
      "\n",
      "You can see what is troubling Granny, though. \n",
      "\n",
      "But don't you think we sometimes make too much \n",
      "\n",
      "Of the old stock? What counts is the ideals, \n",
      "\n",
      "And those will bear some keeping still about.' \n",
      "\n",
      "'I can see we are going to be good friends.' \n",
      "\n",
      "'I like your 'going to be.' You said just now \n",
      "\n",
      "It's going to rain.' \n",
      "\n",
      "'I know, and it was raining. \n",
      "\n",
      "I let you say all that. But I must go now.' \n",
      "\n",
      "'You let me say it? on consideration? \n",
      "\n",
      "How shall we say good-bye in such a case?' \n",
      "\n",
      "'How shall we?' \n",
      "\n",
      "'Will you leave the way to me?' \n",
      "\n",
      "'No, I don't trust your eyes. You've said enough. \n",
      "\n",
      "Now give me your hand up.- Pick me that flower.' \n",
      "\n",
      "'Where shall we meet again?' \n",
      "\n",
      "'Nowhere but here \n",
      "\n",
      "Once more before we meet elsewhere.' \n",
      "\n",
      "'In rain?' \n",
      "\n",
      "'It ought to be in rain. Sometime in rain. \n",
      "\n",
      "In rain to-morrow, shall we, if it rains? \n",
      "\n",
      "But if we must, in sunshine.' So she went.\n",
      "\n",
      "\n",
      "\n",
      "Builder, in building the little house,\n",
      "\n",
      "In every way you may please yourself;\n",
      "\n",
      "But please please me in the kitchen chimney:\n",
      "\n",
      "Don't build me a chimney upon a shelf.\n",
      "\n",
      "\n",
      "\n",
      "However far you must go for bricks,\n",
      "\n",
      "Whatever they cost a-piece or a pound,\n",
      "\n",
      "But me enough for a full-length chimney,\n",
      "\n",
      "And build the chimney clear from the ground.\n",
      "\n",
      "\n",
      "\n",
      "It's not that I'm greatly afraid of fire,\n",
      "\n",
      "But I never heard of a house that throve\n",
      "\n",
      "(And I know of one that didn't thrive)\n",
      "\n",
      "Where the chimney started above the stove.\n",
      "\n",
      "\n",
      "\n",
      "And I dread the ominous stain of tar\n",
      "\n",
      "That there always is on the papered walls,\n",
      "\n",
      "And the smell of fire drowned in rain\n",
      "\n",
      "That there always is when the chimney's false.\n",
      "\n",
      "\n",
      "\n",
      "A shelf's for a clock or vase or picture,\n",
      "\n",
      "But I don't see why it should have to bear\n",
      "\n",
      "A chimney that only would serve to remind me\n",
      "\n",
      "Of castles I used to build in air.\n",
      "\n",
      "\n",
      "\n",
      "I had for my winter evening walk- \n",
      "\n",
      "No one at all with whom to talk,\n",
      "\n",
      "But I had the cottages in a row\n",
      "\n",
      "Up to their shining eyes in snow.\n",
      "\n",
      "\n",
      "\n",
      "And I thought I had the folk within:\n",
      "\n",
      "I had the sound of a violin;\n",
      "\n",
      "I had a glimpse through curtain laces\n",
      "\n",
      "Of youthful forms and youthful faces.\n",
      "\n",
      "\n",
      "\n",
      "I had such company outward bound.\n",
      "\n",
      "I went till there were no cottages found.\n",
      "\n",
      "I turned and repented, but coming back\n",
      "\n",
      "I saw no window but that was black.\n",
      "\n",
      "\n",
      "\n",
      "Over the snow my creaking feet\n",
      "\n",
      "Disturbed the slumbering village street\n",
      "\n",
      "Like profanation, by your leave,\n",
      "\n",
      "At ten o'clock of a winter eve.\n",
      "\n",
      "\n",
      "\n",
      "Inscription for a Garden Wall\n",
      "\n",
      "\n",
      "\n",
      "Winds blow the open grassy places bleak;\n",
      "\n",
      "But where this old wall burns a sunny cheek,\n",
      "\n",
      "They eddy over it too toppling weak\n",
      "\n",
      "To blow the earth or anything self-clear;\n",
      "\n",
      "Moisture and color and odor thicken here.\n",
      "\n",
      "The hours of daylight gather atmosphere. \n",
      "\n",
      "\n",
      "\n",
      "To Ridgely Torrence\n",
      "\n",
      "On Last Looking into His 'Hesperides'\n",
      "\n",
      "\n",
      "\n",
      "I often see flowers from a passing car\n",
      "\n",
      "That are gone before I can tell what they are.\n",
      "\n",
      "\n",
      "\n",
      "I want to get out of the train and go back\n",
      "\n",
      "To see what they were beside the track.\n",
      "\n",
      "\n",
      "\n",
      "I name all the flowers I am sure they weren't;\n",
      "\n",
      "Not fireweed loving where woods have burnt- \n",
      "\n",
      "\n",
      "\n",
      "Not bluebells gracing a tunnel mouth- \n",
      "\n",
      "Not lupine living on sand and drouth.\n",
      "\n",
      "\n",
      "\n",
      "Was something brushed across my mind\n",
      "\n",
      "That no one on earth will ever find?\n",
      "\n",
      "\n",
      "\n",
      "Heaven gives it glimpses only to those\n",
      "\n",
      "Not in position to look too close.\n",
      "\n",
      "\n",
      "\n",
      "Back out of all this now too much for us,\n",
      "\n",
      "Back in a time made simple by the loss\n",
      "\n",
      "Of detail, burned, dissolved, and broken off\n",
      "\n",
      "Like graveyard marble sculpture in the weather,\n",
      "\n",
      "There is a house that is no more a house\n",
      "\n",
      "Upon a farm that is no more a farm\n",
      "\n",
      "And in a town that is no more a town.\n",
      "\n",
      "The road there, if you'll let a guide direct you\n",
      "\n",
      "Who only has at heart your getting lost,\n",
      "\n",
      "May seem as if it should have been a quarry -\n",
      "\n",
      "Great monolithic knees the former town\n",
      "\n",
      "Long since gave up pretense of keeping covered.\n",
      "\n",
      "And there's a story in a book about it:\n",
      "\n",
      "Besides the wear of iron wagon wheels\n",
      "\n",
      "The ledges show lines ruled southeast-northwest,\n",
      "\n",
      "The chisel work of an enormous Glacier\n",
      "\n",
      "That braced his feet against the Arctic Pole.\n",
      "\n",
      "You must not mind a certain coolness from him\n",
      "\n",
      "Still said to haunt this side of Panther Mountain.\n",
      "\n",
      "Nor need you mind the serial ordeal\n",
      "\n",
      "Of being watched from forty cellar holes\n",
      "\n",
      "As if by eye pairs out of forty firkins.\n",
      "\n",
      "As for the woods' excitement over you\n",
      "\n",
      "That sends light rustle rushes to their leaves,\n",
      "\n",
      "Charge that to upstart inexperience.\n",
      "\n",
      "Where were they all not twenty years ago?\n",
      "\n",
      "They think too much of having shaded out\n",
      "\n",
      "A few old pecker-fretted apple trees.\n",
      "\n",
      "Make yourself up a cheering song of how\n",
      "\n",
      "Someone's road home from work this once was,\n",
      "\n",
      "Who may be just ahead of you on foot\n",
      "\n",
      "Or creaking with a buggy load of grain.\n",
      "\n",
      "The height of the adventure is the height\n",
      "\n",
      "Of country where two village cultures faded\n",
      "\n",
      "Into each other. Both of them are lost.\n",
      "\n",
      "And if you're lost enough to find yourself\n",
      "\n",
      "By now, pull in your ladder road behind you\n",
      "\n",
      "And put a sign up CLOSED to all but me.\n",
      "\n",
      "Then make yourself at home. The only field\n",
      "\n",
      "Now left's no bigger than a harness gall.\n",
      "\n",
      "First there's the children's house of make-believe,\n",
      "\n",
      "Some shattered dishes underneath a pine,\n",
      "\n",
      "The playthings in the playhouse of the children.\n",
      "\n",
      "Weep for what little things could make them glad.\n",
      "\n",
      "Then for the house that is no more a house,\n",
      "\n",
      "But only a belilaced cellar hole,\n",
      "\n",
      "Now slowly closing like a dent in dough.\n",
      "\n",
      "This was no playhouse but a house in earnest.\n",
      "\n",
      "Your destination and your destiny's\n",
      "\n",
      "A brook that was the water of the house,\n",
      "\n",
      "Cold as a spring as yet so near its source,\n",
      "\n",
      "Too lofty and original to rage.\n",
      "\n",
      "(We know the valley streams that when aroused\n",
      "\n",
      "Will leave their tatters hung on barb and thorn.)\n",
      "\n",
      "I have kept hidden in the instep arch\n",
      "\n",
      "Of an old cedar at the waterside\n",
      "\n",
      "A broken drinking goblet like the Grail\n",
      "\n",
      "Under a spell so the wrong ones can't find it,\n",
      "\n",
      "So can't get saved, as Saint Mark says they mustn't.\n",
      "\n",
      "(I stole the goblet from the children's playhouse.)\n",
      "\n",
      "Here are your waters and your watering place.\n",
      "\n",
      "Drink and be whole again beyond confusion.\n",
      "\n",
      "\n",
      "\n",
      "I WALKED down alone Sunday after church\n",
      "\n",
      "To the place where John has been cutting trees\n",
      "\n",
      "To see for myself about the birch\n",
      "\n",
      "He said I could have to bush my peas.\n",
      "\n",
      "\n",
      "\n",
      "The sun in the new-cut narrow gap\n",
      "\n",
      "Was hot enough for the first of May,\n",
      "\n",
      "And stifling hot with the odor of sap\n",
      "\n",
      "From stumps still bleeding their life away.\n",
      "\n",
      "\n",
      "\n",
      "The frogs that were peeping a thousand shrill\n",
      "\n",
      "Wherever the ground was low and wet,\n",
      "\n",
      "The minute they heard my step went still\n",
      "\n",
      "To watch me and see what I came to get.\n",
      "\n",
      "\n",
      "\n",
      "Birch boughs enough piled everywhere!—\n",
      "\n",
      "All fresh and sound from the recent axe.\n",
      "\n",
      "Time someone came with cart and pair\n",
      "\n",
      "And got them off the wild flower's backs.\n",
      "\n",
      "\n",
      "\n",
      "They might be good for garden things\n",
      "\n",
      "To curl a little finger round,\n",
      "\n",
      "The same as you seize cat's-cradle strings,\n",
      "\n",
      "And lift themselves up off the ground.\n",
      "\n",
      "\n",
      "\n",
      "Small good to anything growing wild,\n",
      "\n",
      "They were crooking many a trillium\n",
      "\n",
      "That had budded before the boughs were piled\n",
      "\n",
      "And since it was coming up had to come.\n",
      "\n",
      "\n",
      "\n",
      "Over back where they speak of life as staying\n",
      "\n",
      "('You couldn't call it living, for it ain't'),\n",
      "\n",
      "There was an old, old house renewed with paint,\n",
      "\n",
      "And in it a piano loudly playing.\n",
      "\n",
      "\n",
      "\n",
      "Out in the plowed ground in the cold a digger,\n",
      "\n",
      "Among unearthed potatoes standing still,\n",
      "\n",
      "Was counting winter dinners, one a hill,\n",
      "\n",
      "With half an ear to the piano's vigor.\n",
      "\n",
      "\n",
      "\n",
      "All that piano and new paint back there,\n",
      "\n",
      "Was it some money suddenly come into?\n",
      "\n",
      "Or some extravagance young love had been to?\n",
      "\n",
      "Or old love on an impulse not to care- \n",
      "\n",
      "\n",
      "\n",
      "Not to sink under being man and wife,\n",
      "\n",
      "But get some color and music out of life?\n",
      "\n",
      "\n",
      "\n",
      "It was long I lay\n",
      "\n",
      "Awake that night\n",
      "\n",
      "Wishing that night\n",
      "\n",
      "Would name the hour\n",
      "\n",
      "And tell me whether\n",
      "\n",
      "To call it day\n",
      "\n",
      "(Though not yet light)\n",
      "\n",
      "And give up sleep.\n",
      "\n",
      "The snow fell deep\n",
      "\n",
      "With the hiss of spray;\n",
      "\n",
      "Two winds would meet,\n",
      "\n",
      "One down one street,\n",
      "\n",
      "One down another,\n",
      "\n",
      "And fight in a smother\n",
      "\n",
      "Of dust and feather.\n",
      "\n",
      "I could not say,\n",
      "\n",
      "But feared the cold\n",
      "\n",
      "Had checked the pace\n",
      "\n",
      "Of the tower clock\n",
      "\n",
      "By tying together\n",
      "\n",
      "Its hands of gold\n",
      "\n",
      "Before its face.\n",
      "\n",
      "\n",
      "\n",
      "Then cane one knock!\n",
      "\n",
      "A note unruffled\n",
      "\n",
      "Of earthly weather,\n",
      "\n",
      "Though strange and muffled.\n",
      "\n",
      "The tower said, 'One!'\n",
      "\n",
      "And then a steeple.\n",
      "\n",
      "They spoke to themselves\n",
      "\n",
      "And such few people\n",
      "\n",
      "As winds might rouse\n",
      "\n",
      "From sleeping warm\n",
      "\n",
      "(But not unhouse).\n",
      "\n",
      "They left the storm\n",
      "\n",
      "That struck en masse\n",
      "\n",
      "My window glass\n",
      "\n",
      "Like a beaded fur.\n",
      "\n",
      "In that grave One\n",
      "\n",
      "They spoke of the sun\n",
      "\n",
      "And moon and stars,\n",
      "\n",
      "Saturn and Mars\n",
      "\n",
      "And Jupiter.\n",
      "\n",
      "Still more unfettered,\n",
      "\n",
      "They left the named\n",
      "\n",
      "And spoke of the lettered,\n",
      "\n",
      "The sigmas and taus\n",
      "\n",
      "Of constellations.\n",
      "\n",
      "They filled their throats\n",
      "\n",
      "With the furthest bodies\n",
      "\n",
      "To which man sends his\n",
      "\n",
      "Speculation,\n",
      "\n",
      "Beyond which God is;\n",
      "\n",
      "The cosmic motes\n",
      "\n",
      "Of yawning lenses.\n",
      "\n",
      "Their solemn peals\n",
      "\n",
      "Were not their own:\n",
      "\n",
      "They spoke for the clock\n",
      "\n",
      "With whose vast wheels\n",
      "\n",
      "Theirs interlock.\n",
      "\n",
      "In that grave word\n",
      "\n",
      "Uttered alone\n",
      "\n",
      "The utmost star\n",
      "\n",
      "Trembled and stirred,\n",
      "\n",
      "Though set so far\n",
      "\n",
      "Its whirling frenzies\n",
      "\n",
      "Appear like standing\n",
      "\n",
      "in one self station.\n",
      "\n",
      "It has not ranged,\n",
      "\n",
      "And save for the wonder \n",
      "\n",
      "Of once expanding\n",
      "\n",
      "To be a nova,\n",
      "\n",
      "It has not changed\n",
      "\n",
      "To the eye of man\n",
      "\n",
      "On planets over\n",
      "\n",
      "Around and under\n",
      "\n",
      "It in creation\n",
      "\n",
      "Since man began\n",
      "\n",
      "To drag down man\n",
      "\n",
      "And nation nation.\n",
      "\n",
      "\n",
      "\n",
      "The surest thing there is is we are riders,\n",
      "\n",
      "And though none too successful at it, guiders,\n",
      "\n",
      "Through everything presented, land and tide\n",
      "\n",
      "And now the very air, of what we ride.\n",
      "\n",
      "\n",
      "\n",
      "What is this talked-of mystery of birth\n",
      "\n",
      "But being mounted bareback on the earth?\n",
      "\n",
      "We can just see the infant up astride,\n",
      "\n",
      "His small fist buried in the bushy hide.\n",
      "\n",
      "\n",
      "\n",
      "There is our wildest mount- a headless horse.\n",
      "\n",
      "But though it runs unbridled off its course,\n",
      "\n",
      "And all our blandishments would seem defied,\n",
      "\n",
      "We have ideas yet that we haven't tried.\n",
      "\n",
      "\n",
      "\n",
      "I let myself in at the kitchen door.\n",
      "\n",
      "'It's you,' she said. 'I can't get up. Forgive me \n",
      "\n",
      "Not answering your knock. I can no more \n",
      "\n",
      "Let people in than I can keep them out. \n",
      "\n",
      "I'm getting too old for my size, I tell them. \n",
      "\n",
      "My fingers are about all I've the use of \n",
      "\n",
      "So's to take any comfort. I can sew: \n",
      "\n",
      "I help out with this beadwork what I can.' \n",
      "\n",
      "'That's a smart pair of pumps you're beading there. \n",
      "\n",
      "Who are they for?' \n",
      "\n",
      "'You mean?- oh, for some miss. \n",
      "\n",
      "I can't keep track of other people's daughters. \n",
      "\n",
      "Lord, if I were to dream of everyone \n",
      "\n",
      "Whose shoes I primped to dance in!' \n",
      "\n",
      "'And where's John?' \n",
      "\n",
      "'Haven't you seen him? Strange what set you off \n",
      "\n",
      "To come to his house when he's gone to yours. \n",
      "\n",
      "You can't have passed each other. I know what: \n",
      "\n",
      "He must have changed his mind and gone to Garlands. \n",
      "\n",
      "He won't be long in that case. You can wait. \n",
      "\n",
      "Though what good you can be, or anyone- \n",
      "\n",
      "It's gone so far. You've heard? Estelle's run off.' \n",
      "\n",
      "'Yes, what's it all about? When did she go?' \n",
      "\n",
      "'Two weeks since.' \n",
      "\n",
      "'She's in earnest, it appears.' \n",
      "\n",
      "'I'm sure she won't come back. She's hiding somewhere. \n",
      "\n",
      "I don't know where myself. John thinks I do. \n",
      "\n",
      "He thinks I only have to say the word, \n",
      "\n",
      "And she'll come back. But, bless you, I'm her mother- \n",
      "\n",
      "I can't talk to her, and, Lord, if I could!' \n",
      "\n",
      "'It will go hard with John. What will he do? \n",
      "\n",
      "He can't find anyone to take her place.' \n",
      "\n",
      "'Oh, if you ask me that, what will he do? \n",
      "\n",
      "He gets some sort of bakeshop meals together, \n",
      "\n",
      "With me to sit and tell him everything, \n",
      "\n",
      "What's wanted and how much and where it is. \n",
      "\n",
      "But when I'm gone- of course I can't stay here: \n",
      "\n",
      "Estelle's to take me when she's settled down. \n",
      "\n",
      "He and I only hinder one another. \n",
      "\n",
      "I tell them they can't get me through the door, though: \n",
      "\n",
      "I've been built in here like a big church organ. \n",
      "\n",
      "We've been here fifteen years.' \n",
      "\n",
      "'That's a long time \n",
      "\n",
      "To live together and then pull apart. \n",
      "\n",
      "How do you see him living when you're gone? \n",
      "\n",
      "Two of you out will leave an empty house.' \n",
      "\n",
      "'I don't just see him living many years, \n",
      "\n",
      "Left here with nothing but the furniture. \n",
      "\n",
      "I hate to think of the old place when we're gone, \n",
      "\n",
      "With the brook going by below the yard, \n",
      "\n",
      "And no one here but hens blowing about. \n",
      "\n",
      "If he could sell the place, but then, he can't: \n",
      "\n",
      "No one will ever live on it again. \n",
      "\n",
      "It's too run down. This is the last of it. \n",
      "\n",
      "What I think he will do, is let things smash. \n",
      "\n",
      "He'll sort of swear the time away. He's awful! \n",
      "\n",
      "I never saw a man let family troubles \n",
      "\n",
      "Make so much difference in his man's affairs. \n",
      "\n",
      "He's just dropped everything. He's like a child. \n",
      "\n",
      "I blame his being brought up by his mother. \n",
      "\n",
      "He's got hay down that's been rained on three times. \n",
      "\n",
      "He hoed a little yesterday for me: \n",
      "\n",
      "I thought the growing things would do him good. \n",
      "\n",
      "Something went wrong. I saw him throw the hoe \n",
      "\n",
      "Sky-high with both hands. I can see it now- \n",
      "\n",
      "Come here- I'll show you- in that apple tree. \n",
      "\n",
      "That's no way for a man to do at his age: \n",
      "\n",
      "He's fifty-five, you know, if he's a day.' \n",
      "\n",
      "'Aren't you afraid of him? What's that gun for?' \n",
      "\n",
      "'Oh, that's been there for hawks since chicken-time. \n",
      "\n",
      "John Hall touch me! Not if he knows his friends. \n",
      "\n",
      "I'll say that for him, John's no threatener \n",
      "\n",
      "Like some men folk. No one's afraid of him; \n",
      "\n",
      "All is, he's made up his mind not to stand \n",
      "\n",
      "What he has got to stand.' \n",
      "\n",
      "'Where is Estelle? \n",
      "\n",
      "Couldn't one talk to her? What does she say? \n",
      "\n",
      "You say you don't know where she is.' \n",
      "\n",
      "'Nor want to! \n",
      "\n",
      "She thinks if it was bad to live with him, \n",
      "\n",
      "It must be right to leave him.' \n",
      "\n",
      "'Which is wrong!' \n",
      "\n",
      "'Yes, but he should have married her.' \n",
      "\n",
      "'I know.' \n",
      "\n",
      "'The strain's been too much for her all these years: \n",
      "\n",
      "I can't explain it any other way. \n",
      "\n",
      "It's different with a man, at least with John: \n",
      "\n",
      "He knows he's kinder than the run of men. \n",
      "\n",
      "Better than married ought to be as good \n",
      "\n",
      "As married- that's what he has always said. \n",
      "\n",
      "I know the way he's felt- but all the same!' \n",
      "\n",
      "'I wonder why he doesn't marry her \n",
      "\n",
      "And end it.' \n",
      "\n",
      "'Too late now: she wouldn't have him. \n",
      "\n",
      "He's given her time to think of something else. \n",
      "\n",
      "That's his mistake. The dear knows my interest \n",
      "\n",
      "Has been to keep the thing from breaking up. \n",
      "\n",
      "This is a good home: I don't ask for better. \n",
      "\n",
      "But when I've said, 'Why shouldn't they be married,' \n",
      "\n",
      "He'd say, 'Why should they?' no more words than that.' \n",
      "\n",
      "'And after all why should they? John's been fair \n",
      "\n",
      "I take it. What was his was always hers. \n",
      "\n",
      "There was no quarrel about property.' \n",
      "\n",
      "'Reason enough, there was no property. \n",
      "\n",
      "A friend or two as good as own the farm, \n",
      "\n",
      "Such as it is. It isn't worth the mortgage.' \n",
      "\n",
      "'I mean Estelle has always held the purse.' \n",
      "\n",
      "'The rights of that are harder to get at. \n",
      "\n",
      "I guess Estelle and I have filled the purse. \n",
      "\n",
      "'Twas we let him have money, not he us. \n",
      "\n",
      "John's a bad farmer. I'm not blaming him. \n",
      "\n",
      "Take it year in, year out, he doesn't make much. \n",
      "\n",
      "We came here for a home for me, you know, \n",
      "\n",
      "Estelle to do the housework for the board \n",
      "\n",
      "Of both of us. But look how it turns out: \n",
      "\n",
      "She seems to have the housework, and besides, \n",
      "\n",
      "Half of the outdoor work, though as for that, \n",
      "\n",
      "He'd say she does it more because she likes it. \n",
      "\n",
      "You see our pretty things are all outdoors. \n",
      "\n",
      "Our hens and cows and pigs are always better \n",
      "\n",
      "Than folks like us have any business with. \n",
      "\n",
      "Farmers around twice as well off as we \n",
      "\n",
      "Haven't as good. They don't go with the farm. \n",
      "\n",
      "One thing you can't help liking about John, \n",
      "\n",
      "He's fond of nice things- too fond, some would say. \n",
      "\n",
      "But Estelle don't complain: she's like him there. \n",
      "\n",
      "She wants our hens to be the best there are. \n",
      "\n",
      "You never saw this room before a show, \n",
      "\n",
      "Full of lank, shivery, half-drowned birds \n",
      "\n",
      "In separate coops, having their plumage done. \n",
      "\n",
      "The smell of the wet feathers in the heat! \n",
      "\n",
      "You spoke of John's not being safe to stay with. \n",
      "\n",
      "You don't know what a gentle lot we are: \n",
      "\n",
      "We wouldn't hurt a hen! You ought to see us \n",
      "\n",
      "Moving a flock of hens from place to place. \n",
      "\n",
      "We're not allowed to take them upside down, \n",
      "\n",
      "All we can hold together by the legs. \n",
      "\n",
      "Two at a time's the rule, one on each arm, \n",
      "\n",
      "No matter how far and how many times \n",
      "\n",
      "We have to go.' \n",
      "\n",
      "'You mean that's John's idea.' \n",
      "\n",
      "'And we live up to it; or I don't know \n",
      "\n",
      "What childishness he wouldn't give way to. \n",
      "\n",
      "He manages to keep the upper hand \n",
      "\n",
      "On his own farm. He's boss. But as to hens: \n",
      "\n",
      "We fence our flowers in and the hens range. \n",
      "\n",
      "Nothing's too good for them. We say it pays. \n",
      "\n",
      "John likes to tell the offers he has had, \n",
      "\n",
      "Twenty for this cock, twenty-five for that. \n",
      "\n",
      "He never takes the money. If they're worth \n",
      "\n",
      "That much to sell, they're worth as much to keep. \n",
      "\n",
      "Bless you, it's all expense, though. Reach me down \n",
      "\n",
      "The little tin box on the cupboard shelf, \n",
      "\n",
      "The upper shelf, the tin box. That's the one. \n",
      "\n",
      "I'll show you. Here you are.' \n",
      "\n",
      "'What's this?' \n",
      "\n",
      "'A bill- \n",
      "\n",
      "For fifty dollars for one Langshang cock- \n",
      "\n",
      "Receipted. And the cock is in the yard.' \n",
      "\n",
      "'Not in a glass case, then?' \n",
      "\n",
      "'He'd need a tall one: \n",
      "\n",
      "He can eat off a barrel from the ground. \n",
      "\n",
      "He's been in a glass case, as you may say, \n",
      "\n",
      "The Crystal Palace, London. He's imported. \n",
      "\n",
      "John bought him, and we paid the bill with beads- \n",
      "\n",
      "Wampum, I call it. Mind, we don't complain. \n",
      "\n",
      "But you see, don't you, we take care of him.' \n",
      "\n",
      "'And like it, too. It makes it all the worse.' \n",
      "\n",
      "'It seems as if. And that's not all: he's helpless \n",
      "\n",
      "In ways that I can hardly tell you of. \n",
      "\n",
      "Sometimes he gets possessed to keep accounts \n",
      "\n",
      "To see where all the money goes so fast. \n",
      "\n",
      "You know how men will be ridiculous. \n",
      "\n",
      "But it's just fun the way he gets bedeviled- \n",
      "\n",
      "If he's untidy now, what will he be- - ? \n",
      "\n",
      "'It makes it all the worse. You must be blind.' \n",
      "\n",
      "'Estelle's the one. You needn't talk to me.' \n",
      "\n",
      "'Can't you and I get to the root of it? \n",
      "\n",
      "What's the real trouble? What will satisfy her?' \n",
      "\n",
      "'It's as I say: she's turned from him, that's all.' \n",
      "\n",
      "'But why, when she's well off? Is it the neighbours, \n",
      "\n",
      "Being cut off from friends?' \n",
      "\n",
      "'We have our friends. \n",
      "\n",
      "That isn't it. Folks aren't afraid of us.' \n",
      "\n",
      "'She's let it worry her. You stood the strain, \n",
      "\n",
      "And you're her mother.' \n",
      "\n",
      "'But I didn't always. \n",
      "\n",
      "I didn't relish it along at first. \n",
      "\n",
      "But I got wonted to it. And besides- \n",
      "\n",
      "John said I was too old to have grandchildren. \n",
      "\n",
      "But what's the use of talking when it's done? \n",
      "\n",
      "She won't come back- it's worse than that- she can't.' \n",
      "\n",
      "'Why do you speak like that? What do you know? \n",
      "\n",
      "What do you mean?- she's done harm to herself?' \n",
      "\n",
      "'I mean she's married- married someone else.' \n",
      "\n",
      "'Oho, oho!' \n",
      "\n",
      "'You don't believe me.' \n",
      "\n",
      "'Yes, I do, \n",
      "\n",
      "Only too well. I knew there must be something! \n",
      "\n",
      "So that was what was back. She's bad, that's all!' \n",
      "\n",
      "'Bad to get married when she had the chance?' \n",
      "\n",
      "'Nonsense! See what's she done! But who, who- - ' \n",
      "\n",
      "'Who'd marry her straight out of such a mess? \n",
      "\n",
      "Say it right out- no matter for her mother. \n",
      "\n",
      "The man was found. I'd better name no names. \n",
      "\n",
      "John himself won't imagine who he is.' \n",
      "\n",
      "'Then it's all up. I think I'll get away. \n",
      "\n",
      "You'll be expecting John. I pity Estelle; \n",
      "\n",
      "I suppose she deserves some pity, too. \n",
      "\n",
      "You ought to have the kitchen to yourself \n",
      "\n",
      "To break it to him. You may have the job.' \n",
      "\n",
      "'You needn't think you're going to get away. \n",
      "\n",
      "John's almost here. I've had my eye on someone \n",
      "\n",
      "Coming down Ryan's Hill. I thought 'twas him. \n",
      "\n",
      "Here he is now. This box! Put it away. \n",
      "\n",
      "And this bill.' \n",
      "\n",
      "'What's the hurry? He'll unhitch.' \n",
      "\n",
      "'No, he won't, either. He'll just drop the reins \n",
      "\n",
      "And turn Doll out to pasture, rig and all. \n",
      "\n",
      "She won't get far before the wheels hang up \n",
      "\n",
      "On something- there's no harm. See, there he is! \n",
      "\n",
      "My, but he looks as if he must have heard!' \n",
      "\n",
      "John threw the door wide but he didn't enter.\n",
      "\n",
      "'How are you, neighbour? Just the man I'm after. \n",
      "\n",
      "Isn't it Hell,' he said. 'I want to know. \n",
      "\n",
      "Come out here if you want to hear me talk. \n",
      "\n",
      "I'll talk to you, old woman, afterward. \n",
      "\n",
      "I've got some news that maybe isn't news. \n",
      "\n",
      "What are they trying to do to me, these two?' \n",
      "\n",
      "'Do go along with him and stop his shouting.' \n",
      "\n",
      "She raised her voice against the closing door:\n",
      "\n",
      "'Who wants to hear your news, you- dreadful fool?'\n",
      "\n",
      "\n",
      "\n",
      "A winter garden in an alder swamp,\n",
      "\n",
      "Where conies now come out to sun and romp,\n",
      "\n",
      "As near a paradise as it can be\n",
      "\n",
      "And not melt snow or start a dormant tree.\n",
      "\n",
      "\n",
      "\n",
      "It lifts existence on a plane of snow\n",
      "\n",
      "One level higher than the earth below,\n",
      "\n",
      "One level nearer heaven overhead,\n",
      "\n",
      "And last year's berries shining scarlet red.\n",
      "\n",
      "\n",
      "\n",
      "It lifts a gaunt luxuriating beast\n",
      "\n",
      "Where he can stretch and hold his highest feat\n",
      "\n",
      "On some wild apple tree's young tender bark,\n",
      "\n",
      "What well may prove the year's high girdle mark.\n",
      "\n",
      "\n",
      "\n",
      "So near to paradise all pairing ends:\n",
      "\n",
      "Here loveless birds now flock as winter friends,\n",
      "\n",
      "Content with bud-inspecting. They presume\n",
      "\n",
      "To say which buds are leaf and which are bloom.\n",
      "\n",
      "\n",
      "\n",
      "A feather-hammer gives a double knock.\n",
      "\n",
      "This Eden day is done at two o'clock.\n",
      "\n",
      "An hour of winter day might seem too short\n",
      "\n",
      "To make it worth life's while to wake and sport.\n"
     ]
    }
   ],
   "source": [
    "with open('Robert_Frost.txt') as poem:\n",
    "    for line in poem:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating  Inputs and Targets from the Poem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a method similar to teacher forcing in seq2seq decoder. Here the target is shifted by a seqence length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "\n",
    "for line in open('Robert_Frost.txt'):\n",
    "    \n",
    "    line = line.rstrip()\n",
    "    \n",
    "    if not line:\n",
    "        continue\n",
    "            \n",
    "    input_line = '<sos> ' + line  # <sos> is start of sentence tocken \n",
    "    target_line = line + ' <eos>' # <eos> is end of sentence tocken \n",
    "    \n",
    "    input_texts.append(input_line)\n",
    "    target_texts.append(target_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = input_texts + target_texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if everythig is loaded correctly\n",
    "\n",
    "if len(all_lines) == 0:\n",
    "    print('Empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using '' as filter so that it doesn't filter out our sos and eos tockens which contain special characters\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE,filters= '') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "target_sequences = tokenizer.texts_to_sequences(target_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max seq length in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length_in_data = max(len(seq) for seq in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Seq lenght in data: 12\n"
     ]
    }
   ],
   "source": [
    "print('Max Seq lenght in data:', max_sequence_length_in_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word -> integer mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3056\n"
     ]
    }
   ],
   "source": [
    "print(len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert('<sos>' in word2idx) # checking id <sos> is in word2idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert('<eos>' in word2idx) # checking id <eos> is in word2idx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = min(MAX_SEQUENCE_LENGTH,max_sequence_length_in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = pad_sequences(input_sequences,maxlen=max_sequence_length,padding='post')\n",
    "target_sequences = pad_sequences(target_sequences,maxlen=max_sequence_length,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input tensor: (1436, 12)\n"
     ]
    }
   ],
   "source": [
    "print('shape of input tensor:',input_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of target tensor: (1436, 12)\n"
     ]
    }
   ],
   "source": [
    "print('shape of target tensor:',target_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_VOCAB_SIZE,len(word2idx)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((num_words,EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word,i in word2idx.items():\n",
    "    \n",
    "    if i < MAX_VOCAB_SIZE:\n",
    "        \n",
    "        embedding_vector = word2vec.get(word)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            \n",
    "            embedding_matrix[i] = embedding_vector \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Matrix Shape: (3000, 50)\n"
     ]
    }
   ],
   "source": [
    "# Notice the shape of embedding matrix is (MAX_VOCAB_SIZE,EMBEDDING_DIM ), we are using 50 dim Glove vectors here instead of 100\n",
    "\n",
    "print('Embedding Matrix Shape:',embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding the targets\n",
    "\n",
    "We have to do it this way because in the previous toxic comment or mnist classification our targets were not seqences. Each input did not yield a softmax output, therfore we were able to use sparse categorical cross entropy loss. Here, each input gives us an output, this creates problem with sparse categorical cross entropy loss. Therefore, inorder to use just the categorical cross entropy loss we must one hot the targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_targets = np.zeros((len(input_sequences),max_sequence_length,num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, target_sequences in enumerate (target_sequences):\n",
    "    \n",
    "    for t,word in enumerate(target_sequences):\n",
    "        \n",
    "        if word > 0:\n",
    "            \n",
    "            one_hot_targets[i,t,word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one_hot_targets: (1436, 12, 3000)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of one_hot_targets:',one_hot_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-trained word embeddings into an Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We let the model update the weights of the pre-trained embeddings \n",
    "\n",
    "embedding_layer = Embedding(input_dim = num_words,output_dim= EMBEDDING_DIM, weights=[embedding_matrix])\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(max_sequence_length,))\n",
    "\n",
    "# we do not want the model to initialize the hidden and cell states. \n",
    "# Since we want to use the same value for the generative session as well.    \n",
    "\n",
    "initial_h = Input(shape=(HIDDEN_DIM,))\n",
    "initial_c = Input(shape=(HIDDEN_DIM,))\n",
    "\n",
    "x = embedding_layer(input_)\n",
    "\n",
    "lstm = LSTM(HIDDEN_DIM,return_sequences=True,return_state=True)\n",
    "\n",
    "# don't need the states here, we only need to them when we generate poetry later \n",
    "\n",
    "x,_,_ = lstm(x, initial_state=[initial_h, initial_c]) \n",
    "\n",
    "dense = Dense(num_words,activation='softmax')\n",
    "\n",
    "output = dense(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs= [input_,initial_h,initial_c],outputs= output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics= ['accuracy'])\n",
    "\n",
    "# note that accuracy doesn't really mean much here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiting the hidden and cell states \n",
    "\n",
    "z = np.zeros((len(input_sequences),HIDDEN_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1148 samples, validate on 288 samples\n",
      "Epoch 1/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 5.6116 - acc: 0.0048 - val_loss: 5.6753 - val_acc: 0.0052\n",
      "Epoch 2/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 5.5936 - acc: 0.0088 - val_loss: 5.6591 - val_acc: 0.0119\n",
      "Epoch 3/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 5.5711 - acc: 0.0271 - val_loss: 5.6374 - val_acc: 0.0457\n",
      "Epoch 4/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 5.5416 - acc: 0.0597 - val_loss: 5.6081 - val_acc: 0.0709\n",
      "Epoch 5/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 5.5020 - acc: 0.0789 - val_loss: 5.5701 - val_acc: 0.0781\n",
      "Epoch 6/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 5.4516 - acc: 0.0857 - val_loss: 5.5228 - val_acc: 0.0802\n",
      "Epoch 7/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 5.3901 - acc: 0.0853 - val_loss: 5.4670 - val_acc: 0.0796\n",
      "Epoch 8/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 5.3195 - acc: 0.0857 - val_loss: 5.4039 - val_acc: 0.0793\n",
      "Epoch 9/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 5.2401 - acc: 0.0848 - val_loss: 5.3360 - val_acc: 0.0802\n",
      "Epoch 10/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 5.1549 - acc: 0.0865 - val_loss: 5.2661 - val_acc: 0.0804\n",
      "Epoch 11/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 5.0674 - acc: 0.0884 - val_loss: 5.1966 - val_acc: 0.0813\n",
      "Epoch 12/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.9831 - acc: 0.0882 - val_loss: 5.1306 - val_acc: 0.0810\n",
      "Epoch 13/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.9027 - acc: 0.0853 - val_loss: 5.0713 - val_acc: 0.0828\n",
      "Epoch 14/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.8312 - acc: 0.0869 - val_loss: 5.0179 - val_acc: 0.0836\n",
      "Epoch 15/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.7667 - acc: 0.0894 - val_loss: 4.9710 - val_acc: 0.0856\n",
      "Epoch 16/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.7082 - acc: 0.0899 - val_loss: 4.9294 - val_acc: 0.0880\n",
      "Epoch 17/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.6560 - acc: 0.0913 - val_loss: 4.8930 - val_acc: 0.0880\n",
      "Epoch 18/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.6095 - acc: 0.0917 - val_loss: 4.8619 - val_acc: 0.0868\n",
      "Epoch 19/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.5690 - acc: 0.0932 - val_loss: 4.8353 - val_acc: 0.0845\n",
      "Epoch 20/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.5331 - acc: 0.0857 - val_loss: 4.8124 - val_acc: 0.0833\n",
      "Epoch 21/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.5006 - acc: 0.0841 - val_loss: 4.7924 - val_acc: 0.0833\n",
      "Epoch 22/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.4718 - acc: 0.0833 - val_loss: 4.7753 - val_acc: 0.0833\n",
      "Epoch 23/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.4460 - acc: 0.0833 - val_loss: 4.7607 - val_acc: 0.0833\n",
      "Epoch 24/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.4228 - acc: 0.0833 - val_loss: 4.7481 - val_acc: 0.0833\n",
      "Epoch 25/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.4019 - acc: 0.0833 - val_loss: 4.7371 - val_acc: 0.0833\n",
      "Epoch 26/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.3831 - acc: 0.0833 - val_loss: 4.7273 - val_acc: 0.0833\n",
      "Epoch 27/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.3662 - acc: 0.0833 - val_loss: 4.7192 - val_acc: 0.0833\n",
      "Epoch 28/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.3509 - acc: 0.0833 - val_loss: 4.7125 - val_acc: 0.0833\n",
      "Epoch 29/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 4.3371 - acc: 0.0833 - val_loss: 4.7067 - val_acc: 0.0833\n",
      "Epoch 30/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 4.3245 - acc: 0.0833 - val_loss: 4.7023 - val_acc: 0.0833\n",
      "Epoch 31/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.3132 - acc: 0.0833 - val_loss: 4.6989 - val_acc: 0.0833\n",
      "Epoch 32/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.3027 - acc: 0.0833 - val_loss: 4.6959 - val_acc: 0.0833\n",
      "Epoch 33/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2933 - acc: 0.0833 - val_loss: 4.6940 - val_acc: 0.0833\n",
      "Epoch 34/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2846 - acc: 0.0833 - val_loss: 4.6929 - val_acc: 0.0833\n",
      "Epoch 35/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2767 - acc: 0.0833 - val_loss: 4.6925 - val_acc: 0.0833\n",
      "Epoch 36/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2692 - acc: 0.0833 - val_loss: 4.6926 - val_acc: 0.0833\n",
      "Epoch 37/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2623 - acc: 0.0833 - val_loss: 4.6936 - val_acc: 0.0833\n",
      "Epoch 38/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2555 - acc: 0.0833 - val_loss: 4.6937 - val_acc: 0.0833\n",
      "Epoch 39/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2493 - acc: 0.0833 - val_loss: 4.6944 - val_acc: 0.0833\n",
      "Epoch 40/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2430 - acc: 0.0833 - val_loss: 4.6956 - val_acc: 0.0833\n",
      "Epoch 41/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2373 - acc: 0.0833 - val_loss: 4.6968 - val_acc: 0.0833\n",
      "Epoch 42/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2318 - acc: 0.0833 - val_loss: 4.6989 - val_acc: 0.0833\n",
      "Epoch 43/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2265 - acc: 0.0833 - val_loss: 4.7004 - val_acc: 0.0833\n",
      "Epoch 44/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2212 - acc: 0.0833 - val_loss: 4.7017 - val_acc: 0.0833\n",
      "Epoch 45/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2159 - acc: 0.0833 - val_loss: 4.7032 - val_acc: 0.0833\n",
      "Epoch 46/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2106 - acc: 0.0833 - val_loss: 4.7052 - val_acc: 0.0833\n",
      "Epoch 47/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2054 - acc: 0.0833 - val_loss: 4.7070 - val_acc: 0.0833\n",
      "Epoch 48/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.2002 - acc: 0.0833 - val_loss: 4.7087 - val_acc: 0.0833\n",
      "Epoch 49/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.1951 - acc: 0.0833 - val_loss: 4.7098 - val_acc: 0.0833\n",
      "Epoch 50/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.1900 - acc: 0.0833 - val_loss: 4.7108 - val_acc: 0.0833\n",
      "Epoch 51/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.1848 - acc: 0.0833 - val_loss: 4.7113 - val_acc: 0.0833\n",
      "Epoch 52/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.1795 - acc: 0.0833 - val_loss: 4.7115 - val_acc: 0.0833\n",
      "Epoch 53/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.1742 - acc: 0.0833 - val_loss: 4.7120 - val_acc: 0.0833\n",
      "Epoch 54/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.1689 - acc: 0.0833 - val_loss: 4.7124 - val_acc: 0.0833\n",
      "Epoch 55/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1636 - acc: 0.0833 - val_loss: 4.7118 - val_acc: 0.0833\n",
      "Epoch 56/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1585 - acc: 0.0833 - val_loss: 4.7115 - val_acc: 0.0833\n",
      "Epoch 57/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1532 - acc: 0.0833 - val_loss: 4.7111 - val_acc: 0.0833\n",
      "Epoch 58/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1482 - acc: 0.0833 - val_loss: 4.7107 - val_acc: 0.0833\n",
      "Epoch 59/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1432 - acc: 0.0833 - val_loss: 4.7102 - val_acc: 0.0833\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1382 - acc: 0.0833 - val_loss: 4.7097 - val_acc: 0.0833\n",
      "Epoch 61/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1332 - acc: 0.0833 - val_loss: 4.7094 - val_acc: 0.0833\n",
      "Epoch 62/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1285 - acc: 0.0833 - val_loss: 4.7096 - val_acc: 0.0833\n",
      "Epoch 63/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1238 - acc: 0.0833 - val_loss: 4.7090 - val_acc: 0.0833\n",
      "Epoch 64/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1191 - acc: 0.0833 - val_loss: 4.7090 - val_acc: 0.0833\n",
      "Epoch 65/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1144 - acc: 0.0833 - val_loss: 4.7088 - val_acc: 0.0833\n",
      "Epoch 66/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1096 - acc: 0.0833 - val_loss: 4.7091 - val_acc: 0.0833\n",
      "Epoch 67/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.1048 - acc: 0.0833 - val_loss: 4.7088 - val_acc: 0.0833\n",
      "Epoch 68/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.0999 - acc: 0.0833 - val_loss: 4.7086 - val_acc: 0.0833\n",
      "Epoch 69/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.0950 - acc: 0.0833 - val_loss: 4.7081 - val_acc: 0.0833\n",
      "Epoch 70/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.0900 - acc: 0.0833 - val_loss: 4.7078 - val_acc: 0.0833\n",
      "Epoch 71/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.0849 - acc: 0.0833 - val_loss: 4.7073 - val_acc: 0.0833\n",
      "Epoch 72/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 4.0797 - acc: 0.0833 - val_loss: 4.7069 - val_acc: 0.0833\n",
      "Epoch 73/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0745 - acc: 0.0833 - val_loss: 4.7061 - val_acc: 0.0833\n",
      "Epoch 74/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0691 - acc: 0.0833 - val_loss: 4.7054 - val_acc: 0.0833\n",
      "Epoch 75/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0637 - acc: 0.0833 - val_loss: 4.7042 - val_acc: 0.0833\n",
      "Epoch 76/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0582 - acc: 0.0833 - val_loss: 4.7031 - val_acc: 0.0833\n",
      "Epoch 77/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0527 - acc: 0.0833 - val_loss: 4.7021 - val_acc: 0.0833\n",
      "Epoch 78/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0470 - acc: 0.0833 - val_loss: 4.7002 - val_acc: 0.0833\n",
      "Epoch 79/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0414 - acc: 0.0833 - val_loss: 4.6989 - val_acc: 0.0833\n",
      "Epoch 80/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0357 - acc: 0.0833 - val_loss: 4.6972 - val_acc: 0.0833\n",
      "Epoch 81/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0300 - acc: 0.0833 - val_loss: 4.6958 - val_acc: 0.0833\n",
      "Epoch 82/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0243 - acc: 0.0833 - val_loss: 4.6944 - val_acc: 0.0833\n",
      "Epoch 83/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0186 - acc: 0.0833 - val_loss: 4.6929 - val_acc: 0.0833\n",
      "Epoch 84/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0129 - acc: 0.0833 - val_loss: 4.6911 - val_acc: 0.0833\n",
      "Epoch 85/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0073 - acc: 0.0833 - val_loss: 4.6905 - val_acc: 0.0833\n",
      "Epoch 86/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 4.0017 - acc: 0.0833 - val_loss: 4.6885 - val_acc: 0.0833\n",
      "Epoch 87/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9961 - acc: 0.0833 - val_loss: 4.6873 - val_acc: 0.0833\n",
      "Epoch 88/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9906 - acc: 0.0833 - val_loss: 4.6857 - val_acc: 0.0833\n",
      "Epoch 89/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9850 - acc: 0.0833 - val_loss: 4.6831 - val_acc: 0.0833\n",
      "Epoch 90/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9795 - acc: 0.0833 - val_loss: 4.6817 - val_acc: 0.0833\n",
      "Epoch 91/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9740 - acc: 0.0833 - val_loss: 4.6795 - val_acc: 0.0833\n",
      "Epoch 92/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9686 - acc: 0.0833 - val_loss: 4.6771 - val_acc: 0.0833\n",
      "Epoch 93/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9631 - acc: 0.0833 - val_loss: 4.6762 - val_acc: 0.0833\n",
      "Epoch 94/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9579 - acc: 0.0833 - val_loss: 4.6750 - val_acc: 0.0833\n",
      "Epoch 95/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.9528 - acc: 0.0833 - val_loss: 4.6728 - val_acc: 0.0833\n",
      "Epoch 96/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.9477 - acc: 0.0833 - val_loss: 4.6730 - val_acc: 0.0833\n",
      "Epoch 97/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9427 - acc: 0.0836 - val_loss: 4.6711 - val_acc: 0.0833\n",
      "Epoch 98/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9378 - acc: 0.0836 - val_loss: 4.6706 - val_acc: 0.0833\n",
      "Epoch 99/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9331 - acc: 0.0836 - val_loss: 4.6698 - val_acc: 0.0833\n",
      "Epoch 100/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9285 - acc: 0.0837 - val_loss: 4.6681 - val_acc: 0.0833\n",
      "Epoch 101/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9241 - acc: 0.0838 - val_loss: 4.6687 - val_acc: 0.0833\n",
      "Epoch 102/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9195 - acc: 0.0838 - val_loss: 4.6673 - val_acc: 0.0833\n",
      "Epoch 103/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9151 - acc: 0.0837 - val_loss: 4.6661 - val_acc: 0.0839\n",
      "Epoch 104/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9108 - acc: 0.0839 - val_loss: 4.6662 - val_acc: 0.0839\n",
      "Epoch 105/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9065 - acc: 0.0839 - val_loss: 4.6652 - val_acc: 0.0839\n",
      "Epoch 106/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.9023 - acc: 0.0841 - val_loss: 4.6655 - val_acc: 0.0839\n",
      "Epoch 107/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8983 - acc: 0.0843 - val_loss: 4.6657 - val_acc: 0.0848\n",
      "Epoch 108/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8943 - acc: 0.0846 - val_loss: 4.6651 - val_acc: 0.0845\n",
      "Epoch 109/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8903 - acc: 0.0847 - val_loss: 4.6656 - val_acc: 0.0845\n",
      "Epoch 110/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8863 - acc: 0.0850 - val_loss: 4.6647 - val_acc: 0.0845\n",
      "Epoch 111/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8823 - acc: 0.0850 - val_loss: 4.6650 - val_acc: 0.0845\n",
      "Epoch 112/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8785 - acc: 0.0851 - val_loss: 4.6653 - val_acc: 0.0845\n",
      "Epoch 113/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8747 - acc: 0.0856 - val_loss: 4.6652 - val_acc: 0.0848\n",
      "Epoch 114/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 3.8709 - acc: 0.0859 - val_loss: 4.6661 - val_acc: 0.0854\n",
      "Epoch 115/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8671 - acc: 0.0860 - val_loss: 4.6653 - val_acc: 0.0854\n",
      "Epoch 116/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8633 - acc: 0.0862 - val_loss: 4.6662 - val_acc: 0.0854\n",
      "Epoch 117/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8596 - acc: 0.0868 - val_loss: 4.6662 - val_acc: 0.0854\n",
      "Epoch 118/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8559 - acc: 0.0867 - val_loss: 4.6660 - val_acc: 0.0854\n",
      "Epoch 119/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8522 - acc: 0.0868 - val_loss: 4.6671 - val_acc: 0.0854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8485 - acc: 0.0869 - val_loss: 4.6662 - val_acc: 0.0848\n",
      "Epoch 121/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8450 - acc: 0.0871 - val_loss: 4.6674 - val_acc: 0.0854\n",
      "Epoch 122/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8413 - acc: 0.0874 - val_loss: 4.6672 - val_acc: 0.0851\n",
      "Epoch 123/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8377 - acc: 0.0873 - val_loss: 4.6664 - val_acc: 0.0848\n",
      "Epoch 124/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8340 - acc: 0.0875 - val_loss: 4.6673 - val_acc: 0.0851\n",
      "Epoch 125/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8304 - acc: 0.0877 - val_loss: 4.6664 - val_acc: 0.0851\n",
      "Epoch 126/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8267 - acc: 0.0880 - val_loss: 4.6663 - val_acc: 0.0854\n",
      "Epoch 127/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8230 - acc: 0.0882 - val_loss: 4.6665 - val_acc: 0.0851\n",
      "Epoch 128/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.8194 - acc: 0.0884 - val_loss: 4.6669 - val_acc: 0.0851\n",
      "Epoch 129/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8158 - acc: 0.0886 - val_loss: 4.6669 - val_acc: 0.0851\n",
      "Epoch 130/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8122 - acc: 0.0891 - val_loss: 4.6678 - val_acc: 0.0851\n",
      "Epoch 131/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8085 - acc: 0.0891 - val_loss: 4.6665 - val_acc: 0.0851\n",
      "Epoch 132/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8048 - acc: 0.0892 - val_loss: 4.6673 - val_acc: 0.0854\n",
      "Epoch 133/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.8011 - acc: 0.0894 - val_loss: 4.6664 - val_acc: 0.0851\n",
      "Epoch 134/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7974 - acc: 0.0896 - val_loss: 4.6665 - val_acc: 0.0848\n",
      "Epoch 135/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7937 - acc: 0.0901 - val_loss: 4.6676 - val_acc: 0.0851\n",
      "Epoch 136/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7901 - acc: 0.0896 - val_loss: 4.6658 - val_acc: 0.0851\n",
      "Epoch 137/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7863 - acc: 0.0905 - val_loss: 4.6675 - val_acc: 0.0854\n",
      "Epoch 138/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7826 - acc: 0.0905 - val_loss: 4.6677 - val_acc: 0.0854\n",
      "Epoch 139/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7788 - acc: 0.0908 - val_loss: 4.6671 - val_acc: 0.0854\n",
      "Epoch 140/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7749 - acc: 0.0909 - val_loss: 4.6677 - val_acc: 0.0856\n",
      "Epoch 141/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7711 - acc: 0.0910 - val_loss: 4.6664 - val_acc: 0.0859\n",
      "Epoch 142/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7673 - acc: 0.0910 - val_loss: 4.6670 - val_acc: 0.0859\n",
      "Epoch 143/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7634 - acc: 0.0913 - val_loss: 4.6668 - val_acc: 0.0859\n",
      "Epoch 144/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7598 - acc: 0.0914 - val_loss: 4.6680 - val_acc: 0.0859\n",
      "Epoch 145/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7561 - acc: 0.0917 - val_loss: 4.6679 - val_acc: 0.0871\n",
      "Epoch 146/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7524 - acc: 0.0919 - val_loss: 4.6689 - val_acc: 0.0862\n",
      "Epoch 147/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.7488 - acc: 0.0920 - val_loss: 4.6684 - val_acc: 0.0871\n",
      "Epoch 148/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7451 - acc: 0.0926 - val_loss: 4.6707 - val_acc: 0.0865\n",
      "Epoch 149/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7414 - acc: 0.0924 - val_loss: 4.6692 - val_acc: 0.0871\n",
      "Epoch 150/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7378 - acc: 0.0929 - val_loss: 4.6713 - val_acc: 0.0868\n",
      "Epoch 151/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7341 - acc: 0.0929 - val_loss: 4.6697 - val_acc: 0.0877\n",
      "Epoch 152/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7305 - acc: 0.0980 - val_loss: 4.6723 - val_acc: 0.0909\n",
      "Epoch 153/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7268 - acc: 0.1020 - val_loss: 4.6709 - val_acc: 0.0911\n",
      "Epoch 154/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7231 - acc: 0.1025 - val_loss: 4.6724 - val_acc: 0.0914\n",
      "Epoch 155/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7194 - acc: 0.1026 - val_loss: 4.6724 - val_acc: 0.0911\n",
      "Epoch 156/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7157 - acc: 0.1026 - val_loss: 4.6723 - val_acc: 0.0914\n",
      "Epoch 157/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7119 - acc: 0.1032 - val_loss: 4.6738 - val_acc: 0.0914\n",
      "Epoch 158/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7082 - acc: 0.1037 - val_loss: 4.6742 - val_acc: 0.0920\n",
      "Epoch 159/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7045 - acc: 0.1045 - val_loss: 4.6735 - val_acc: 0.0923\n",
      "Epoch 160/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.7007 - acc: 0.1058 - val_loss: 4.6744 - val_acc: 0.0923\n",
      "Epoch 161/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.6970 - acc: 0.1059 - val_loss: 4.6754 - val_acc: 0.0926\n",
      "Epoch 162/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.6933 - acc: 0.1066 - val_loss: 4.6749 - val_acc: 0.0923\n",
      "Epoch 163/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.6895 - acc: 0.1068 - val_loss: 4.6752 - val_acc: 0.0923\n",
      "Epoch 164/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.6858 - acc: 0.1070 - val_loss: 4.6758 - val_acc: 0.0923\n",
      "Epoch 165/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.6820 - acc: 0.1073 - val_loss: 4.6758 - val_acc: 0.0920\n",
      "Epoch 166/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6783 - acc: 0.1077 - val_loss: 4.6763 - val_acc: 0.0932\n",
      "Epoch 167/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6745 - acc: 0.1082 - val_loss: 4.6785 - val_acc: 0.0937\n",
      "Epoch 168/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6708 - acc: 0.1087 - val_loss: 4.6781 - val_acc: 0.0940\n",
      "Epoch 169/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6670 - acc: 0.1090 - val_loss: 4.6781 - val_acc: 0.0940\n",
      "Epoch 170/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6633 - acc: 0.1092 - val_loss: 4.6805 - val_acc: 0.0943\n",
      "Epoch 171/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6595 - acc: 0.1094 - val_loss: 4.6797 - val_acc: 0.0940\n",
      "Epoch 172/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6558 - acc: 0.1097 - val_loss: 4.6814 - val_acc: 0.0940\n",
      "Epoch 173/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6520 - acc: 0.1100 - val_loss: 4.6813 - val_acc: 0.0943\n",
      "Epoch 174/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6483 - acc: 0.1102 - val_loss: 4.6820 - val_acc: 0.0952\n",
      "Epoch 175/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6445 - acc: 0.1105 - val_loss: 4.6823 - val_acc: 0.0955\n",
      "Epoch 176/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6406 - acc: 0.1107 - val_loss: 4.6821 - val_acc: 0.0952\n",
      "Epoch 177/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6368 - acc: 0.1112 - val_loss: 4.6831 - val_acc: 0.0961\n",
      "Epoch 178/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6329 - acc: 0.1120 - val_loss: 4.6824 - val_acc: 0.0961\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6291 - acc: 0.1123 - val_loss: 4.6830 - val_acc: 0.0961\n",
      "Epoch 180/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6252 - acc: 0.1127 - val_loss: 4.6838 - val_acc: 0.0964\n",
      "Epoch 181/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6215 - acc: 0.1126 - val_loss: 4.6859 - val_acc: 0.0964\n",
      "Epoch 182/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6176 - acc: 0.1129 - val_loss: 4.6843 - val_acc: 0.0964\n",
      "Epoch 183/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6138 - acc: 0.1132 - val_loss: 4.6844 - val_acc: 0.0964\n",
      "Epoch 184/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6100 - acc: 0.1132 - val_loss: 4.6858 - val_acc: 0.0966\n",
      "Epoch 185/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6060 - acc: 0.1135 - val_loss: 4.6864 - val_acc: 0.0966\n",
      "Epoch 186/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.6022 - acc: 0.1142 - val_loss: 4.6875 - val_acc: 0.0964\n",
      "Epoch 187/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5983 - acc: 0.1148 - val_loss: 4.6859 - val_acc: 0.0964\n",
      "Epoch 188/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5944 - acc: 0.1148 - val_loss: 4.6891 - val_acc: 0.0972\n",
      "Epoch 189/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5907 - acc: 0.1148 - val_loss: 4.6878 - val_acc: 0.0966\n",
      "Epoch 190/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5867 - acc: 0.1150 - val_loss: 4.6885 - val_acc: 0.0969\n",
      "Epoch 191/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.5828 - acc: 0.1154 - val_loss: 4.6898 - val_acc: 0.0966\n",
      "Epoch 192/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.5788 - acc: 0.1156 - val_loss: 4.6901 - val_acc: 0.0966\n",
      "Epoch 193/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.5749 - acc: 0.1163 - val_loss: 4.6898 - val_acc: 0.0969\n",
      "Epoch 194/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5710 - acc: 0.1165 - val_loss: 4.6901 - val_acc: 0.0969\n",
      "Epoch 195/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5670 - acc: 0.1173 - val_loss: 4.6913 - val_acc: 0.0969\n",
      "Epoch 196/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5631 - acc: 0.1177 - val_loss: 4.6924 - val_acc: 0.0969\n",
      "Epoch 197/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5592 - acc: 0.1179 - val_loss: 4.6916 - val_acc: 0.0969\n",
      "Epoch 198/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5552 - acc: 0.1180 - val_loss: 4.6932 - val_acc: 0.0972\n",
      "Epoch 199/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5513 - acc: 0.1184 - val_loss: 4.6932 - val_acc: 0.0972\n",
      "Epoch 200/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5474 - acc: 0.1189 - val_loss: 4.6937 - val_acc: 0.0975\n",
      "Epoch 201/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5434 - acc: 0.1194 - val_loss: 4.6944 - val_acc: 0.0972\n",
      "Epoch 202/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5395 - acc: 0.1196 - val_loss: 4.6951 - val_acc: 0.0972\n",
      "Epoch 203/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5356 - acc: 0.1201 - val_loss: 4.6970 - val_acc: 0.0972\n",
      "Epoch 204/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5316 - acc: 0.1207 - val_loss: 4.6959 - val_acc: 0.0975\n",
      "Epoch 205/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5277 - acc: 0.1208 - val_loss: 4.6970 - val_acc: 0.0975\n",
      "Epoch 206/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5239 - acc: 0.1213 - val_loss: 4.7003 - val_acc: 0.0972\n",
      "Epoch 207/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5200 - acc: 0.1212 - val_loss: 4.6979 - val_acc: 0.0975\n",
      "Epoch 208/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5160 - acc: 0.1217 - val_loss: 4.6999 - val_acc: 0.0972\n",
      "Epoch 209/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5119 - acc: 0.1217 - val_loss: 4.6998 - val_acc: 0.0975\n",
      "Epoch 210/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5080 - acc: 0.1219 - val_loss: 4.7002 - val_acc: 0.0975\n",
      "Epoch 211/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5041 - acc: 0.1222 - val_loss: 4.7006 - val_acc: 0.0975\n",
      "Epoch 212/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.5001 - acc: 0.1227 - val_loss: 4.7017 - val_acc: 0.0975\n",
      "Epoch 213/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4961 - acc: 0.1230 - val_loss: 4.7020 - val_acc: 0.0975\n",
      "Epoch 214/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4921 - acc: 0.1233 - val_loss: 4.7018 - val_acc: 0.0978\n",
      "Epoch 215/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4883 - acc: 0.1235 - val_loss: 4.7030 - val_acc: 0.0978\n",
      "Epoch 216/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4843 - acc: 0.1238 - val_loss: 4.7034 - val_acc: 0.0978\n",
      "Epoch 217/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4803 - acc: 0.1236 - val_loss: 4.7036 - val_acc: 0.0978\n",
      "Epoch 218/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4763 - acc: 0.1241 - val_loss: 4.7050 - val_acc: 0.0978\n",
      "Epoch 219/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4724 - acc: 0.1245 - val_loss: 4.7049 - val_acc: 0.0969\n",
      "Epoch 220/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4684 - acc: 0.1247 - val_loss: 4.7054 - val_acc: 0.0969\n",
      "Epoch 221/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4644 - acc: 0.1246 - val_loss: 4.7056 - val_acc: 0.0972\n",
      "Epoch 222/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4604 - acc: 0.1251 - val_loss: 4.7066 - val_acc: 0.0966\n",
      "Epoch 223/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4564 - acc: 0.1252 - val_loss: 4.7060 - val_acc: 0.0966\n",
      "Epoch 224/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4524 - acc: 0.1256 - val_loss: 4.7073 - val_acc: 0.0964\n",
      "Epoch 225/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4484 - acc: 0.1257 - val_loss: 4.7072 - val_acc: 0.0964\n",
      "Epoch 226/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4444 - acc: 0.1259 - val_loss: 4.7063 - val_acc: 0.0964\n",
      "Epoch 227/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4404 - acc: 0.1264 - val_loss: 4.7075 - val_acc: 0.0969\n",
      "Epoch 228/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4362 - acc: 0.1266 - val_loss: 4.7063 - val_acc: 0.0972\n",
      "Epoch 229/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4321 - acc: 0.1265 - val_loss: 4.7058 - val_acc: 0.0969\n",
      "Epoch 230/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4279 - acc: 0.1268 - val_loss: 4.7066 - val_acc: 0.0969\n",
      "Epoch 231/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4237 - acc: 0.1267 - val_loss: 4.7036 - val_acc: 0.0975\n",
      "Epoch 232/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4195 - acc: 0.1272 - val_loss: 4.7054 - val_acc: 0.0972\n",
      "Epoch 233/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4154 - acc: 0.1270 - val_loss: 4.7029 - val_acc: 0.0975\n",
      "Epoch 234/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4114 - acc: 0.1265 - val_loss: 4.7042 - val_acc: 0.0975\n",
      "Epoch 235/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.4073 - acc: 0.1269 - val_loss: 4.7049 - val_acc: 0.0975\n",
      "Epoch 236/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.4032 - acc: 0.1265 - val_loss: 4.7045 - val_acc: 0.0975\n",
      "Epoch 237/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3990 - acc: 0.1267 - val_loss: 4.7059 - val_acc: 0.0978\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3950 - acc: 0.1273 - val_loss: 4.7067 - val_acc: 0.0975\n",
      "Epoch 239/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3909 - acc: 0.1275 - val_loss: 4.7066 - val_acc: 0.0969\n",
      "Epoch 240/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3868 - acc: 0.1278 - val_loss: 4.7076 - val_acc: 0.0969\n",
      "Epoch 241/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3827 - acc: 0.1280 - val_loss: 4.7078 - val_acc: 0.0969\n",
      "Epoch 242/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3787 - acc: 0.1281 - val_loss: 4.7074 - val_acc: 0.0972\n",
      "Epoch 243/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3746 - acc: 0.1286 - val_loss: 4.7085 - val_acc: 0.0972\n",
      "Epoch 244/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3705 - acc: 0.1286 - val_loss: 4.7073 - val_acc: 0.0972\n",
      "Epoch 245/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3665 - acc: 0.1293 - val_loss: 4.7100 - val_acc: 0.0969\n",
      "Epoch 246/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3623 - acc: 0.1294 - val_loss: 4.7083 - val_acc: 0.0972\n",
      "Epoch 247/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3582 - acc: 0.1298 - val_loss: 4.7112 - val_acc: 0.0972\n",
      "Epoch 248/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3541 - acc: 0.1304 - val_loss: 4.7101 - val_acc: 0.0972\n",
      "Epoch 249/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3500 - acc: 0.1302 - val_loss: 4.7112 - val_acc: 0.0978\n",
      "Epoch 250/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3458 - acc: 0.1304 - val_loss: 4.7108 - val_acc: 0.0975\n",
      "Epoch 251/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3417 - acc: 0.1305 - val_loss: 4.7118 - val_acc: 0.0978\n",
      "Epoch 252/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3375 - acc: 0.1310 - val_loss: 4.7123 - val_acc: 0.0975\n",
      "Epoch 253/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3334 - acc: 0.1312 - val_loss: 4.7135 - val_acc: 0.0975\n",
      "Epoch 254/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3292 - acc: 0.1310 - val_loss: 4.7130 - val_acc: 0.0975\n",
      "Epoch 255/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3251 - acc: 0.1313 - val_loss: 4.7141 - val_acc: 0.0975\n",
      "Epoch 256/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3209 - acc: 0.1320 - val_loss: 4.7144 - val_acc: 0.0978\n",
      "Epoch 257/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3168 - acc: 0.1320 - val_loss: 4.7144 - val_acc: 0.0978\n",
      "Epoch 258/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3126 - acc: 0.1327 - val_loss: 4.7152 - val_acc: 0.0981\n",
      "Epoch 259/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3085 - acc: 0.1331 - val_loss: 4.7154 - val_acc: 0.0984\n",
      "Epoch 260/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3042 - acc: 0.1331 - val_loss: 4.7162 - val_acc: 0.0981\n",
      "Epoch 261/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.3000 - acc: 0.1333 - val_loss: 4.7170 - val_acc: 0.0978\n",
      "Epoch 262/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2959 - acc: 0.1332 - val_loss: 4.7171 - val_acc: 0.0978\n",
      "Epoch 263/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2916 - acc: 0.1333 - val_loss: 4.7181 - val_acc: 0.0975\n",
      "Epoch 264/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2875 - acc: 0.1337 - val_loss: 4.7185 - val_acc: 0.0975\n",
      "Epoch 265/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2833 - acc: 0.1341 - val_loss: 4.7188 - val_acc: 0.0975\n",
      "Epoch 266/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2791 - acc: 0.1344 - val_loss: 4.7197 - val_acc: 0.0978\n",
      "Epoch 267/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2750 - acc: 0.1349 - val_loss: 4.7200 - val_acc: 0.0978\n",
      "Epoch 268/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2707 - acc: 0.1355 - val_loss: 4.7214 - val_acc: 0.0978\n",
      "Epoch 269/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2666 - acc: 0.1354 - val_loss: 4.7223 - val_acc: 0.0975\n",
      "Epoch 270/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2624 - acc: 0.1357 - val_loss: 4.7231 - val_acc: 0.0975\n",
      "Epoch 271/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2583 - acc: 0.1356 - val_loss: 4.7231 - val_acc: 0.0978\n",
      "Epoch 272/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2542 - acc: 0.1364 - val_loss: 4.7246 - val_acc: 0.0975\n",
      "Epoch 273/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2501 - acc: 0.1370 - val_loss: 4.7245 - val_acc: 0.0975\n",
      "Epoch 274/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2459 - acc: 0.1372 - val_loss: 4.7261 - val_acc: 0.0975\n",
      "Epoch 275/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2418 - acc: 0.1373 - val_loss: 4.7258 - val_acc: 0.0972\n",
      "Epoch 276/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2378 - acc: 0.1377 - val_loss: 4.7272 - val_acc: 0.0975\n",
      "Epoch 277/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2337 - acc: 0.1381 - val_loss: 4.7266 - val_acc: 0.0972\n",
      "Epoch 278/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2296 - acc: 0.1385 - val_loss: 4.7265 - val_acc: 0.0975\n",
      "Epoch 279/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2255 - acc: 0.1397 - val_loss: 4.7289 - val_acc: 0.0972\n",
      "Epoch 280/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2214 - acc: 0.1394 - val_loss: 4.7279 - val_acc: 0.0975\n",
      "Epoch 281/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2173 - acc: 0.1399 - val_loss: 4.7305 - val_acc: 0.0978\n",
      "Epoch 282/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2133 - acc: 0.1409 - val_loss: 4.7310 - val_acc: 0.0978\n",
      "Epoch 283/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2093 - acc: 0.1415 - val_loss: 4.7306 - val_acc: 0.0981\n",
      "Epoch 284/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2051 - acc: 0.1422 - val_loss: 4.7329 - val_acc: 0.0987\n",
      "Epoch 285/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.2010 - acc: 0.1430 - val_loss: 4.7332 - val_acc: 0.0981\n",
      "Epoch 286/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1970 - acc: 0.1434 - val_loss: 4.7348 - val_acc: 0.0984\n",
      "Epoch 287/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1930 - acc: 0.1438 - val_loss: 4.7346 - val_acc: 0.0981\n",
      "Epoch 288/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1890 - acc: 0.1437 - val_loss: 4.7347 - val_acc: 0.0981\n",
      "Epoch 289/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1850 - acc: 0.1440 - val_loss: 4.7360 - val_acc: 0.0984\n",
      "Epoch 290/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1810 - acc: 0.1451 - val_loss: 4.7368 - val_acc: 0.0987\n",
      "Epoch 291/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1770 - acc: 0.1445 - val_loss: 4.7368 - val_acc: 0.0984\n",
      "Epoch 292/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 3.1730 - acc: 0.1455 - val_loss: 4.7385 - val_acc: 0.0981\n",
      "Epoch 293/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1691 - acc: 0.1456 - val_loss: 4.7384 - val_acc: 0.0975\n",
      "Epoch 294/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1651 - acc: 0.1460 - val_loss: 4.7393 - val_acc: 0.0984\n",
      "Epoch 295/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1612 - acc: 0.1471 - val_loss: 4.7400 - val_acc: 0.0981\n",
      "Epoch 296/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1572 - acc: 0.1478 - val_loss: 4.7401 - val_acc: 0.0984\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1531 - acc: 0.1482 - val_loss: 4.7405 - val_acc: 0.0984\n",
      "Epoch 298/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1492 - acc: 0.1483 - val_loss: 4.7421 - val_acc: 0.0990\n",
      "Epoch 299/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1452 - acc: 0.1484 - val_loss: 4.7420 - val_acc: 0.0981\n",
      "Epoch 300/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1413 - acc: 0.1492 - val_loss: 4.7441 - val_acc: 0.0981\n",
      "Epoch 301/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1373 - acc: 0.1496 - val_loss: 4.7445 - val_acc: 0.0978\n",
      "Epoch 302/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1334 - acc: 0.1498 - val_loss: 4.7446 - val_acc: 0.0987\n",
      "Epoch 303/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1295 - acc: 0.1506 - val_loss: 4.7467 - val_acc: 0.0978\n",
      "Epoch 304/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1256 - acc: 0.1505 - val_loss: 4.7470 - val_acc: 0.0987\n",
      "Epoch 305/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1217 - acc: 0.1511 - val_loss: 4.7474 - val_acc: 0.0992\n",
      "Epoch 306/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1177 - acc: 0.1514 - val_loss: 4.7487 - val_acc: 0.0995\n",
      "Epoch 307/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1137 - acc: 0.1519 - val_loss: 4.7491 - val_acc: 0.0992\n",
      "Epoch 308/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1097 - acc: 0.1525 - val_loss: 4.7503 - val_acc: 0.0990\n",
      "Epoch 309/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1057 - acc: 0.1531 - val_loss: 4.7505 - val_acc: 0.0990\n",
      "Epoch 310/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.1018 - acc: 0.1532 - val_loss: 4.7524 - val_acc: 0.0987\n",
      "Epoch 311/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0979 - acc: 0.1539 - val_loss: 4.7529 - val_acc: 0.0987\n",
      "Epoch 312/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0940 - acc: 0.1542 - val_loss: 4.7539 - val_acc: 0.0992\n",
      "Epoch 313/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0901 - acc: 0.1550 - val_loss: 4.7551 - val_acc: 0.0990\n",
      "Epoch 314/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0861 - acc: 0.1553 - val_loss: 4.7561 - val_acc: 0.0992\n",
      "Epoch 315/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0824 - acc: 0.1556 - val_loss: 4.7568 - val_acc: 0.0990\n",
      "Epoch 316/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0784 - acc: 0.1568 - val_loss: 4.7578 - val_acc: 0.0995\n",
      "Epoch 317/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0745 - acc: 0.1566 - val_loss: 4.7580 - val_acc: 0.1001\n",
      "Epoch 318/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0707 - acc: 0.1575 - val_loss: 4.7601 - val_acc: 0.0998\n",
      "Epoch 319/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0669 - acc: 0.1574 - val_loss: 4.7605 - val_acc: 0.0995\n",
      "Epoch 320/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0630 - acc: 0.1581 - val_loss: 4.7619 - val_acc: 0.0992\n",
      "Epoch 321/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0592 - acc: 0.1582 - val_loss: 4.7626 - val_acc: 0.0990\n",
      "Epoch 322/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0553 - acc: 0.1590 - val_loss: 4.7642 - val_acc: 0.0992\n",
      "Epoch 323/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0514 - acc: 0.1593 - val_loss: 4.7644 - val_acc: 0.0995\n",
      "Epoch 324/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0476 - acc: 0.1593 - val_loss: 4.7661 - val_acc: 0.0992\n",
      "Epoch 325/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0438 - acc: 0.1603 - val_loss: 4.7667 - val_acc: 0.0998\n",
      "Epoch 326/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0399 - acc: 0.1604 - val_loss: 4.7684 - val_acc: 0.0992\n",
      "Epoch 327/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0362 - acc: 0.1609 - val_loss: 4.7687 - val_acc: 0.0992\n",
      "Epoch 328/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0324 - acc: 0.1606 - val_loss: 4.7691 - val_acc: 0.1001\n",
      "Epoch 329/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0286 - acc: 0.1618 - val_loss: 4.7702 - val_acc: 0.0995\n",
      "Epoch 330/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0248 - acc: 0.1622 - val_loss: 4.7709 - val_acc: 0.1001\n",
      "Epoch 331/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0210 - acc: 0.1625 - val_loss: 4.7721 - val_acc: 0.1001\n",
      "Epoch 332/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0172 - acc: 0.1632 - val_loss: 4.7730 - val_acc: 0.0998\n",
      "Epoch 333/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0135 - acc: 0.1632 - val_loss: 4.7747 - val_acc: 0.0998\n",
      "Epoch 334/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0097 - acc: 0.1632 - val_loss: 4.7743 - val_acc: 0.0998\n",
      "Epoch 335/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0061 - acc: 0.1646 - val_loss: 4.7770 - val_acc: 0.1001\n",
      "Epoch 336/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 3.0023 - acc: 0.1654 - val_loss: 4.7778 - val_acc: 0.1001\n",
      "Epoch 337/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.9986 - acc: 0.1651 - val_loss: 4.7780 - val_acc: 0.1001\n",
      "Epoch 338/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.9949 - acc: 0.1665 - val_loss: 4.7801 - val_acc: 0.1004\n",
      "Epoch 339/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.9912 - acc: 0.1667 - val_loss: 4.7807 - val_acc: 0.1004\n",
      "Epoch 340/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9876 - acc: 0.1664 - val_loss: 4.7815 - val_acc: 0.1004\n",
      "Epoch 341/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9838 - acc: 0.1677 - val_loss: 4.7834 - val_acc: 0.1004\n",
      "Epoch 342/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9802 - acc: 0.1673 - val_loss: 4.7830 - val_acc: 0.0995\n",
      "Epoch 343/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9765 - acc: 0.1683 - val_loss: 4.7850 - val_acc: 0.1004\n",
      "Epoch 344/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9729 - acc: 0.1681 - val_loss: 4.7857 - val_acc: 0.0998\n",
      "Epoch 345/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9691 - acc: 0.1681 - val_loss: 4.7864 - val_acc: 0.0992\n",
      "Epoch 346/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9655 - acc: 0.1696 - val_loss: 4.7885 - val_acc: 0.1001\n",
      "Epoch 347/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9619 - acc: 0.1692 - val_loss: 4.7880 - val_acc: 0.0992\n",
      "Epoch 348/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9582 - acc: 0.1699 - val_loss: 4.7892 - val_acc: 0.0992\n",
      "Epoch 349/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9544 - acc: 0.1710 - val_loss: 4.7913 - val_acc: 0.0995\n",
      "Epoch 350/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9508 - acc: 0.1705 - val_loss: 4.7907 - val_acc: 0.0995\n",
      "Epoch 351/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9473 - acc: 0.1709 - val_loss: 4.7933 - val_acc: 0.0995\n",
      "Epoch 352/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9436 - acc: 0.1715 - val_loss: 4.7930 - val_acc: 0.0995\n",
      "Epoch 353/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9400 - acc: 0.1718 - val_loss: 4.7946 - val_acc: 0.0995\n",
      "Epoch 354/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9363 - acc: 0.1729 - val_loss: 4.7960 - val_acc: 0.0992\n",
      "Epoch 355/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9327 - acc: 0.1731 - val_loss: 4.7970 - val_acc: 0.0992\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9290 - acc: 0.1739 - val_loss: 4.7987 - val_acc: 0.0995\n",
      "Epoch 357/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9255 - acc: 0.1741 - val_loss: 4.7990 - val_acc: 0.0987\n",
      "Epoch 358/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9220 - acc: 0.1744 - val_loss: 4.8009 - val_acc: 0.0987\n",
      "Epoch 359/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9185 - acc: 0.1752 - val_loss: 4.8015 - val_acc: 0.0990\n",
      "Epoch 360/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9149 - acc: 0.1753 - val_loss: 4.8031 - val_acc: 0.0987\n",
      "Epoch 361/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9112 - acc: 0.1765 - val_loss: 4.8043 - val_acc: 0.0984\n",
      "Epoch 362/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9076 - acc: 0.1771 - val_loss: 4.8055 - val_acc: 0.0987\n",
      "Epoch 363/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9041 - acc: 0.1776 - val_loss: 4.8062 - val_acc: 0.0978\n",
      "Epoch 364/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.9005 - acc: 0.1783 - val_loss: 4.8075 - val_acc: 0.0990\n",
      "Epoch 365/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.8969 - acc: 0.1789 - val_loss: 4.8085 - val_acc: 0.0987\n",
      "Epoch 366/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.8933 - acc: 0.1793 - val_loss: 4.8093 - val_acc: 0.0987\n",
      "Epoch 367/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.8898 - acc: 0.1792 - val_loss: 4.8113 - val_acc: 0.0981\n",
      "Epoch 368/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.8863 - acc: 0.1802 - val_loss: 4.8112 - val_acc: 0.0981\n",
      "Epoch 369/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.8827 - acc: 0.1801 - val_loss: 4.8129 - val_acc: 0.0978\n",
      "Epoch 370/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.8792 - acc: 0.1811 - val_loss: 4.8137 - val_acc: 0.0978\n",
      "Epoch 371/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.8758 - acc: 0.1813 - val_loss: 4.8149 - val_acc: 0.0984\n",
      "Epoch 372/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.8723 - acc: 0.1818 - val_loss: 4.8157 - val_acc: 0.0984\n",
      "Epoch 373/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.8688 - acc: 0.1829 - val_loss: 4.8172 - val_acc: 0.0975\n",
      "Epoch 374/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.8653 - acc: 0.1838 - val_loss: 4.8180 - val_acc: 0.0978\n",
      "Epoch 375/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8618 - acc: 0.1841 - val_loss: 4.8190 - val_acc: 0.0978\n",
      "Epoch 376/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8583 - acc: 0.1847 - val_loss: 4.8204 - val_acc: 0.0972\n",
      "Epoch 377/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8549 - acc: 0.1848 - val_loss: 4.8202 - val_acc: 0.0981\n",
      "Epoch 378/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8516 - acc: 0.1852 - val_loss: 4.8226 - val_acc: 0.0972\n",
      "Epoch 379/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8482 - acc: 0.1863 - val_loss: 4.8231 - val_acc: 0.0975\n",
      "Epoch 380/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8446 - acc: 0.1871 - val_loss: 4.8243 - val_acc: 0.0972\n",
      "Epoch 381/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8411 - acc: 0.1873 - val_loss: 4.8253 - val_acc: 0.0975\n",
      "Epoch 382/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8376 - acc: 0.1871 - val_loss: 4.8267 - val_acc: 0.0978\n",
      "Epoch 383/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8342 - acc: 0.1879 - val_loss: 4.8286 - val_acc: 0.0975\n",
      "Epoch 384/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8308 - acc: 0.1884 - val_loss: 4.8291 - val_acc: 0.0981\n",
      "Epoch 385/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8273 - acc: 0.1895 - val_loss: 4.8313 - val_acc: 0.0972\n",
      "Epoch 386/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8239 - acc: 0.1898 - val_loss: 4.8317 - val_acc: 0.0978\n",
      "Epoch 387/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8205 - acc: 0.1900 - val_loss: 4.8336 - val_acc: 0.0978\n",
      "Epoch 388/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8171 - acc: 0.1905 - val_loss: 4.8340 - val_acc: 0.0978\n",
      "Epoch 389/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8138 - acc: 0.1904 - val_loss: 4.8361 - val_acc: 0.0972\n",
      "Epoch 390/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8104 - acc: 0.1902 - val_loss: 4.8361 - val_acc: 0.0972\n",
      "Epoch 391/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8070 - acc: 0.1905 - val_loss: 4.8380 - val_acc: 0.0975\n",
      "Epoch 392/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8036 - acc: 0.1910 - val_loss: 4.8395 - val_acc: 0.0981\n",
      "Epoch 393/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.8003 - acc: 0.1913 - val_loss: 4.8407 - val_acc: 0.0990\n",
      "Epoch 394/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7971 - acc: 0.1924 - val_loss: 4.8426 - val_acc: 0.0990\n",
      "Epoch 395/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7937 - acc: 0.1930 - val_loss: 4.8436 - val_acc: 0.0987\n",
      "Epoch 396/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7906 - acc: 0.1929 - val_loss: 4.8441 - val_acc: 0.0984\n",
      "Epoch 397/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7874 - acc: 0.1939 - val_loss: 4.8464 - val_acc: 0.0984\n",
      "Epoch 398/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7844 - acc: 0.1942 - val_loss: 4.8462 - val_acc: 0.0984\n",
      "Epoch 399/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7811 - acc: 0.1936 - val_loss: 4.8482 - val_acc: 0.0987\n",
      "Epoch 400/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7774 - acc: 0.1953 - val_loss: 4.8485 - val_acc: 0.0984\n",
      "Epoch 401/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7739 - acc: 0.1950 - val_loss: 4.8501 - val_acc: 0.0981\n",
      "Epoch 402/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7704 - acc: 0.1954 - val_loss: 4.8518 - val_acc: 0.0987\n",
      "Epoch 403/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.7671 - acc: 0.1961 - val_loss: 4.8520 - val_acc: 0.0984\n",
      "Epoch 404/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7637 - acc: 0.1961 - val_loss: 4.8541 - val_acc: 0.0987\n",
      "Epoch 405/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7604 - acc: 0.1966 - val_loss: 4.8548 - val_acc: 0.0984\n",
      "Epoch 406/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7571 - acc: 0.1970 - val_loss: 4.8565 - val_acc: 0.0984\n",
      "Epoch 407/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7536 - acc: 0.1979 - val_loss: 4.8564 - val_acc: 0.0984\n",
      "Epoch 408/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7503 - acc: 0.1988 - val_loss: 4.8590 - val_acc: 0.0984\n",
      "Epoch 409/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7471 - acc: 0.1988 - val_loss: 4.8602 - val_acc: 0.0981\n",
      "Epoch 410/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7437 - acc: 0.1988 - val_loss: 4.8611 - val_acc: 0.0981\n",
      "Epoch 411/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7404 - acc: 0.1993 - val_loss: 4.8631 - val_acc: 0.0984\n",
      "Epoch 412/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7370 - acc: 0.1994 - val_loss: 4.8634 - val_acc: 0.0984\n",
      "Epoch 413/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7337 - acc: 0.1998 - val_loss: 4.8659 - val_acc: 0.0984\n",
      "Epoch 414/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7304 - acc: 0.2006 - val_loss: 4.8661 - val_acc: 0.0981\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7272 - acc: 0.2010 - val_loss: 4.8684 - val_acc: 0.0981\n",
      "Epoch 416/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7239 - acc: 0.2015 - val_loss: 4.8688 - val_acc: 0.0981\n",
      "Epoch 417/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7207 - acc: 0.2022 - val_loss: 4.8701 - val_acc: 0.0981\n",
      "Epoch 418/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7174 - acc: 0.2030 - val_loss: 4.8721 - val_acc: 0.0981\n",
      "Epoch 419/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.7142 - acc: 0.2032 - val_loss: 4.8733 - val_acc: 0.0978\n",
      "Epoch 420/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.7109 - acc: 0.2030 - val_loss: 4.8748 - val_acc: 0.0978\n",
      "Epoch 421/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.7077 - acc: 0.2033 - val_loss: 4.8762 - val_acc: 0.0978\n",
      "Epoch 422/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.7045 - acc: 0.2043 - val_loss: 4.8780 - val_acc: 0.0978\n",
      "Epoch 423/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.7014 - acc: 0.2043 - val_loss: 4.8786 - val_acc: 0.0978\n",
      "Epoch 424/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6981 - acc: 0.2048 - val_loss: 4.8806 - val_acc: 0.0978\n",
      "Epoch 425/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6949 - acc: 0.2050 - val_loss: 4.8814 - val_acc: 0.0978\n",
      "Epoch 426/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6917 - acc: 0.2056 - val_loss: 4.8825 - val_acc: 0.0975\n",
      "Epoch 427/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6886 - acc: 0.2060 - val_loss: 4.8848 - val_acc: 0.0978\n",
      "Epoch 428/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6855 - acc: 0.2062 - val_loss: 4.8849 - val_acc: 0.0972\n",
      "Epoch 429/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6822 - acc: 0.2065 - val_loss: 4.8866 - val_acc: 0.0978\n",
      "Epoch 430/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6791 - acc: 0.2072 - val_loss: 4.8877 - val_acc: 0.0978\n",
      "Epoch 431/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6759 - acc: 0.2073 - val_loss: 4.8886 - val_acc: 0.0975\n",
      "Epoch 432/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6728 - acc: 0.2075 - val_loss: 4.8898 - val_acc: 0.0978\n",
      "Epoch 433/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6696 - acc: 0.2078 - val_loss: 4.8914 - val_acc: 0.0975\n",
      "Epoch 434/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6666 - acc: 0.2080 - val_loss: 4.8925 - val_acc: 0.0972\n",
      "Epoch 435/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6635 - acc: 0.2087 - val_loss: 4.8945 - val_acc: 0.0972\n",
      "Epoch 436/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6605 - acc: 0.2091 - val_loss: 4.8941 - val_acc: 0.0966\n",
      "Epoch 437/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6572 - acc: 0.2105 - val_loss: 4.8965 - val_acc: 0.0966\n",
      "Epoch 438/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6543 - acc: 0.2104 - val_loss: 4.8980 - val_acc: 0.0972\n",
      "Epoch 439/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6512 - acc: 0.2109 - val_loss: 4.8974 - val_acc: 0.0952\n",
      "Epoch 440/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6480 - acc: 0.2120 - val_loss: 4.9012 - val_acc: 0.0966\n",
      "Epoch 441/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6450 - acc: 0.2123 - val_loss: 4.9003 - val_acc: 0.0952\n",
      "Epoch 442/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.6420 - acc: 0.2126 - val_loss: 4.9018 - val_acc: 0.0955\n",
      "Epoch 443/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6387 - acc: 0.2128 - val_loss: 4.9042 - val_acc: 0.0952\n",
      "Epoch 444/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6356 - acc: 0.2134 - val_loss: 4.9042 - val_acc: 0.0946\n",
      "Epoch 445/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6325 - acc: 0.2140 - val_loss: 4.9072 - val_acc: 0.0949\n",
      "Epoch 446/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6295 - acc: 0.2136 - val_loss: 4.9072 - val_acc: 0.0949\n",
      "Epoch 447/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6263 - acc: 0.2141 - val_loss: 4.9086 - val_acc: 0.0946\n",
      "Epoch 448/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6232 - acc: 0.2152 - val_loss: 4.9098 - val_acc: 0.0943\n",
      "Epoch 449/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6201 - acc: 0.2158 - val_loss: 4.9112 - val_acc: 0.0943\n",
      "Epoch 450/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6170 - acc: 0.2158 - val_loss: 4.9129 - val_acc: 0.0943\n",
      "Epoch 451/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6141 - acc: 0.2158 - val_loss: 4.9138 - val_acc: 0.0943\n",
      "Epoch 452/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6111 - acc: 0.2161 - val_loss: 4.9155 - val_acc: 0.0943\n",
      "Epoch 453/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6081 - acc: 0.2162 - val_loss: 4.9171 - val_acc: 0.0943\n",
      "Epoch 454/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6051 - acc: 0.2158 - val_loss: 4.9176 - val_acc: 0.0943\n",
      "Epoch 455/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.6021 - acc: 0.2167 - val_loss: 4.9199 - val_acc: 0.0943\n",
      "Epoch 456/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5992 - acc: 0.2170 - val_loss: 4.9202 - val_acc: 0.0943\n",
      "Epoch 457/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5964 - acc: 0.2176 - val_loss: 4.9227 - val_acc: 0.0949\n",
      "Epoch 458/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5935 - acc: 0.2181 - val_loss: 4.9234 - val_acc: 0.0943\n",
      "Epoch 459/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5908 - acc: 0.2178 - val_loss: 4.9237 - val_acc: 0.0943\n",
      "Epoch 460/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5881 - acc: 0.2194 - val_loss: 4.9276 - val_acc: 0.0946\n",
      "Epoch 461/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5855 - acc: 0.2186 - val_loss: 4.9263 - val_acc: 0.0943\n",
      "Epoch 462/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5823 - acc: 0.2197 - val_loss: 4.9295 - val_acc: 0.0943\n",
      "Epoch 463/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5794 - acc: 0.2197 - val_loss: 4.9292 - val_acc: 0.0938\n",
      "Epoch 464/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5762 - acc: 0.2206 - val_loss: 4.9323 - val_acc: 0.0943\n",
      "Epoch 465/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5732 - acc: 0.2217 - val_loss: 4.9319 - val_acc: 0.0935\n",
      "Epoch 466/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5702 - acc: 0.2214 - val_loss: 4.9350 - val_acc: 0.0940\n",
      "Epoch 467/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5673 - acc: 0.2228 - val_loss: 4.9360 - val_acc: 0.0940\n",
      "Epoch 468/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5645 - acc: 0.2224 - val_loss: 4.9368 - val_acc: 0.0932\n",
      "Epoch 469/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5616 - acc: 0.2232 - val_loss: 4.9392 - val_acc: 0.0940\n",
      "Epoch 470/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5585 - acc: 0.2239 - val_loss: 4.9391 - val_acc: 0.0932\n",
      "Epoch 471/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5557 - acc: 0.2242 - val_loss: 4.9432 - val_acc: 0.0937\n",
      "Epoch 472/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5526 - acc: 0.2252 - val_loss: 4.9430 - val_acc: 0.0929\n",
      "Epoch 473/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5498 - acc: 0.2248 - val_loss: 4.9455 - val_acc: 0.0926\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5470 - acc: 0.2250 - val_loss: 4.9472 - val_acc: 0.0929\n",
      "Epoch 475/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5440 - acc: 0.2258 - val_loss: 4.9478 - val_acc: 0.0926\n",
      "Epoch 476/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5412 - acc: 0.2258 - val_loss: 4.9505 - val_acc: 0.0926\n",
      "Epoch 477/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5385 - acc: 0.2270 - val_loss: 4.9507 - val_acc: 0.0923\n",
      "Epoch 478/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5356 - acc: 0.2270 - val_loss: 4.9533 - val_acc: 0.0926\n",
      "Epoch 479/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5327 - acc: 0.2277 - val_loss: 4.9538 - val_acc: 0.0926\n",
      "Epoch 480/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5298 - acc: 0.2277 - val_loss: 4.9557 - val_acc: 0.0926\n",
      "Epoch 481/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5270 - acc: 0.2279 - val_loss: 4.9567 - val_acc: 0.0926\n",
      "Epoch 482/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5241 - acc: 0.2284 - val_loss: 4.9582 - val_acc: 0.0926\n",
      "Epoch 483/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5214 - acc: 0.2283 - val_loss: 4.9600 - val_acc: 0.0926\n",
      "Epoch 484/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5186 - acc: 0.2290 - val_loss: 4.9610 - val_acc: 0.0923\n",
      "Epoch 485/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5158 - acc: 0.2294 - val_loss: 4.9628 - val_acc: 0.0926\n",
      "Epoch 486/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5129 - acc: 0.2297 - val_loss: 4.9647 - val_acc: 0.0926\n",
      "Epoch 487/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5102 - acc: 0.2300 - val_loss: 4.9659 - val_acc: 0.0923\n",
      "Epoch 488/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5074 - acc: 0.2303 - val_loss: 4.9673 - val_acc: 0.0920\n",
      "Epoch 489/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5046 - acc: 0.2311 - val_loss: 4.9679 - val_acc: 0.0917\n",
      "Epoch 490/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.5019 - acc: 0.2311 - val_loss: 4.9695 - val_acc: 0.0917\n",
      "Epoch 491/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4992 - acc: 0.2316 - val_loss: 4.9712 - val_acc: 0.0917\n",
      "Epoch 492/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4967 - acc: 0.2321 - val_loss: 4.9711 - val_acc: 0.0911\n",
      "Epoch 493/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4939 - acc: 0.2326 - val_loss: 4.9729 - val_acc: 0.0911\n",
      "Epoch 494/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4911 - acc: 0.2327 - val_loss: 4.9754 - val_acc: 0.0911\n",
      "Epoch 495/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4884 - acc: 0.2332 - val_loss: 4.9755 - val_acc: 0.0909\n",
      "Epoch 496/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4857 - acc: 0.2335 - val_loss: 4.9777 - val_acc: 0.0909\n",
      "Epoch 497/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4828 - acc: 0.2337 - val_loss: 4.9791 - val_acc: 0.0906\n",
      "Epoch 498/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4801 - acc: 0.2344 - val_loss: 4.9808 - val_acc: 0.0909\n",
      "Epoch 499/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4774 - acc: 0.2343 - val_loss: 4.9828 - val_acc: 0.0914\n",
      "Epoch 500/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4748 - acc: 0.2348 - val_loss: 4.9825 - val_acc: 0.0906\n",
      "Epoch 501/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4721 - acc: 0.2348 - val_loss: 4.9856 - val_acc: 0.0911\n",
      "Epoch 502/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4694 - acc: 0.2353 - val_loss: 4.9867 - val_acc: 0.0897\n",
      "Epoch 503/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4667 - acc: 0.2358 - val_loss: 4.9876 - val_acc: 0.0897\n",
      "Epoch 504/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4639 - acc: 0.2369 - val_loss: 4.9895 - val_acc: 0.0897\n",
      "Epoch 505/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4614 - acc: 0.2373 - val_loss: 4.9906 - val_acc: 0.0894\n",
      "Epoch 506/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4586 - acc: 0.2374 - val_loss: 4.9926 - val_acc: 0.0900\n",
      "Epoch 507/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4560 - acc: 0.2376 - val_loss: 4.9943 - val_acc: 0.0897\n",
      "Epoch 508/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.4532 - acc: 0.2384 - val_loss: 4.9956 - val_acc: 0.0897\n",
      "Epoch 509/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4507 - acc: 0.2381 - val_loss: 4.9968 - val_acc: 0.0897\n",
      "Epoch 510/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4481 - acc: 0.2390 - val_loss: 4.9995 - val_acc: 0.0894\n",
      "Epoch 511/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4454 - acc: 0.2387 - val_loss: 5.0010 - val_acc: 0.0900\n",
      "Epoch 512/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4429 - acc: 0.2393 - val_loss: 5.0021 - val_acc: 0.0900\n",
      "Epoch 513/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4405 - acc: 0.2398 - val_loss: 5.0037 - val_acc: 0.0897\n",
      "Epoch 514/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4379 - acc: 0.2409 - val_loss: 5.0044 - val_acc: 0.0903\n",
      "Epoch 515/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4352 - acc: 0.2409 - val_loss: 5.0068 - val_acc: 0.0894\n",
      "Epoch 516/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4329 - acc: 0.2407 - val_loss: 5.0095 - val_acc: 0.0897\n",
      "Epoch 517/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4312 - acc: 0.2410 - val_loss: 5.0090 - val_acc: 0.0900\n",
      "Epoch 518/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4288 - acc: 0.2419 - val_loss: 5.0109 - val_acc: 0.0906\n",
      "Epoch 519/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4260 - acc: 0.2411 - val_loss: 5.0102 - val_acc: 0.0903\n",
      "Epoch 520/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4236 - acc: 0.2419 - val_loss: 5.0127 - val_acc: 0.0897\n",
      "Epoch 521/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4208 - acc: 0.2425 - val_loss: 5.0131 - val_acc: 0.0900\n",
      "Epoch 522/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4186 - acc: 0.2424 - val_loss: 5.0146 - val_acc: 0.0903\n",
      "Epoch 523/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4155 - acc: 0.2433 - val_loss: 5.0159 - val_acc: 0.0900\n",
      "Epoch 524/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4128 - acc: 0.2438 - val_loss: 5.0172 - val_acc: 0.0900\n",
      "Epoch 525/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4103 - acc: 0.2443 - val_loss: 5.0192 - val_acc: 0.0903\n",
      "Epoch 526/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4078 - acc: 0.2443 - val_loss: 5.0206 - val_acc: 0.0900\n",
      "Epoch 527/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4052 - acc: 0.2456 - val_loss: 5.0223 - val_acc: 0.0906\n",
      "Epoch 528/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4026 - acc: 0.2461 - val_loss: 5.0234 - val_acc: 0.0900\n",
      "Epoch 529/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.4001 - acc: 0.2466 - val_loss: 5.0264 - val_acc: 0.0903\n",
      "Epoch 530/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3976 - acc: 0.2463 - val_loss: 5.0269 - val_acc: 0.0900\n",
      "Epoch 531/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3950 - acc: 0.2471 - val_loss: 5.0290 - val_acc: 0.0900\n",
      "Epoch 532/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3927 - acc: 0.2471 - val_loss: 5.0299 - val_acc: 0.0897\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3901 - acc: 0.2473 - val_loss: 5.0324 - val_acc: 0.0897\n",
      "Epoch 534/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3877 - acc: 0.2477 - val_loss: 5.0317 - val_acc: 0.0894\n",
      "Epoch 535/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3850 - acc: 0.2481 - val_loss: 5.0350 - val_acc: 0.0897\n",
      "Epoch 536/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3825 - acc: 0.2482 - val_loss: 5.0357 - val_acc: 0.0894\n",
      "Epoch 537/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3803 - acc: 0.2483 - val_loss: 5.0373 - val_acc: 0.0900\n",
      "Epoch 538/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.3777 - acc: 0.2486 - val_loss: 5.0390 - val_acc: 0.0900\n",
      "Epoch 539/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.3752 - acc: 0.2491 - val_loss: 5.0392 - val_acc: 0.0897\n",
      "Epoch 540/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.3727 - acc: 0.2492 - val_loss: 5.0421 - val_acc: 0.0900\n",
      "Epoch 541/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3704 - acc: 0.2498 - val_loss: 5.0421 - val_acc: 0.0894\n",
      "Epoch 542/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3680 - acc: 0.2504 - val_loss: 5.0448 - val_acc: 0.0897\n",
      "Epoch 543/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3657 - acc: 0.2509 - val_loss: 5.0459 - val_acc: 0.0900\n",
      "Epoch 544/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3632 - acc: 0.2506 - val_loss: 5.0467 - val_acc: 0.0900\n",
      "Epoch 545/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3608 - acc: 0.2505 - val_loss: 5.0491 - val_acc: 0.0894\n",
      "Epoch 546/1000\n",
      "1148/1148 [==============================] - 6s 6ms/step - loss: 2.3586 - acc: 0.2513 - val_loss: 5.0505 - val_acc: 0.0897\n",
      "Epoch 547/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3561 - acc: 0.2512 - val_loss: 5.0511 - val_acc: 0.0894\n",
      "Epoch 548/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3537 - acc: 0.2518 - val_loss: 5.0537 - val_acc: 0.0894\n",
      "Epoch 549/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3513 - acc: 0.2517 - val_loss: 5.0540 - val_acc: 0.0900\n",
      "Epoch 550/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3490 - acc: 0.2525 - val_loss: 5.0569 - val_acc: 0.0897\n",
      "Epoch 551/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3465 - acc: 0.2528 - val_loss: 5.0570 - val_acc: 0.0900\n",
      "Epoch 552/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3445 - acc: 0.2525 - val_loss: 5.0599 - val_acc: 0.0894\n",
      "Epoch 553/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3421 - acc: 0.2525 - val_loss: 5.0611 - val_acc: 0.0891\n",
      "Epoch 554/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3398 - acc: 0.2533 - val_loss: 5.0622 - val_acc: 0.0897\n",
      "Epoch 555/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3372 - acc: 0.2535 - val_loss: 5.0640 - val_acc: 0.0888\n",
      "Epoch 556/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3350 - acc: 0.2541 - val_loss: 5.0654 - val_acc: 0.0894\n",
      "Epoch 557/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3325 - acc: 0.2544 - val_loss: 5.0661 - val_acc: 0.0891\n",
      "Epoch 558/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3302 - acc: 0.2545 - val_loss: 5.0684 - val_acc: 0.0894\n",
      "Epoch 559/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3277 - acc: 0.2547 - val_loss: 5.0692 - val_acc: 0.0885\n",
      "Epoch 560/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3255 - acc: 0.2553 - val_loss: 5.0709 - val_acc: 0.0888\n",
      "Epoch 561/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3231 - acc: 0.2558 - val_loss: 5.0730 - val_acc: 0.0888\n",
      "Epoch 562/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3208 - acc: 0.2562 - val_loss: 5.0734 - val_acc: 0.0897\n",
      "Epoch 563/1000\n",
      "1148/1148 [==============================] - 6s 6ms/step - loss: 2.3187 - acc: 0.2559 - val_loss: 5.0756 - val_acc: 0.0880\n",
      "Epoch 564/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3163 - acc: 0.2567 - val_loss: 5.0766 - val_acc: 0.0883\n",
      "Epoch 565/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3140 - acc: 0.2567 - val_loss: 5.0779 - val_acc: 0.0880\n",
      "Epoch 566/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.3119 - acc: 0.2572 - val_loss: 5.0806 - val_acc: 0.0883\n",
      "Epoch 567/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3095 - acc: 0.2570 - val_loss: 5.0805 - val_acc: 0.0888\n",
      "Epoch 568/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3073 - acc: 0.2571 - val_loss: 5.0832 - val_acc: 0.0880\n",
      "Epoch 569/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3051 - acc: 0.2576 - val_loss: 5.0842 - val_acc: 0.0885\n",
      "Epoch 570/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3030 - acc: 0.2575 - val_loss: 5.0854 - val_acc: 0.0880\n",
      "Epoch 571/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.3006 - acc: 0.2584 - val_loss: 5.0876 - val_acc: 0.0888\n",
      "Epoch 572/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2983 - acc: 0.2588 - val_loss: 5.0882 - val_acc: 0.0885\n",
      "Epoch 573/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2961 - acc: 0.2592 - val_loss: 5.0899 - val_acc: 0.0885\n",
      "Epoch 574/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2938 - acc: 0.2597 - val_loss: 5.0915 - val_acc: 0.0891\n",
      "Epoch 575/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2915 - acc: 0.2599 - val_loss: 5.0923 - val_acc: 0.0880\n",
      "Epoch 576/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2896 - acc: 0.2602 - val_loss: 5.0939 - val_acc: 0.0891\n",
      "Epoch 577/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2874 - acc: 0.2602 - val_loss: 5.0951 - val_acc: 0.0891\n",
      "Epoch 578/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2851 - acc: 0.2602 - val_loss: 5.0969 - val_acc: 0.0880\n",
      "Epoch 579/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2828 - acc: 0.2604 - val_loss: 5.0980 - val_acc: 0.0894\n",
      "Epoch 580/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2807 - acc: 0.2602 - val_loss: 5.0993 - val_acc: 0.0877\n",
      "Epoch 581/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2787 - acc: 0.2607 - val_loss: 5.1017 - val_acc: 0.0891\n",
      "Epoch 582/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2764 - acc: 0.2615 - val_loss: 5.1018 - val_acc: 0.0877\n",
      "Epoch 583/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2748 - acc: 0.2606 - val_loss: 5.1042 - val_acc: 0.0883\n",
      "Epoch 584/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2729 - acc: 0.2615 - val_loss: 5.1048 - val_acc: 0.0885\n",
      "Epoch 585/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2703 - acc: 0.2612 - val_loss: 5.1058 - val_acc: 0.0888\n",
      "Epoch 586/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.2682 - acc: 0.2623 - val_loss: 5.1082 - val_acc: 0.0891\n",
      "Epoch 587/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2659 - acc: 0.2620 - val_loss: 5.1087 - val_acc: 0.0883\n",
      "Epoch 588/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.2635 - acc: 0.2630 - val_loss: 5.1116 - val_acc: 0.0891\n",
      "Epoch 589/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2612 - acc: 0.2632 - val_loss: 5.1117 - val_acc: 0.0877\n",
      "Epoch 590/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2593 - acc: 0.2633 - val_loss: 5.1143 - val_acc: 0.0891\n",
      "Epoch 591/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.2570 - acc: 0.2634 - val_loss: 5.1147 - val_acc: 0.0877\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.2548 - acc: 0.2639 - val_loss: 5.1163 - val_acc: 0.0885\n",
      "Epoch 593/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2528 - acc: 0.2642 - val_loss: 5.1181 - val_acc: 0.0880\n",
      "Epoch 594/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.2506 - acc: 0.2651 - val_loss: 5.1191 - val_acc: 0.0883\n",
      "Epoch 595/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2484 - acc: 0.2655 - val_loss: 5.1215 - val_acc: 0.0883\n",
      "Epoch 596/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2462 - acc: 0.2659 - val_loss: 5.1219 - val_acc: 0.0880\n",
      "Epoch 597/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.2441 - acc: 0.2662 - val_loss: 5.1242 - val_acc: 0.0888\n",
      "Epoch 598/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2421 - acc: 0.2660 - val_loss: 5.1243 - val_acc: 0.0883\n",
      "Epoch 599/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2398 - acc: 0.2668 - val_loss: 5.1265 - val_acc: 0.0883\n",
      "Epoch 600/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2377 - acc: 0.2671 - val_loss: 5.1280 - val_acc: 0.0885\n",
      "Epoch 601/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.2358 - acc: 0.2672 - val_loss: 5.1301 - val_acc: 0.0885\n",
      "Epoch 602/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.2337 - acc: 0.2672 - val_loss: 5.1306 - val_acc: 0.0883\n",
      "Epoch 603/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.2316 - acc: 0.2677 - val_loss: 5.1327 - val_acc: 0.0883\n",
      "Epoch 604/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.2296 - acc: 0.2675 - val_loss: 5.1330 - val_acc: 0.0885\n",
      "Epoch 605/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2277 - acc: 0.2679 - val_loss: 5.1342 - val_acc: 0.0894\n",
      "Epoch 606/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2255 - acc: 0.2681 - val_loss: 5.1364 - val_acc: 0.0885\n",
      "Epoch 607/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2233 - acc: 0.2687 - val_loss: 5.1376 - val_acc: 0.0888\n",
      "Epoch 608/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.2212 - acc: 0.2684 - val_loss: 5.1393 - val_acc: 0.0883\n",
      "Epoch 609/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2193 - acc: 0.2690 - val_loss: 5.1408 - val_acc: 0.0885\n",
      "Epoch 610/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2172 - acc: 0.2688 - val_loss: 5.1418 - val_acc: 0.0885\n",
      "Epoch 611/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2148 - acc: 0.2692 - val_loss: 5.1441 - val_acc: 0.0880\n",
      "Epoch 612/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2128 - acc: 0.2700 - val_loss: 5.1449 - val_acc: 0.0885\n",
      "Epoch 613/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2107 - acc: 0.2705 - val_loss: 5.1476 - val_acc: 0.0880\n",
      "Epoch 614/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2087 - acc: 0.2707 - val_loss: 5.1484 - val_acc: 0.0885\n",
      "Epoch 615/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2067 - acc: 0.2705 - val_loss: 5.1504 - val_acc: 0.0883\n",
      "Epoch 616/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2047 - acc: 0.2704 - val_loss: 5.1512 - val_acc: 0.0885\n",
      "Epoch 617/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2028 - acc: 0.2708 - val_loss: 5.1530 - val_acc: 0.0883\n",
      "Epoch 618/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.2006 - acc: 0.2705 - val_loss: 5.1550 - val_acc: 0.0880\n",
      "Epoch 619/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1988 - acc: 0.2708 - val_loss: 5.1565 - val_acc: 0.0883\n",
      "Epoch 620/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1967 - acc: 0.2719 - val_loss: 5.1583 - val_acc: 0.0880\n",
      "Epoch 621/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1946 - acc: 0.2718 - val_loss: 5.1594 - val_acc: 0.0883\n",
      "Epoch 622/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1927 - acc: 0.2720 - val_loss: 5.1614 - val_acc: 0.0883\n",
      "Epoch 623/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1906 - acc: 0.2722 - val_loss: 5.1619 - val_acc: 0.0885\n",
      "Epoch 624/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1889 - acc: 0.2724 - val_loss: 5.1638 - val_acc: 0.0883\n",
      "Epoch 625/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1871 - acc: 0.2729 - val_loss: 5.1650 - val_acc: 0.0885\n",
      "Epoch 626/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1848 - acc: 0.2732 - val_loss: 5.1658 - val_acc: 0.0885\n",
      "Epoch 627/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1828 - acc: 0.2734 - val_loss: 5.1679 - val_acc: 0.0885\n",
      "Epoch 628/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1809 - acc: 0.2737 - val_loss: 5.1692 - val_acc: 0.0885\n",
      "Epoch 629/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1789 - acc: 0.2740 - val_loss: 5.1717 - val_acc: 0.0883\n",
      "Epoch 630/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1770 - acc: 0.2745 - val_loss: 5.1717 - val_acc: 0.0885\n",
      "Epoch 631/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1749 - acc: 0.2747 - val_loss: 5.1735 - val_acc: 0.0888\n",
      "Epoch 632/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1730 - acc: 0.2747 - val_loss: 5.1750 - val_acc: 0.0888\n",
      "Epoch 633/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1710 - acc: 0.2753 - val_loss: 5.1768 - val_acc: 0.0888\n",
      "Epoch 634/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1690 - acc: 0.2755 - val_loss: 5.1784 - val_acc: 0.0888\n",
      "Epoch 635/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1671 - acc: 0.2759 - val_loss: 5.1795 - val_acc: 0.0888\n",
      "Epoch 636/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1652 - acc: 0.2761 - val_loss: 5.1815 - val_acc: 0.0888\n",
      "Epoch 637/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1632 - acc: 0.2766 - val_loss: 5.1824 - val_acc: 0.0888\n",
      "Epoch 638/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1613 - acc: 0.2769 - val_loss: 5.1837 - val_acc: 0.0891\n",
      "Epoch 639/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1593 - acc: 0.2769 - val_loss: 5.1852 - val_acc: 0.0891\n",
      "Epoch 640/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1574 - acc: 0.2773 - val_loss: 5.1865 - val_acc: 0.0891\n",
      "Epoch 641/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1555 - acc: 0.2779 - val_loss: 5.1879 - val_acc: 0.0891\n",
      "Epoch 642/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1536 - acc: 0.2780 - val_loss: 5.1892 - val_acc: 0.0888\n",
      "Epoch 643/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1520 - acc: 0.2779 - val_loss: 5.1909 - val_acc: 0.0888\n",
      "Epoch 644/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1502 - acc: 0.2786 - val_loss: 5.1923 - val_acc: 0.0888\n",
      "Epoch 645/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1481 - acc: 0.2786 - val_loss: 5.1936 - val_acc: 0.0888\n",
      "Epoch 646/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1461 - acc: 0.2789 - val_loss: 5.1958 - val_acc: 0.0888\n",
      "Epoch 647/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.1443 - acc: 0.2799 - val_loss: 5.1964 - val_acc: 0.0888\n",
      "Epoch 648/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1428 - acc: 0.2795 - val_loss: 5.1987 - val_acc: 0.0888\n",
      "Epoch 649/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.1410 - acc: 0.2801 - val_loss: 5.2001 - val_acc: 0.0888\n",
      "Epoch 650/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.1391 - acc: 0.2804 - val_loss: 5.2017 - val_acc: 0.0891\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1371 - acc: 0.2811 - val_loss: 5.2039 - val_acc: 0.0888\n",
      "Epoch 652/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1352 - acc: 0.2806 - val_loss: 5.2036 - val_acc: 0.0885\n",
      "Epoch 653/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1341 - acc: 0.2811 - val_loss: 5.2065 - val_acc: 0.0885\n",
      "Epoch 654/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1323 - acc: 0.2810 - val_loss: 5.2081 - val_acc: 0.0883\n",
      "Epoch 655/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.1299 - acc: 0.2811 - val_loss: 5.2085 - val_acc: 0.0883\n",
      "Epoch 656/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1281 - acc: 0.2814 - val_loss: 5.2109 - val_acc: 0.0880\n",
      "Epoch 657/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1261 - acc: 0.2817 - val_loss: 5.2121 - val_acc: 0.0877\n",
      "Epoch 658/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1241 - acc: 0.2815 - val_loss: 5.2137 - val_acc: 0.0877\n",
      "Epoch 659/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1223 - acc: 0.2818 - val_loss: 5.2150 - val_acc: 0.0880\n",
      "Epoch 660/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1204 - acc: 0.2821 - val_loss: 5.2168 - val_acc: 0.0877\n",
      "Epoch 661/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1186 - acc: 0.2820 - val_loss: 5.2182 - val_acc: 0.0877\n",
      "Epoch 662/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1168 - acc: 0.2824 - val_loss: 5.2194 - val_acc: 0.0874\n",
      "Epoch 663/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1150 - acc: 0.2825 - val_loss: 5.2215 - val_acc: 0.0880\n",
      "Epoch 664/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1132 - acc: 0.2830 - val_loss: 5.2229 - val_acc: 0.0874\n",
      "Epoch 665/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1115 - acc: 0.2828 - val_loss: 5.2243 - val_acc: 0.0877\n",
      "Epoch 666/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1096 - acc: 0.2836 - val_loss: 5.2249 - val_acc: 0.0877\n",
      "Epoch 667/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1078 - acc: 0.2839 - val_loss: 5.2270 - val_acc: 0.0874\n",
      "Epoch 668/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1061 - acc: 0.2843 - val_loss: 5.2281 - val_acc: 0.0868\n",
      "Epoch 669/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1044 - acc: 0.2850 - val_loss: 5.2298 - val_acc: 0.0877\n",
      "Epoch 670/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1026 - acc: 0.2845 - val_loss: 5.2315 - val_acc: 0.0877\n",
      "Epoch 671/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.1008 - acc: 0.2851 - val_loss: 5.2322 - val_acc: 0.0871\n",
      "Epoch 672/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0990 - acc: 0.2854 - val_loss: 5.2343 - val_acc: 0.0868\n",
      "Epoch 673/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0972 - acc: 0.2851 - val_loss: 5.2358 - val_acc: 0.0874\n",
      "Epoch 674/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0955 - acc: 0.2854 - val_loss: 5.2369 - val_acc: 0.0871\n",
      "Epoch 675/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0937 - acc: 0.2862 - val_loss: 5.2386 - val_acc: 0.0871\n",
      "Epoch 676/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0922 - acc: 0.2862 - val_loss: 5.2397 - val_acc: 0.0871\n",
      "Epoch 677/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0904 - acc: 0.2865 - val_loss: 5.2416 - val_acc: 0.0877\n",
      "Epoch 678/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0887 - acc: 0.2866 - val_loss: 5.2420 - val_acc: 0.0877\n",
      "Epoch 679/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0871 - acc: 0.2867 - val_loss: 5.2445 - val_acc: 0.0877\n",
      "Epoch 680/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0854 - acc: 0.2874 - val_loss: 5.2456 - val_acc: 0.0871\n",
      "Epoch 681/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0834 - acc: 0.2872 - val_loss: 5.2471 - val_acc: 0.0874\n",
      "Epoch 682/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0817 - acc: 0.2880 - val_loss: 5.2487 - val_acc: 0.0877\n",
      "Epoch 683/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0800 - acc: 0.2880 - val_loss: 5.2503 - val_acc: 0.0877\n",
      "Epoch 684/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0782 - acc: 0.2886 - val_loss: 5.2517 - val_acc: 0.0874\n",
      "Epoch 685/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0767 - acc: 0.2883 - val_loss: 5.2532 - val_acc: 0.0874\n",
      "Epoch 686/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0752 - acc: 0.2890 - val_loss: 5.2543 - val_acc: 0.0874\n",
      "Epoch 687/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0737 - acc: 0.2885 - val_loss: 5.2559 - val_acc: 0.0874\n",
      "Epoch 688/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0718 - acc: 0.2894 - val_loss: 5.2574 - val_acc: 0.0874\n",
      "Epoch 689/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0700 - acc: 0.2899 - val_loss: 5.2583 - val_acc: 0.0877\n",
      "Epoch 690/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0684 - acc: 0.2899 - val_loss: 5.2605 - val_acc: 0.0877\n",
      "Epoch 691/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0667 - acc: 0.2908 - val_loss: 5.2622 - val_acc: 0.0874\n",
      "Epoch 692/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0652 - acc: 0.2906 - val_loss: 5.2633 - val_acc: 0.0874\n",
      "Epoch 693/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0637 - acc: 0.2913 - val_loss: 5.2643 - val_acc: 0.0874\n",
      "Epoch 694/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0625 - acc: 0.2913 - val_loss: 5.2665 - val_acc: 0.0883\n",
      "Epoch 695/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.0607 - acc: 0.2913 - val_loss: 5.2674 - val_acc: 0.0868\n",
      "Epoch 696/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.0593 - acc: 0.2914 - val_loss: 5.2700 - val_acc: 0.0874\n",
      "Epoch 697/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0577 - acc: 0.2912 - val_loss: 5.2706 - val_acc: 0.0865\n",
      "Epoch 698/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0565 - acc: 0.2925 - val_loss: 5.2738 - val_acc: 0.0877\n",
      "Epoch 699/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.0549 - acc: 0.2914 - val_loss: 5.2738 - val_acc: 0.0862\n",
      "Epoch 700/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.0533 - acc: 0.2926 - val_loss: 5.2765 - val_acc: 0.0874\n",
      "Epoch 701/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0509 - acc: 0.2918 - val_loss: 5.2775 - val_acc: 0.0862\n",
      "Epoch 702/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0492 - acc: 0.2936 - val_loss: 5.2799 - val_acc: 0.0871\n",
      "Epoch 703/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0472 - acc: 0.2930 - val_loss: 5.2808 - val_acc: 0.0865\n",
      "Epoch 704/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0456 - acc: 0.2938 - val_loss: 5.2831 - val_acc: 0.0856\n",
      "Epoch 705/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0437 - acc: 0.2939 - val_loss: 5.2842 - val_acc: 0.0865\n",
      "Epoch 706/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0418 - acc: 0.2942 - val_loss: 5.2863 - val_acc: 0.0865\n",
      "Epoch 707/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0403 - acc: 0.2946 - val_loss: 5.2878 - val_acc: 0.0865\n",
      "Epoch 708/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0384 - acc: 0.2951 - val_loss: 5.2890 - val_acc: 0.0856\n",
      "Epoch 709/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0368 - acc: 0.2947 - val_loss: 5.2911 - val_acc: 0.0854\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0350 - acc: 0.2950 - val_loss: 5.2927 - val_acc: 0.0854\n",
      "Epoch 711/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0333 - acc: 0.2960 - val_loss: 5.2943 - val_acc: 0.0854\n",
      "Epoch 712/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0316 - acc: 0.2955 - val_loss: 5.2953 - val_acc: 0.0854\n",
      "Epoch 713/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0300 - acc: 0.2962 - val_loss: 5.2973 - val_acc: 0.0859\n",
      "Epoch 714/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0285 - acc: 0.2965 - val_loss: 5.2983 - val_acc: 0.0851\n",
      "Epoch 715/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0268 - acc: 0.2970 - val_loss: 5.2998 - val_acc: 0.0851\n",
      "Epoch 716/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0251 - acc: 0.2975 - val_loss: 5.3012 - val_acc: 0.0856\n",
      "Epoch 717/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0238 - acc: 0.2978 - val_loss: 5.3023 - val_acc: 0.0851\n",
      "Epoch 718/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0221 - acc: 0.2979 - val_loss: 5.3038 - val_acc: 0.0851\n",
      "Epoch 719/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.0205 - acc: 0.2979 - val_loss: 5.3058 - val_acc: 0.0854\n",
      "Epoch 720/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0191 - acc: 0.2985 - val_loss: 5.3074 - val_acc: 0.0854\n",
      "Epoch 721/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 2.0175 - acc: 0.2983 - val_loss: 5.3084 - val_acc: 0.0851\n",
      "Epoch 722/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0158 - acc: 0.2995 - val_loss: 5.3105 - val_acc: 0.0851\n",
      "Epoch 723/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0142 - acc: 0.2994 - val_loss: 5.3118 - val_acc: 0.0848\n",
      "Epoch 724/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0126 - acc: 0.2998 - val_loss: 5.3139 - val_acc: 0.0848\n",
      "Epoch 725/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0112 - acc: 0.3005 - val_loss: 5.3153 - val_acc: 0.0848\n",
      "Epoch 726/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0097 - acc: 0.3001 - val_loss: 5.3162 - val_acc: 0.0848\n",
      "Epoch 727/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0080 - acc: 0.3011 - val_loss: 5.3180 - val_acc: 0.0851\n",
      "Epoch 728/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0067 - acc: 0.3010 - val_loss: 5.3190 - val_acc: 0.0839\n",
      "Epoch 729/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0050 - acc: 0.3016 - val_loss: 5.3213 - val_acc: 0.0839\n",
      "Epoch 730/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0037 - acc: 0.3019 - val_loss: 5.3225 - val_acc: 0.0839\n",
      "Epoch 731/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0020 - acc: 0.3015 - val_loss: 5.3239 - val_acc: 0.0842\n",
      "Epoch 732/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.0004 - acc: 0.3017 - val_loss: 5.3255 - val_acc: 0.0842\n",
      "Epoch 733/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9988 - acc: 0.3021 - val_loss: 5.3260 - val_acc: 0.0836\n",
      "Epoch 734/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9975 - acc: 0.3026 - val_loss: 5.3278 - val_acc: 0.0842\n",
      "Epoch 735/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9956 - acc: 0.3023 - val_loss: 5.3290 - val_acc: 0.0842\n",
      "Epoch 736/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9942 - acc: 0.3027 - val_loss: 5.3302 - val_acc: 0.0839\n",
      "Epoch 737/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9926 - acc: 0.3028 - val_loss: 5.3326 - val_acc: 0.0839\n",
      "Epoch 738/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9911 - acc: 0.3027 - val_loss: 5.3334 - val_acc: 0.0836\n",
      "Epoch 739/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9896 - acc: 0.3034 - val_loss: 5.3352 - val_acc: 0.0839\n",
      "Epoch 740/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9879 - acc: 0.3040 - val_loss: 5.3363 - val_acc: 0.0836\n",
      "Epoch 741/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9865 - acc: 0.3045 - val_loss: 5.3380 - val_acc: 0.0836\n",
      "Epoch 742/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9848 - acc: 0.3041 - val_loss: 5.3396 - val_acc: 0.0842\n",
      "Epoch 743/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9836 - acc: 0.3044 - val_loss: 5.3408 - val_acc: 0.0839\n",
      "Epoch 744/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 1.9819 - acc: 0.3052 - val_loss: 5.3428 - val_acc: 0.0842\n",
      "Epoch 745/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9806 - acc: 0.3047 - val_loss: 5.3442 - val_acc: 0.0839\n",
      "Epoch 746/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9791 - acc: 0.3055 - val_loss: 5.3455 - val_acc: 0.0842\n",
      "Epoch 747/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 1.9776 - acc: 0.3055 - val_loss: 5.3473 - val_acc: 0.0833\n",
      "Epoch 748/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9761 - acc: 0.3060 - val_loss: 5.3480 - val_acc: 0.0836\n",
      "Epoch 749/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9746 - acc: 0.3059 - val_loss: 5.3497 - val_acc: 0.0833\n",
      "Epoch 750/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9733 - acc: 0.3057 - val_loss: 5.3512 - val_acc: 0.0836\n",
      "Epoch 751/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9720 - acc: 0.3064 - val_loss: 5.3530 - val_acc: 0.0830\n",
      "Epoch 752/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9706 - acc: 0.3061 - val_loss: 5.3553 - val_acc: 0.0833\n",
      "Epoch 753/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9694 - acc: 0.3068 - val_loss: 5.3554 - val_acc: 0.0828\n",
      "Epoch 754/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9678 - acc: 0.3071 - val_loss: 5.3577 - val_acc: 0.0828\n",
      "Epoch 755/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9664 - acc: 0.3072 - val_loss: 5.3587 - val_acc: 0.0828\n",
      "Epoch 756/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9648 - acc: 0.3073 - val_loss: 5.3599 - val_acc: 0.0825\n",
      "Epoch 757/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9631 - acc: 0.3078 - val_loss: 5.3631 - val_acc: 0.0828\n",
      "Epoch 758/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9623 - acc: 0.3068 - val_loss: 5.3636 - val_acc: 0.0828\n",
      "Epoch 759/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9604 - acc: 0.3076 - val_loss: 5.3650 - val_acc: 0.0830\n",
      "Epoch 760/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9591 - acc: 0.3070 - val_loss: 5.3670 - val_acc: 0.0822\n",
      "Epoch 761/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9574 - acc: 0.3079 - val_loss: 5.3682 - val_acc: 0.0825\n",
      "Epoch 762/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9559 - acc: 0.3081 - val_loss: 5.3701 - val_acc: 0.0828\n",
      "Epoch 763/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9544 - acc: 0.3081 - val_loss: 5.3710 - val_acc: 0.0825\n",
      "Epoch 764/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9528 - acc: 0.3081 - val_loss: 5.3726 - val_acc: 0.0822\n",
      "Epoch 765/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9513 - acc: 0.3087 - val_loss: 5.3739 - val_acc: 0.0819\n",
      "Epoch 766/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9497 - acc: 0.3084 - val_loss: 5.3755 - val_acc: 0.0813\n",
      "Epoch 767/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9483 - acc: 0.3088 - val_loss: 5.3761 - val_acc: 0.0819\n",
      "Epoch 768/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9469 - acc: 0.3097 - val_loss: 5.3782 - val_acc: 0.0816\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9456 - acc: 0.3092 - val_loss: 5.3797 - val_acc: 0.0816\n",
      "Epoch 770/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9440 - acc: 0.3096 - val_loss: 5.3814 - val_acc: 0.0819\n",
      "Epoch 771/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9427 - acc: 0.3097 - val_loss: 5.3829 - val_acc: 0.0819\n",
      "Epoch 772/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9412 - acc: 0.3102 - val_loss: 5.3844 - val_acc: 0.0816\n",
      "Epoch 773/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9397 - acc: 0.3111 - val_loss: 5.3861 - val_acc: 0.0813\n",
      "Epoch 774/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9384 - acc: 0.3107 - val_loss: 5.3876 - val_acc: 0.0813\n",
      "Epoch 775/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9370 - acc: 0.3106 - val_loss: 5.3887 - val_acc: 0.0813\n",
      "Epoch 776/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9356 - acc: 0.3113 - val_loss: 5.3904 - val_acc: 0.0813\n",
      "Epoch 777/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9342 - acc: 0.3115 - val_loss: 5.3920 - val_acc: 0.0813\n",
      "Epoch 778/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9329 - acc: 0.3114 - val_loss: 5.3937 - val_acc: 0.0819\n",
      "Epoch 779/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9315 - acc: 0.3112 - val_loss: 5.3946 - val_acc: 0.0816\n",
      "Epoch 780/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9302 - acc: 0.3123 - val_loss: 5.3968 - val_acc: 0.0819\n",
      "Epoch 781/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9286 - acc: 0.3125 - val_loss: 5.3983 - val_acc: 0.0819\n",
      "Epoch 782/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9274 - acc: 0.3129 - val_loss: 5.3998 - val_acc: 0.0819\n",
      "Epoch 783/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9260 - acc: 0.3121 - val_loss: 5.4006 - val_acc: 0.0819\n",
      "Epoch 784/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9247 - acc: 0.3132 - val_loss: 5.4031 - val_acc: 0.0819\n",
      "Epoch 785/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9237 - acc: 0.3133 - val_loss: 5.4043 - val_acc: 0.0819\n",
      "Epoch 786/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9221 - acc: 0.3132 - val_loss: 5.4056 - val_acc: 0.0819\n",
      "Epoch 787/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9209 - acc: 0.3137 - val_loss: 5.4080 - val_acc: 0.0816\n",
      "Epoch 788/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9194 - acc: 0.3140 - val_loss: 5.4086 - val_acc: 0.0819\n",
      "Epoch 789/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9182 - acc: 0.3140 - val_loss: 5.4112 - val_acc: 0.0819\n",
      "Epoch 790/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9167 - acc: 0.3142 - val_loss: 5.4126 - val_acc: 0.0816\n",
      "Epoch 791/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9154 - acc: 0.3139 - val_loss: 5.4142 - val_acc: 0.0816\n",
      "Epoch 792/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9138 - acc: 0.3145 - val_loss: 5.4150 - val_acc: 0.0819\n",
      "Epoch 793/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9124 - acc: 0.3153 - val_loss: 5.4167 - val_acc: 0.0819\n",
      "Epoch 794/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9110 - acc: 0.3155 - val_loss: 5.4179 - val_acc: 0.0819\n",
      "Epoch 795/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9096 - acc: 0.3158 - val_loss: 5.4199 - val_acc: 0.0816\n",
      "Epoch 796/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9084 - acc: 0.3161 - val_loss: 5.4211 - val_acc: 0.0816\n",
      "Epoch 797/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.9069 - acc: 0.3172 - val_loss: 5.4225 - val_acc: 0.0816\n",
      "Epoch 798/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9056 - acc: 0.3165 - val_loss: 5.4243 - val_acc: 0.0819\n",
      "Epoch 799/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9043 - acc: 0.3168 - val_loss: 5.4261 - val_acc: 0.0816\n",
      "Epoch 800/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9031 - acc: 0.3168 - val_loss: 5.4276 - val_acc: 0.0816\n",
      "Epoch 801/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9018 - acc: 0.3171 - val_loss: 5.4294 - val_acc: 0.0822\n",
      "Epoch 802/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.9006 - acc: 0.3175 - val_loss: 5.4312 - val_acc: 0.0816\n",
      "Epoch 803/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8993 - acc: 0.3175 - val_loss: 5.4329 - val_acc: 0.0822\n",
      "Epoch 804/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8978 - acc: 0.3179 - val_loss: 5.4339 - val_acc: 0.0816\n",
      "Epoch 805/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8964 - acc: 0.3187 - val_loss: 5.4355 - val_acc: 0.0816\n",
      "Epoch 806/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8950 - acc: 0.3183 - val_loss: 5.4373 - val_acc: 0.0819\n",
      "Epoch 807/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8937 - acc: 0.3190 - val_loss: 5.4388 - val_acc: 0.0819\n",
      "Epoch 808/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8923 - acc: 0.3190 - val_loss: 5.4403 - val_acc: 0.0816\n",
      "Epoch 809/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8910 - acc: 0.3189 - val_loss: 5.4413 - val_acc: 0.0816\n",
      "Epoch 810/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8897 - acc: 0.3194 - val_loss: 5.4430 - val_acc: 0.0813\n",
      "Epoch 811/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.8884 - acc: 0.3204 - val_loss: 5.4439 - val_acc: 0.0816\n",
      "Epoch 812/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.8872 - acc: 0.3197 - val_loss: 5.4458 - val_acc: 0.0819\n",
      "Epoch 813/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8859 - acc: 0.3201 - val_loss: 5.4473 - val_acc: 0.0819\n",
      "Epoch 814/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8848 - acc: 0.3202 - val_loss: 5.4489 - val_acc: 0.0816\n",
      "Epoch 815/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8834 - acc: 0.3205 - val_loss: 5.4501 - val_acc: 0.0819\n",
      "Epoch 816/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8822 - acc: 0.3208 - val_loss: 5.4513 - val_acc: 0.0816\n",
      "Epoch 817/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8809 - acc: 0.3204 - val_loss: 5.4528 - val_acc: 0.0816\n",
      "Epoch 818/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8795 - acc: 0.3203 - val_loss: 5.4540 - val_acc: 0.0819\n",
      "Epoch 819/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8782 - acc: 0.3211 - val_loss: 5.4557 - val_acc: 0.0822\n",
      "Epoch 820/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8770 - acc: 0.3205 - val_loss: 5.4570 - val_acc: 0.0816\n",
      "Epoch 821/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8756 - acc: 0.3215 - val_loss: 5.4584 - val_acc: 0.0816\n",
      "Epoch 822/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8745 - acc: 0.3218 - val_loss: 5.4595 - val_acc: 0.0816\n",
      "Epoch 823/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8733 - acc: 0.3216 - val_loss: 5.4606 - val_acc: 0.0819\n",
      "Epoch 824/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8720 - acc: 0.3214 - val_loss: 5.4622 - val_acc: 0.0813\n",
      "Epoch 825/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8710 - acc: 0.3219 - val_loss: 5.4633 - val_acc: 0.0816\n",
      "Epoch 826/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8694 - acc: 0.3223 - val_loss: 5.4647 - val_acc: 0.0816\n",
      "Epoch 827/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8683 - acc: 0.3219 - val_loss: 5.4669 - val_acc: 0.0819\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8669 - acc: 0.3227 - val_loss: 5.4690 - val_acc: 0.0819\n",
      "Epoch 829/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8658 - acc: 0.3223 - val_loss: 5.4703 - val_acc: 0.0816\n",
      "Epoch 830/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.8644 - acc: 0.3234 - val_loss: 5.4718 - val_acc: 0.0816\n",
      "Epoch 831/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8632 - acc: 0.3234 - val_loss: 5.4732 - val_acc: 0.0819\n",
      "Epoch 832/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8619 - acc: 0.3238 - val_loss: 5.4749 - val_acc: 0.0819\n",
      "Epoch 833/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.8606 - acc: 0.3232 - val_loss: 5.4761 - val_acc: 0.0822\n",
      "Epoch 834/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8596 - acc: 0.3230 - val_loss: 5.4780 - val_acc: 0.0819\n",
      "Epoch 835/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.8582 - acc: 0.3237 - val_loss: 5.4790 - val_acc: 0.0816\n",
      "Epoch 836/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8573 - acc: 0.3237 - val_loss: 5.4810 - val_acc: 0.0819\n",
      "Epoch 837/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8561 - acc: 0.3240 - val_loss: 5.4813 - val_acc: 0.0825\n",
      "Epoch 838/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.8550 - acc: 0.3240 - val_loss: 5.4833 - val_acc: 0.0816\n",
      "Epoch 839/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8535 - acc: 0.3237 - val_loss: 5.4844 - val_acc: 0.0819\n",
      "Epoch 840/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8521 - acc: 0.3246 - val_loss: 5.4852 - val_acc: 0.0819\n",
      "Epoch 841/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8507 - acc: 0.3255 - val_loss: 5.4873 - val_acc: 0.0813\n",
      "Epoch 842/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.8496 - acc: 0.3254 - val_loss: 5.4884 - val_acc: 0.0822\n",
      "Epoch 843/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.8484 - acc: 0.3257 - val_loss: 5.4904 - val_acc: 0.0810\n",
      "Epoch 844/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 1.8471 - acc: 0.3253 - val_loss: 5.4917 - val_acc: 0.0822\n",
      "Epoch 845/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8460 - acc: 0.3261 - val_loss: 5.4937 - val_acc: 0.0813\n",
      "Epoch 846/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.8450 - acc: 0.3259 - val_loss: 5.4950 - val_acc: 0.0822\n",
      "Epoch 847/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8438 - acc: 0.3262 - val_loss: 5.4969 - val_acc: 0.0819\n",
      "Epoch 848/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.8423 - acc: 0.3267 - val_loss: 5.4978 - val_acc: 0.0825\n",
      "Epoch 849/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8411 - acc: 0.3269 - val_loss: 5.4987 - val_acc: 0.0825\n",
      "Epoch 850/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8399 - acc: 0.3263 - val_loss: 5.5008 - val_acc: 0.0807\n",
      "Epoch 851/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8387 - acc: 0.3269 - val_loss: 5.5019 - val_acc: 0.0825\n",
      "Epoch 852/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8375 - acc: 0.3270 - val_loss: 5.5038 - val_acc: 0.0810\n",
      "Epoch 853/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8366 - acc: 0.3278 - val_loss: 5.5040 - val_acc: 0.0825\n",
      "Epoch 854/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8356 - acc: 0.3270 - val_loss: 5.5065 - val_acc: 0.0810\n",
      "Epoch 855/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8347 - acc: 0.3268 - val_loss: 5.5079 - val_acc: 0.0825\n",
      "Epoch 856/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8334 - acc: 0.3278 - val_loss: 5.5098 - val_acc: 0.0807\n",
      "Epoch 857/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8323 - acc: 0.3280 - val_loss: 5.5109 - val_acc: 0.0816\n",
      "Epoch 858/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8310 - acc: 0.3284 - val_loss: 5.5121 - val_acc: 0.0816\n",
      "Epoch 859/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8296 - acc: 0.3289 - val_loss: 5.5133 - val_acc: 0.0822\n",
      "Epoch 860/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8284 - acc: 0.3290 - val_loss: 5.5145 - val_acc: 0.0816\n",
      "Epoch 861/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8271 - acc: 0.3291 - val_loss: 5.5160 - val_acc: 0.0819\n",
      "Epoch 862/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8257 - acc: 0.3290 - val_loss: 5.5175 - val_acc: 0.0822\n",
      "Epoch 863/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8245 - acc: 0.3290 - val_loss: 5.5187 - val_acc: 0.0819\n",
      "Epoch 864/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8232 - acc: 0.3296 - val_loss: 5.5194 - val_acc: 0.0822\n",
      "Epoch 865/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8219 - acc: 0.3304 - val_loss: 5.5208 - val_acc: 0.0816\n",
      "Epoch 866/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8208 - acc: 0.3304 - val_loss: 5.5226 - val_acc: 0.0828\n",
      "Epoch 867/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8196 - acc: 0.3298 - val_loss: 5.5242 - val_acc: 0.0822\n",
      "Epoch 868/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8184 - acc: 0.3303 - val_loss: 5.5257 - val_acc: 0.0822\n",
      "Epoch 869/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8172 - acc: 0.3303 - val_loss: 5.5270 - val_acc: 0.0816\n",
      "Epoch 870/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8161 - acc: 0.3307 - val_loss: 5.5285 - val_acc: 0.0816\n",
      "Epoch 871/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.8149 - acc: 0.3309 - val_loss: 5.5290 - val_acc: 0.0819\n",
      "Epoch 872/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8137 - acc: 0.3308 - val_loss: 5.5309 - val_acc: 0.0822\n",
      "Epoch 873/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8125 - acc: 0.3309 - val_loss: 5.5324 - val_acc: 0.0819\n",
      "Epoch 874/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8113 - acc: 0.3311 - val_loss: 5.5335 - val_acc: 0.0819\n",
      "Epoch 875/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8103 - acc: 0.3320 - val_loss: 5.5354 - val_acc: 0.0822\n",
      "Epoch 876/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8091 - acc: 0.3320 - val_loss: 5.5368 - val_acc: 0.0816\n",
      "Epoch 877/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8080 - acc: 0.3326 - val_loss: 5.5380 - val_acc: 0.0816\n",
      "Epoch 878/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8069 - acc: 0.3320 - val_loss: 5.5395 - val_acc: 0.0819\n",
      "Epoch 879/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8057 - acc: 0.3325 - val_loss: 5.5410 - val_acc: 0.0816\n",
      "Epoch 880/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8046 - acc: 0.3329 - val_loss: 5.5419 - val_acc: 0.0819\n",
      "Epoch 881/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8035 - acc: 0.3336 - val_loss: 5.5428 - val_acc: 0.0819\n",
      "Epoch 882/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.8021 - acc: 0.3339 - val_loss: 5.5448 - val_acc: 0.0816\n",
      "Epoch 883/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 1.8010 - acc: 0.3338 - val_loss: 5.5456 - val_acc: 0.0822\n",
      "Epoch 884/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7999 - acc: 0.3343 - val_loss: 5.5469 - val_acc: 0.0819\n",
      "Epoch 885/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7987 - acc: 0.3341 - val_loss: 5.5482 - val_acc: 0.0819\n",
      "Epoch 886/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7976 - acc: 0.3341 - val_loss: 5.5494 - val_acc: 0.0816\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7965 - acc: 0.3343 - val_loss: 5.5501 - val_acc: 0.0819\n",
      "Epoch 888/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7953 - acc: 0.3349 - val_loss: 5.5515 - val_acc: 0.0816\n",
      "Epoch 889/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7943 - acc: 0.3353 - val_loss: 5.5526 - val_acc: 0.0819\n",
      "Epoch 890/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7933 - acc: 0.3357 - val_loss: 5.5544 - val_acc: 0.0807\n",
      "Epoch 891/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7922 - acc: 0.3358 - val_loss: 5.5557 - val_acc: 0.0813\n",
      "Epoch 892/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7912 - acc: 0.3357 - val_loss: 5.5575 - val_acc: 0.0807\n",
      "Epoch 893/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7901 - acc: 0.3358 - val_loss: 5.5588 - val_acc: 0.0807\n",
      "Epoch 894/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7887 - acc: 0.3365 - val_loss: 5.5595 - val_acc: 0.0807\n",
      "Epoch 895/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7876 - acc: 0.3361 - val_loss: 5.5604 - val_acc: 0.0810\n",
      "Epoch 896/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7865 - acc: 0.3364 - val_loss: 5.5616 - val_acc: 0.0807\n",
      "Epoch 897/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7854 - acc: 0.3370 - val_loss: 5.5638 - val_acc: 0.0807\n",
      "Epoch 898/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7842 - acc: 0.3365 - val_loss: 5.5640 - val_acc: 0.0804\n",
      "Epoch 899/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7832 - acc: 0.3370 - val_loss: 5.5651 - val_acc: 0.0807\n",
      "Epoch 900/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7822 - acc: 0.3374 - val_loss: 5.5657 - val_acc: 0.0810\n",
      "Epoch 901/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 1.7814 - acc: 0.3373 - val_loss: 5.5682 - val_acc: 0.0813\n",
      "Epoch 902/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7816 - acc: 0.3377 - val_loss: 5.5698 - val_acc: 0.0810\n",
      "Epoch 903/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7814 - acc: 0.3386 - val_loss: 5.5738 - val_acc: 0.0813\n",
      "Epoch 904/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7812 - acc: 0.3381 - val_loss: 5.5753 - val_acc: 0.0804\n",
      "Epoch 905/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7791 - acc: 0.3381 - val_loss: 5.5760 - val_acc: 0.0796\n",
      "Epoch 906/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7791 - acc: 0.3372 - val_loss: 5.5774 - val_acc: 0.0804\n",
      "Epoch 907/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7779 - acc: 0.3389 - val_loss: 5.5772 - val_acc: 0.0799\n",
      "Epoch 908/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 1.7760 - acc: 0.3381 - val_loss: 5.5783 - val_acc: 0.0804\n",
      "Epoch 909/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7747 - acc: 0.3396 - val_loss: 5.5800 - val_acc: 0.0807\n",
      "Epoch 910/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 1.7730 - acc: 0.3394 - val_loss: 5.5807 - val_acc: 0.0796\n",
      "Epoch 911/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 1.7720 - acc: 0.3389 - val_loss: 5.5817 - val_acc: 0.0804\n",
      "Epoch 912/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7708 - acc: 0.3394 - val_loss: 5.5836 - val_acc: 0.0796\n",
      "Epoch 913/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7694 - acc: 0.3391 - val_loss: 5.5849 - val_acc: 0.0804\n",
      "Epoch 914/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7684 - acc: 0.3390 - val_loss: 5.5857 - val_acc: 0.0799\n",
      "Epoch 915/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7671 - acc: 0.3395 - val_loss: 5.5868 - val_acc: 0.0796\n",
      "Epoch 916/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7657 - acc: 0.3399 - val_loss: 5.5878 - val_acc: 0.0802\n",
      "Epoch 917/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7644 - acc: 0.3399 - val_loss: 5.5887 - val_acc: 0.0802\n",
      "Epoch 918/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7635 - acc: 0.3406 - val_loss: 5.5897 - val_acc: 0.0813\n",
      "Epoch 919/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7624 - acc: 0.3410 - val_loss: 5.5908 - val_acc: 0.0807\n",
      "Epoch 920/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7611 - acc: 0.3413 - val_loss: 5.5921 - val_acc: 0.0813\n",
      "Epoch 921/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7602 - acc: 0.3406 - val_loss: 5.5935 - val_acc: 0.0804\n",
      "Epoch 922/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7591 - acc: 0.3412 - val_loss: 5.5951 - val_acc: 0.0819\n",
      "Epoch 923/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7580 - acc: 0.3407 - val_loss: 5.5962 - val_acc: 0.0813\n",
      "Epoch 924/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7570 - acc: 0.3414 - val_loss: 5.5964 - val_acc: 0.0816\n",
      "Epoch 925/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7560 - acc: 0.3415 - val_loss: 5.5978 - val_acc: 0.0804\n",
      "Epoch 926/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7548 - acc: 0.3414 - val_loss: 5.5992 - val_acc: 0.0822\n",
      "Epoch 927/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7539 - acc: 0.3412 - val_loss: 5.6007 - val_acc: 0.0810\n",
      "Epoch 928/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7529 - acc: 0.3423 - val_loss: 5.6013 - val_acc: 0.0819\n",
      "Epoch 929/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7519 - acc: 0.3428 - val_loss: 5.6027 - val_acc: 0.0804\n",
      "Epoch 930/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7506 - acc: 0.3433 - val_loss: 5.6043 - val_acc: 0.0813\n",
      "Epoch 931/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7495 - acc: 0.3427 - val_loss: 5.6050 - val_acc: 0.0807\n",
      "Epoch 932/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7484 - acc: 0.3424 - val_loss: 5.6063 - val_acc: 0.0813\n",
      "Epoch 933/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7473 - acc: 0.3423 - val_loss: 5.6080 - val_acc: 0.0810\n",
      "Epoch 934/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7463 - acc: 0.3429 - val_loss: 5.6092 - val_acc: 0.0807\n",
      "Epoch 935/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7453 - acc: 0.3439 - val_loss: 5.6098 - val_acc: 0.0807\n",
      "Epoch 936/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7443 - acc: 0.3437 - val_loss: 5.6114 - val_acc: 0.0807\n",
      "Epoch 937/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7429 - acc: 0.3444 - val_loss: 5.6130 - val_acc: 0.0816\n",
      "Epoch 938/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7418 - acc: 0.3441 - val_loss: 5.6149 - val_acc: 0.0813\n",
      "Epoch 939/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7407 - acc: 0.3442 - val_loss: 5.6163 - val_acc: 0.0810\n",
      "Epoch 940/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7396 - acc: 0.3441 - val_loss: 5.6168 - val_acc: 0.0813\n",
      "Epoch 941/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7384 - acc: 0.3445 - val_loss: 5.6181 - val_acc: 0.0810\n",
      "Epoch 942/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7374 - acc: 0.3447 - val_loss: 5.6201 - val_acc: 0.0810\n",
      "Epoch 943/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7363 - acc: 0.3449 - val_loss: 5.6217 - val_acc: 0.0816\n",
      "Epoch 944/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7354 - acc: 0.3449 - val_loss: 5.6221 - val_acc: 0.0810\n",
      "Epoch 945/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7344 - acc: 0.3451 - val_loss: 5.6229 - val_acc: 0.0810\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7336 - acc: 0.3452 - val_loss: 5.6241 - val_acc: 0.0810\n",
      "Epoch 947/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7324 - acc: 0.3450 - val_loss: 5.6260 - val_acc: 0.0810\n",
      "Epoch 948/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7316 - acc: 0.3449 - val_loss: 5.6276 - val_acc: 0.0807\n",
      "Epoch 949/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7304 - acc: 0.3458 - val_loss: 5.6292 - val_acc: 0.0810\n",
      "Epoch 950/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7295 - acc: 0.3461 - val_loss: 5.6300 - val_acc: 0.0813\n",
      "Epoch 951/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7285 - acc: 0.3462 - val_loss: 5.6314 - val_acc: 0.0807\n",
      "Epoch 952/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7277 - acc: 0.3465 - val_loss: 5.6329 - val_acc: 0.0813\n",
      "Epoch 953/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7269 - acc: 0.3463 - val_loss: 5.6340 - val_acc: 0.0807\n",
      "Epoch 954/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7259 - acc: 0.3462 - val_loss: 5.6355 - val_acc: 0.0816\n",
      "Epoch 955/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7250 - acc: 0.3470 - val_loss: 5.6366 - val_acc: 0.0819\n",
      "Epoch 956/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7241 - acc: 0.3469 - val_loss: 5.6380 - val_acc: 0.0819\n",
      "Epoch 957/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7230 - acc: 0.3473 - val_loss: 5.6390 - val_acc: 0.0816\n",
      "Epoch 958/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7222 - acc: 0.3473 - val_loss: 5.6397 - val_acc: 0.0802\n",
      "Epoch 959/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7212 - acc: 0.3471 - val_loss: 5.6411 - val_acc: 0.0813\n",
      "Epoch 960/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7203 - acc: 0.3476 - val_loss: 5.6425 - val_acc: 0.0799\n",
      "Epoch 961/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7194 - acc: 0.3482 - val_loss: 5.6438 - val_acc: 0.0804\n",
      "Epoch 962/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7183 - acc: 0.3481 - val_loss: 5.6452 - val_acc: 0.0799\n",
      "Epoch 963/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7174 - acc: 0.3481 - val_loss: 5.6461 - val_acc: 0.0807\n",
      "Epoch 964/1000\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 1.7167 - acc: 0.3476 - val_loss: 5.6473 - val_acc: 0.0816\n",
      "Epoch 965/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7160 - acc: 0.3486 - val_loss: 5.6491 - val_acc: 0.0802\n",
      "Epoch 966/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7156 - acc: 0.3487 - val_loss: 5.6506 - val_acc: 0.0807\n",
      "Epoch 967/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7145 - acc: 0.3487 - val_loss: 5.6514 - val_acc: 0.0802\n",
      "Epoch 968/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7134 - acc: 0.3488 - val_loss: 5.6526 - val_acc: 0.0810\n",
      "Epoch 969/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7122 - acc: 0.3492 - val_loss: 5.6533 - val_acc: 0.0810\n",
      "Epoch 970/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7113 - acc: 0.3503 - val_loss: 5.6545 - val_acc: 0.0813\n",
      "Epoch 971/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7101 - acc: 0.3500 - val_loss: 5.6559 - val_acc: 0.0813\n",
      "Epoch 972/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7087 - acc: 0.3504 - val_loss: 5.6567 - val_acc: 0.0807\n",
      "Epoch 973/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7078 - acc: 0.3505 - val_loss: 5.6586 - val_acc: 0.0807\n",
      "Epoch 974/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7068 - acc: 0.3501 - val_loss: 5.6599 - val_acc: 0.0807\n",
      "Epoch 975/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7057 - acc: 0.3510 - val_loss: 5.6606 - val_acc: 0.0807\n",
      "Epoch 976/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7048 - acc: 0.3507 - val_loss: 5.6622 - val_acc: 0.0802\n",
      "Epoch 977/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7038 - acc: 0.3507 - val_loss: 5.6641 - val_acc: 0.0810\n",
      "Epoch 978/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.7029 - acc: 0.3510 - val_loss: 5.6659 - val_acc: 0.0802\n",
      "Epoch 979/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7018 - acc: 0.3513 - val_loss: 5.6672 - val_acc: 0.0810\n",
      "Epoch 980/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.7008 - acc: 0.3513 - val_loss: 5.6687 - val_acc: 0.0804\n",
      "Epoch 981/1000\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.6999 - acc: 0.3524 - val_loss: 5.6701 - val_acc: 0.0810\n",
      "Epoch 982/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6992 - acc: 0.3523 - val_loss: 5.6713 - val_acc: 0.0799\n",
      "Epoch 983/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6983 - acc: 0.3525 - val_loss: 5.6729 - val_acc: 0.0810\n",
      "Epoch 984/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6973 - acc: 0.3524 - val_loss: 5.6740 - val_acc: 0.0793\n",
      "Epoch 985/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6963 - acc: 0.3525 - val_loss: 5.6753 - val_acc: 0.0807\n",
      "Epoch 986/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6955 - acc: 0.3526 - val_loss: 5.6767 - val_acc: 0.0793\n",
      "Epoch 987/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6944 - acc: 0.3529 - val_loss: 5.6776 - val_acc: 0.0804\n",
      "Epoch 988/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6934 - acc: 0.3536 - val_loss: 5.6791 - val_acc: 0.0799\n",
      "Epoch 989/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6924 - acc: 0.3534 - val_loss: 5.6806 - val_acc: 0.0810\n",
      "Epoch 990/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6915 - acc: 0.3535 - val_loss: 5.6819 - val_acc: 0.0793\n",
      "Epoch 991/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6906 - acc: 0.3534 - val_loss: 5.6830 - val_acc: 0.0802\n",
      "Epoch 992/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6898 - acc: 0.3529 - val_loss: 5.6846 - val_acc: 0.0799\n",
      "Epoch 993/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6890 - acc: 0.3534 - val_loss: 5.6859 - val_acc: 0.0802\n",
      "Epoch 994/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6879 - acc: 0.3534 - val_loss: 5.6871 - val_acc: 0.0793\n",
      "Epoch 995/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6870 - acc: 0.3539 - val_loss: 5.6885 - val_acc: 0.0802\n",
      "Epoch 996/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6862 - acc: 0.3545 - val_loss: 5.6895 - val_acc: 0.0802\n",
      "Epoch 997/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6851 - acc: 0.3537 - val_loss: 5.6906 - val_acc: 0.0793\n",
      "Epoch 998/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6842 - acc: 0.3540 - val_loss: 5.6919 - val_acc: 0.0799\n",
      "Epoch 999/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6832 - acc: 0.3549 - val_loss: 5.6936 - val_acc: 0.0793\n",
      "Epoch 1000/1000\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.6823 - acc: 0.3547 - val_loss: 5.6941 - val_acc: 0.0807\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(x= [input_sequences,z,z],y= one_hot_targets,batch_size= BATCH_SIZE,\n",
    "                  epochs= EPOCHS,validation_split= VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ambar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py:2379: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_2:0' shape=(?, 25) dtype=float32>, <tf.Tensor 'input_3:0' shape=(?, 25) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.save('Poetry_generation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting loss and accuracy \n",
    "\n",
    "Note: This plot does't really make sense here because each output is a softmax classifier. Our mode is just learning next words based on previous words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b045f8aef0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.history['loss'], label='loss')\n",
    "plt.plot(train.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b045f94198>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.history['acc'], label='acc')\n",
    "plt.plot(train.history['val_acc'], label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New model to generate poem\n",
    "\n",
    "In this session we will build a new model to generate poetry. \n",
    "\n",
    "In Keras we must specify the input seqence length beforehand, for training this was the length of the longest sentence in the poem. This was ok for training since the training is done using teacher forcing method but it will not work for the generative session. This is because in generative session, the output from the first LSTM unit is used as the input to the next LSTM unit and so on. \n",
    "\n",
    "For Example: \n",
    "\n",
    " - sos = x1, this gives y1\n",
    " - y1 = x2, this gives y2\n",
    " - y2 = x3, this gives y3 and so on .....\n",
    " \n",
    "We will sample a random word and ask the model to predict the next word. The next word is calculated by taking the argmax of the predicted words so that we will get word with the highest probability. This word is passed on as the next input and so on in a for loop. Note that we will be using the pre-trained state values from the trained model here and this is why we had to manually initialize the hidden and cell states when we built the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll only input one word at a time\n",
    "    \n",
    "input2 = Input(shape=(1,))\n",
    "x = embedding_layer(input2)\n",
    "x, h, c = lstm(x, initial_state=[initial_h, initial_c]) # now we need states to feed back in\n",
    "output2 = dense(x)\n",
    "generative_model = Model([input2, initial_h, initial_c], [output2, h, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse word2idx dictionary to get back words\n",
    "# during prediction\n",
    "\n",
    "idx2word = {value:key for key, value in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem():\n",
    "    \n",
    "    np_input = np.array([[ word2idx['<sos>'] ]])\n",
    "    h = np.zeros((1, HIDDEN_DIM))\n",
    "    c = np.zeros((1, HIDDEN_DIM))\n",
    "    \n",
    "    \n",
    "    eos = word2idx['<eos>']\n",
    "    \n",
    "    output_sentence = []\n",
    "    \n",
    "    for _ in range(max_sequence_length):\n",
    "        \n",
    "        o, h, c = generative_model.predict([np_input, h, c])\n",
    "        \n",
    "        probs = o[0,0]\n",
    "            \n",
    "        if np.argmax(probs) == 0:\n",
    "            \n",
    "            print(\"wtf\")\n",
    "            \n",
    "        probs[0] = 0\n",
    "        probs /= probs.sum()\n",
    "        idx = np.random.choice(len(probs), p=probs)    \n",
    "        \n",
    "        if idx == eos:\n",
    "            break\n",
    "        output_sentence.append(idx2word.get(idx, '<WTF %s>' % idx))\n",
    "        \n",
    "        np_input[0,0] = idx\n",
    "        \n",
    "        \n",
    "    return ' '.join(output_sentence) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a 4 line poem\n",
    "\n",
    "We will generate 4 lines of poem as an infinite loop, this loop goes on till we quit manually. Generally Robert Frost poems are 4 lines per verse, that's why we are generating 4 lines here so that it can be interpretable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and bring the which was no have them tended:\n",
      "the you, is me. he kept its kitchen to gold,\n",
      "'well i—'\n",
      "that means the avalanches,\n",
      "---generate another? [Y/n]---y\n",
      "nor granny's, surely. take his house that sailing like such the empty\n",
      "done?\n",
      "the january teeth.\n",
      "it is to other that night\n",
      "---generate another? [Y/n]---y\n",
      "could matter to fathom\n",
      "and tell some color and shouted, 'shut after cider, the shut,\n",
      "in leaves no joined in me\n",
      "the chimney glass to south across a low of dishes\n",
      "---generate another? [Y/n]---y\n",
      "'take one,' mother that me say all that. he inquired. 'no much\n",
      "of tying together\n",
      "(the timber-\n",
      "but all the young and forty still been trees\n",
      "---generate another? [Y/n]---y\n",
      "they'll tell me say two again to familiar traps\n",
      "faster or mountain like a going to all with over\n",
      "drawn into the book in trees,\n",
      "toffile alone fate\n",
      "---generate another? [Y/n]---y\n",
      "its voices decently they're witch?\n",
      "i would on.\n",
      "he had looked down take had lingered brown,\n",
      "he'd only idled down.'\n",
      "---generate another? [Y/n]---n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    for _ in range(4):\n",
    "        print(generate_poem())\n",
    "\n",
    "    ans = input(\"---generate another? [Y/n]---\")\n",
    "    if ans and ans[0].lower().startswith('n'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
